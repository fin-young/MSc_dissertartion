{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affbafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FX_DATA_GEN as DG\n",
    "from THEO_POULA_Model import LSTMModel, get_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import hstack, array\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from THEO_POULA_Optim import THEOPOULA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily FX Rate dataset call\n",
    "#DG.Get_curr_data('MX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0df15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Macro economic dataset call\n",
    "#MEX = DG.MacEcon_TS('MX',1980, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feef7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of Macro economic dataset\n",
    "#DG.describe_MacEcon_TS(MEX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58c38cf",
   "metadata": {},
   "source": [
    "## Create dataset & Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2b3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint dataset of Macro economic & FX Rates combined\n",
    "mex_full = DG.Get_FX_MacEcon_Data('MX')\n",
    "#mex_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393723a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description to know which columns to remove from dataframe\n",
    "DG.describe_MacEcon_TS(mex_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74174106",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEX_copy = mex_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe210396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add one hot dummy columns for month\n",
    "MEX_copy = (DG.Add_dummy_MoY(MEX_copy))\n",
    "#MEX_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15233ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>First Valid</th>\n",
       "      <th>Last Valid</th>\n",
       "      <th>Null Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MXN</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sin_DoY</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ave Monthly USD FX Rate</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inflation (CPI) %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deposit Interest Rate %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lending Interest Rate %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Real Interest Rate(%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Foreign Exchange Reserves(%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M2 Multiplier Growth (%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REED 12mth std dev</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Current Account(%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FDI(%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Capital Formations(USD)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gov Consumption Expendature (%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GDP % Growth</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MoY_is_1</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MoY_is_2</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MoY_is_3</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MoY_is_4</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MoY_is_5</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MoY_is_6</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MoY_is_7</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MoY_is_8</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MoY_is_9</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MoY_is_10</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoY_is_11</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoY_is_12</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features First Valid Last Valid  Null Values\n",
       "0                                  MXN  1993-11-08 2020-11-30            0\n",
       "1                              sin_DoY  1993-11-08 2020-11-30            0\n",
       "2              Ave Monthly USD FX Rate  1993-11-08 2020-11-30            0\n",
       "3                    Inflation (CPI) %  1993-11-08 2020-11-30            0\n",
       "4              Deposit Interest Rate %  1993-11-08 2020-11-30            0\n",
       "5              Lending Interest Rate %  1993-11-08 2020-11-30            0\n",
       "6                       NY.GDP.MKTP.CD  1993-11-08 2020-11-30            0\n",
       "7                Real Interest Rate(%)  1993-11-08 2020-11-30            0\n",
       "8         Foreign Exchange Reserves(%)  1993-11-08 2020-11-30            0\n",
       "9             M2 Multiplier Growth (%)  1993-11-08 2020-11-30            0\n",
       "10                  REED 12mth std dev  1993-11-08 2020-11-30            0\n",
       "11               Current Account(%GDP)  1993-11-08 2020-11-30            0\n",
       "12                           FDI(%GDP)  1993-11-08 2020-11-30            0\n",
       "13             Capital Formations(USD)  1993-11-08 2020-11-30            0\n",
       "14  Gov Consumption Expendature (%GDP)  1993-11-08 2020-11-30            0\n",
       "15                        GDP % Growth  1993-11-08 2020-11-30            0\n",
       "16                            MoY_is_1  1993-11-08 2020-11-30            0\n",
       "17                            MoY_is_2  1993-11-08 2020-11-30            0\n",
       "18                            MoY_is_3  1993-11-08 2020-11-30            0\n",
       "19                            MoY_is_4  1993-11-08 2020-11-30            0\n",
       "20                            MoY_is_5  1993-11-08 2020-11-30            0\n",
       "21                            MoY_is_6  1993-11-08 2020-11-30            0\n",
       "22                            MoY_is_7  1993-11-08 2020-11-30            0\n",
       "23                            MoY_is_8  1993-11-08 2020-11-30            0\n",
       "24                            MoY_is_9  1993-11-08 2020-11-30            0\n",
       "25                           MoY_is_10  1993-11-08 2020-11-30            0\n",
       "26                           MoY_is_11  1993-11-08 2020-11-30            0\n",
       "27                           MoY_is_12  1993-11-08 2020-11-30            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description of cleaned and one-hott'ed dataset\n",
    "MEX_copy.drop(columns = ['M2/Reserves','Domestic Credit to GDP','Portfolio Investments(USD)','Total Debt(USD)','Short Term Debt(USD)','cos_DoY','Yr','DoM'], inplace = True)\n",
    "DG.describe_MacEcon_TS(MEX_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d747a891",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MXN_X</th>\n",
       "      <th>sin_DoY</th>\n",
       "      <th>Ave Monthly USD FX Rate</th>\n",
       "      <th>Inflation (CPI) %</th>\n",
       "      <th>Deposit Interest Rate %</th>\n",
       "      <th>Lending Interest Rate %</th>\n",
       "      <th>NY.GDP.MKTP.CD</th>\n",
       "      <th>Real Interest Rate(%)</th>\n",
       "      <th>Foreign Exchange Reserves(%)</th>\n",
       "      <th>M2 Multiplier Growth (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>MoY_is_4</th>\n",
       "      <th>MoY_is_5</th>\n",
       "      <th>MoY_is_6</th>\n",
       "      <th>MoY_is_7</th>\n",
       "      <th>MoY_is_8</th>\n",
       "      <th>MoY_is_9</th>\n",
       "      <th>MoY_is_10</th>\n",
       "      <th>MoY_is_11</th>\n",
       "      <th>MoY_is_12</th>\n",
       "      <th>MXN_Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-11-09</th>\n",
       "      <td>3.1520</td>\n",
       "      <td>-0.790946</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-10</th>\n",
       "      <td>3.2400</td>\n",
       "      <td>-0.780296</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-12</th>\n",
       "      <td>3.2400</td>\n",
       "      <td>-0.758306</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-15</th>\n",
       "      <td>3.2400</td>\n",
       "      <td>-0.723644</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-18</th>\n",
       "      <td>3.2150</td>\n",
       "      <td>-0.687053</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-19</th>\n",
       "      <td>3.1080</td>\n",
       "      <td>-0.674444</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-22</th>\n",
       "      <td>3.1150</td>\n",
       "      <td>-0.635432</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-23</th>\n",
       "      <td>3.1022</td>\n",
       "      <td>-0.622047</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-24</th>\n",
       "      <td>3.1026</td>\n",
       "      <td>-0.608477</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-26</th>\n",
       "      <td>3.1030</td>\n",
       "      <td>-0.580800</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.1140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             MXN_X   sin_DoY  Ave Monthly USD FX Rate  Inflation (CPI) %  \\\n",
       "Date                                                                       \n",
       "1993-11-09  3.1520 -0.790946                   3.1553          18.715507   \n",
       "1993-11-10  3.2400 -0.780296                   3.1553          18.715507   \n",
       "1993-11-12  3.2400 -0.758306                   3.1553          18.715507   \n",
       "1993-11-15  3.2400 -0.723644                   3.1553          18.715507   \n",
       "1993-11-18  3.2150 -0.687053                   3.1553          18.715507   \n",
       "1993-11-19  3.1080 -0.674444                   3.1553          18.715507   \n",
       "1993-11-22  3.1150 -0.635432                   3.1553          18.715507   \n",
       "1993-11-23  3.1022 -0.622047                   3.1553          18.715507   \n",
       "1993-11-24  3.1026 -0.608477                   3.1553          18.715507   \n",
       "1993-11-26  3.1030 -0.580800                   3.1553          18.715507   \n",
       "\n",
       "            Deposit Interest Rate %  Lending Interest Rate %  NY.GDP.MKTP.CD  \\\n",
       "Date                                                                           \n",
       "1993-11-09                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-10                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-12                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-15                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-18                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-19                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-22                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-23                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-24                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-26                    14.74                    17.95    5.007361e+11   \n",
       "\n",
       "            Real Interest Rate(%)  Foreign Exchange Reserves(%)  \\\n",
       "Date                                                              \n",
       "1993-11-09              -0.765507                      3.788303   \n",
       "1993-11-10              -0.765507                      3.788303   \n",
       "1993-11-12              -0.765507                      3.788303   \n",
       "1993-11-15              -0.765507                      3.788303   \n",
       "1993-11-18              -0.765507                      3.788303   \n",
       "1993-11-19              -0.765507                      3.788303   \n",
       "1993-11-22              -0.765507                      3.788303   \n",
       "1993-11-23              -0.765507                      3.788303   \n",
       "1993-11-24              -0.765507                      3.788303   \n",
       "1993-11-26              -0.765507                      3.788303   \n",
       "\n",
       "            M2 Multiplier Growth (%)  ...  MoY_is_4  MoY_is_5  MoY_is_6  \\\n",
       "Date                                  ...                                 \n",
       "1993-11-09                   4.49811  ...         0         0         0   \n",
       "1993-11-10                   4.49811  ...         0         0         0   \n",
       "1993-11-12                   4.49811  ...         0         0         0   \n",
       "1993-11-15                   4.49811  ...         0         0         0   \n",
       "1993-11-18                   4.49811  ...         0         0         0   \n",
       "1993-11-19                   4.49811  ...         0         0         0   \n",
       "1993-11-22                   4.49811  ...         0         0         0   \n",
       "1993-11-23                   4.49811  ...         0         0         0   \n",
       "1993-11-24                   4.49811  ...         0         0         0   \n",
       "1993-11-26                   4.49811  ...         0         0         0   \n",
       "\n",
       "            MoY_is_7  MoY_is_8  MoY_is_9  MoY_is_10  MoY_is_11  MoY_is_12  \\\n",
       "Date                                                                        \n",
       "1993-11-09         0         0         0          0          1          0   \n",
       "1993-11-10         0         0         0          0          1          0   \n",
       "1993-11-12         0         0         0          0          1          0   \n",
       "1993-11-15         0         0         0          0          1          0   \n",
       "1993-11-18         0         0         0          0          1          0   \n",
       "1993-11-19         0         0         0          0          1          0   \n",
       "1993-11-22         0         0         0          0          1          0   \n",
       "1993-11-23         0         0         0          0          1          0   \n",
       "1993-11-24         0         0         0          0          1          0   \n",
       "1993-11-26         0         0         0          0          1          0   \n",
       "\n",
       "             MXN_Y  \n",
       "Date                \n",
       "1993-11-09  3.2400  \n",
       "1993-11-10  3.2400  \n",
       "1993-11-12  3.2400  \n",
       "1993-11-15  3.2150  \n",
       "1993-11-18  3.1080  \n",
       "1993-11-19  3.1150  \n",
       "1993-11-22  3.1022  \n",
       "1993-11-23  3.1026  \n",
       "1993-11-24  3.1030  \n",
       "1993-11-26  3.1140  \n",
       "\n",
       "[10 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift DF so that there is a FX_X and FX_Y at the start & end of the DF, respectively. \n",
    "MEX_SHF = DG.shift_FX(MEX_copy)\n",
    "MEX_SHF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1fa13",
   "metadata": {},
   "source": [
    "## Normalise & pre-process data for pytorch (3D array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ee7d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Set split param\n",
    "test_ratio = 0.2\n",
    "val_ratio = test_ratio / (1 - test_ratio)\n",
    "\n",
    "#Cut into Features and Target Variable\n",
    "y_name = MEX_SHF.iloc[:,-1].name\n",
    "X, y = MEX_SHF.drop([y_name], axis=1) , MEX_SHF[[y_name]]\n",
    "\n",
    "#Train & Test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)\n",
    "#Train & Validation \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90a4ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise data using standard scalar\n",
    "#Fit each row of data as an array\n",
    "scaler = DG.get_scaler('minmax')#DG.get_scaler('standard')\n",
    "\n",
    "X_train_arr = scaler.fit_transform(X_train)\n",
    "X_val_arr = scaler.transform(X_val)\n",
    "X_test_arr = scaler.transform(X_test)\n",
    "\n",
    "y_train_arr = scaler.fit_transform(y_train)\n",
    "y_val_arr = scaler.transform(y_val)\n",
    "y_test_arr = scaler.transform(y_test)\n",
    "\n",
    "#Stack the data back together before splitting the sequence\n",
    "train_arr = hstack((X_train_arr, y_train_arr))\n",
    "val_arr = hstack((X_val_arr, y_val_arr))\n",
    "test_arr = hstack((X_test_arr, y_test_arr))\n",
    "\n",
    "#split sequence will create a lag of the past 300 entries of the dataframe\n",
    "#\n",
    "n_steps = 90\n",
    "X_train_split, y_train_split = DG.split_sequences(train_arr,n_steps)\n",
    "X_val_split, y_val_split = DG.split_sequences(val_arr,n_steps)\n",
    "X_test_split, y_test_split = DG.split_sequences(test_arr,n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b5fd2fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3983, 90, 28)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f88257b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_features = torch.Tensor(X_train_split)\n",
    "train_targets = torch.Tensor(y_train_split)\n",
    "val_features = torch.Tensor(X_val_split)\n",
    "val_targets = torch.Tensor(y_val_split)\n",
    "test_features = torch.Tensor(X_test_split)\n",
    "test_targets = torch.Tensor(y_test_split)\n",
    "\n",
    "#Joint Tensor of \n",
    "train = TensorDataset(train_features, train_targets)\n",
    "val = TensorDataset(val_features, val_targets)\n",
    "test = TensorDataset(test_features, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8950917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Optimizer\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50747d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "#opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "#opt.plot_losses()\n",
    "\n",
    "#predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41604d",
   "metadata": {},
   "source": [
    "## Set Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "81fec510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMModel(\n",
      "  (lstm): LSTM(28, 6, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=6, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "input_dim = len(X_train.columns) #sequence length\n",
    "output_dim = 1\n",
    "seq_length = n_steps\n",
    "hidden_dim = 24\n",
    "layer_dim = 3\n",
    "batch_size = batch_size\n",
    "dropout = 0.2\n",
    "n_epochs = 100\n",
    "#learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'seq_length' : seq_length,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n",
    "\n",
    "#Call the LSTM Model from THEO_PULA_Model\n",
    "#model = get_model(\"lstm\", model_params)\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'pytorch CIFAR10')\n",
    "parser.add_argument('-f','--file',help='Path for input file. First line should contain number of lines to search in')\n",
    "parser.add_argument('--trial', default='trial1', type=str)\n",
    "parser.add_argument('--lr', default=1e-2, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--model_name', default='lstm', type=str)\n",
    "parser.add_argument('--num_epoch', default=200, type=int, dest='num_epoch')\n",
    "parser.add_argument('--optimizer_name', default='THEOPOULA', type=str)\n",
    "parser.add_argument('--eta', default='0', type=float)\n",
    "parser.add_argument('--beta', default='1e14', type=float)\n",
    "parser.add_argument('--r', default=5, type=int)\n",
    "parser.add_argument('--eps', default=1e-4, type=float)\n",
    "parser.add_argument('--act_fn', default='silu', type=str)\n",
    "\n",
    "parser.add_argument('--log_dir', default='./log/', type=str)\n",
    "parser.add_argument('--ckpt_dir', default='./ckpt/', type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_loss = 999\n",
    "state = []\n",
    "start_epoch = 1\n",
    "trial = args.trial\n",
    "#batch_size = args.batch_size\n",
    "num_epoch = args.num_epoch  #________________________________Change for real batch______________________ 20\n",
    "optimizer_name = args.optimizer_name\n",
    "act_fn = args.act_fn\n",
    "model_name = args.model_name\n",
    "model = get_model(args.model_name, model_params)\n",
    "lr = args.lr\n",
    "eta = args.eta\n",
    "beta = args.beta\n",
    "r = args.r\n",
    "eps = args.eps\n",
    "print(\"Model:\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a64cc5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_data: 124\n",
      "num_batch: 4.0\n"
     ]
    }
   ],
   "source": [
    "#Len of a dataloader is the number of batches: len(dataloader) = dataset size / batch size\n",
    "num_data = len(train_loader)\n",
    "print('num_data:',num_data)\n",
    "num_batch = np.ceil(num_data / batch_size)\n",
    "print('num_batch:',num_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf03e3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. on {cpu}\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model.. on {%s}'%device)\n",
    "net = model\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6499431d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(28, 6, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=6, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8b99b121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting optimizer.. {ADAM}\n"
     ]
    }
   ],
   "source": [
    "# To specfy when calling \n",
    "optimizer_name = 'ADAM'\n",
    "#_______________________________________________\n",
    "print('==> Setting optimizer.. {%s}'%optimizer_name)\n",
    "if optimizer_name == 'SGD':\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'ADAM':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'AMSGrad':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, amsgrad=True)\n",
    "elif optimizer_name == 'THEOPOULA':\n",
    "    optimizer = THEOPOULA(net.parameters(), lr=lr, eta=eta, beta=args.beta, r=r, eps=eps)\n",
    "\n",
    "\n",
    "\n",
    "if optimizer_name == 'THEOPOULA':\n",
    "    experiment_name = '%s_%s_bs{%d}_lr{%.1e}_epoch{%d}_eta{%.1e}_beta{%.1e}_r{%d}_eps{%.1e}' \\\n",
    "                      %(optimizer_name, model, batch_size, lr, num_epoch, eta, beta, r, eps)\n",
    "else:\n",
    "    experiment_name = '%s_%s_bs{%d}_lr{%.1e}_eps{%.1e}_epoch{%d}'%(optimizer_name, model_name, batch_size, lr, eps, num_epoch)\n",
    "    \n",
    "\n",
    "\n",
    "log_dir = args.log_dir + experiment_name\n",
    "ckpt_dir = args.ckpt_dir + experiment_name\n",
    "\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "## Training\n",
    "\n",
    "history = {'training_loss': [],\n",
    "           'test_loss': [],\n",
    "           'training_acc': [],\n",
    "           'test_acc': [],\n",
    "           }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae3f215",
   "metadata": {},
   "source": [
    "## Trian & Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e8e0587b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = []\n",
    "    acc_arr = []\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        #inputs = inputs.to(device)\n",
    "        inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        pred = fn_pred(outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        acc = fn_acc(pred, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "\n",
    "        if batch_idx%2 == 0:\n",
    "            print('TRAIN: EPOCH %04d/%04d | BATCH %04d/%04d | LOSS: %.4f |  ACC %.4f' %\n",
    "              (epoch, args.num_epoch, batch_idx, num_batch, train_loss[-1], acc_arr[-1]))\n",
    "    print('TRAIN: EPOCH %04d/%04d | LOSS: %.4f |  ACC %.4f' %\n",
    "          (epoch, args.num_epoch, np.mean(train_loss), np.mean(acc_arr)))\n",
    "    writer.add_scalar('Training loss', np.mean(train_loss), epoch)\n",
    "    writer.add_scalar('Training accuracy', np.mean(acc_arr), epoch)\n",
    "\n",
    "    history['training_loss'].append(np.mean(train_loss))\n",
    "    history['training_acc'].append(np.mean(acc_arr))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_loss, state\n",
    "    net.eval()\n",
    "    test_loss = []\n",
    "    acc_arr = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            pred = fn_pred(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = fn_acc(pred, targets)\n",
    "\n",
    "            test_loss += [loss.item()]\n",
    "            acc_arr += [acc.item()]\n",
    "\n",
    "        print('TEST:  LOSS: %.4f |  ACC %.4f' %\n",
    "                  (np.mean(test_loss),  np.mean(acc_arr)))\n",
    "\n",
    "    if np.mean(test_loss) < best_loss:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': np.mean(test_loss),\n",
    "            'epoch': epoch,\n",
    "            'optim': optimizer.state_dict()\n",
    "        }\n",
    "        best_loss = np.mean(test_loss)\n",
    "\n",
    "    writer.add_scalar('Validation loss', np.mean(test_loss), epoch)\n",
    "    writer.add_scalar('Validation accuracy', np.mean(acc_arr), epoch)\n",
    "\n",
    "    history['test_loss'].append(np.mean(test_loss))\n",
    "    history['test_acc'].append(np.mean(acc_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a5a1209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0000/0004 | LOSS: 0.0478 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0002/0004 | LOSS: 0.0161 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S1026623\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0200 | BATCH 0004/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0006/0004 | LOSS: 0.0410 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0008/0004 | LOSS: 0.0528 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0010/0004 | LOSS: 0.0380 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0012/0004 | LOSS: 0.0576 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0014/0004 | LOSS: 0.0496 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0016/0004 | LOSS: 0.0328 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0018/0004 | LOSS: 0.0231 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0020/0004 | LOSS: 0.0189 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0022/0004 | LOSS: 0.0090 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0024/0004 | LOSS: 0.0042 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0026/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0028/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0030/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0032/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0034/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0036/0004 | LOSS: 0.0023 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0038/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0040/0004 | LOSS: 0.0059 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0042/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0044/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0046/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0048/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0050/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0052/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0054/0004 | LOSS: 0.0026 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0056/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0058/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0060/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0062/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0064/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0066/0004 | LOSS: 0.0023 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0068/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0070/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0072/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0074/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0076/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0078/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0080/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0082/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0084/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0086/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0088/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0090/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0094/0004 | LOSS: 0.0022 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0096/0004 | LOSS: 0.0040 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0098/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0104/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0106/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0108/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0110/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0112/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0114/0004 | LOSS: 0.0311 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0116/0004 | LOSS: 0.0788 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0118/0004 | LOSS: 0.0281 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0120/0004 | LOSS: 0.0028 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | BATCH 0122/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | LOSS: 0.0099 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0268 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0000/0004 | LOSS: 0.8761 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0002/0004 | LOSS: 0.6632 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0004/0004 | LOSS: 0.4488 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0006/0004 | LOSS: 0.1352 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0008/0004 | LOSS: 0.0527 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0010/0004 | LOSS: 0.0230 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0012/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0014/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0016/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0018/0004 | LOSS: 0.0127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0020/0004 | LOSS: 0.0220 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0022/0004 | LOSS: 0.0218 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0024/0004 | LOSS: 0.0235 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0026/0004 | LOSS: 0.0191 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0028/0004 | LOSS: 0.0247 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0030/0004 | LOSS: 0.0276 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0032/0004 | LOSS: 0.0226 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0034/0004 | LOSS: 0.0303 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0036/0004 | LOSS: 0.0257 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0038/0004 | LOSS: 0.0041 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0040/0004 | LOSS: 0.0162 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0042/0004 | LOSS: 0.0143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0044/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0046/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0048/0004 | LOSS: 0.0040 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0050/0004 | LOSS: 0.0020 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0052/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0054/0004 | LOSS: 0.0048 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0056/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0058/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0060/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0062/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0064/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0066/0004 | LOSS: 0.0041 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0068/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0070/0004 | LOSS: 0.0096 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0072/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0074/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0076/0004 | LOSS: 0.0022 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0078/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0080/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0082/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0084/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0086/0004 | LOSS: 0.0038 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0088/0004 | LOSS: 0.0034 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0090/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0092/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0094/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0096/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0098/0004 | LOSS: 0.0025 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0100/0004 | LOSS: 0.0026 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0102/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0104/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0106/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0108/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0110/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0112/0004 | LOSS: 0.0048 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0002/0200 | BATCH 0114/0004 | LOSS: 0.0200 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0116/0004 | LOSS: 0.0586 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0118/0004 | LOSS: 0.0233 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0120/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0122/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | LOSS: 0.0401 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0128 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0000/0004 | LOSS: 0.7559 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0002/0004 | LOSS: 0.6292 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0004/0004 | LOSS: 0.4281 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0006/0004 | LOSS: 0.1237 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0008/0004 | LOSS: 0.0377 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0010/0004 | LOSS: 0.0114 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0012/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0014/0004 | LOSS: 0.0113 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0016/0004 | LOSS: 0.0173 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0018/0004 | LOSS: 0.0248 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0020/0004 | LOSS: 0.0363 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0022/0004 | LOSS: 0.0352 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0024/0004 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0026/0004 | LOSS: 0.0308 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0028/0004 | LOSS: 0.0382 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0030/0004 | LOSS: 0.0431 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0032/0004 | LOSS: 0.0410 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0034/0004 | LOSS: 0.0609 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0036/0004 | LOSS: 0.0769 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0038/0004 | LOSS: 0.0629 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0040/0004 | LOSS: 0.0344 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0042/0004 | LOSS: 0.0239 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0044/0004 | LOSS: 0.0183 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0046/0004 | LOSS: 0.0119 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0048/0004 | LOSS: 0.0110 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0050/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0052/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0054/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0056/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0058/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0062/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0064/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0066/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0068/0004 | LOSS: 0.0020 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0070/0004 | LOSS: 0.0087 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0072/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0074/0004 | LOSS: 0.0077 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0076/0004 | LOSS: 0.0090 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0078/0004 | LOSS: 0.0058 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0080/0004 | LOSS: 0.0092 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0082/0004 | LOSS: 0.0072 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0084/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0086/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0088/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0090/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0092/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0094/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0096/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0098/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0100/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0102/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0104/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0106/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0108/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0110/0004 | LOSS: 0.0022 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0112/0004 | LOSS: 0.0049 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0114/0004 | LOSS: 0.0188 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0116/0004 | LOSS: 0.0594 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0118/0004 | LOSS: 0.0352 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0120/0004 | LOSS: 0.0279 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0122/0004 | LOSS: 0.0205 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | LOSS: 0.0437 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0153 |  ACC 0.0000\n",
      "\n",
      "Epoch: 4\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0000/0004 | LOSS: 0.4659 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0002/0004 | LOSS: 0.4465 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0004/0004 | LOSS: 0.4169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0006/0004 | LOSS: 0.1770 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0008/0004 | LOSS: 0.1154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0010/0004 | LOSS: 0.0862 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0012/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0014/0004 | LOSS: 0.0109 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0016/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0018/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0020/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0022/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0024/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0026/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0028/0004 | LOSS: 0.0068 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0030/0004 | LOSS: 0.0124 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0032/0004 | LOSS: 0.0151 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0034/0004 | LOSS: 0.0336 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0036/0004 | LOSS: 0.0516 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0038/0004 | LOSS: 0.0457 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0040/0004 | LOSS: 0.0257 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0042/0004 | LOSS: 0.0199 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0044/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0046/0004 | LOSS: 0.0122 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0048/0004 | LOSS: 0.0135 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0050/0004 | LOSS: 0.0054 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0052/0004 | LOSS: 0.0058 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0054/0004 | LOSS: 0.0061 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0056/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0058/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0060/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0062/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0064/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0066/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0068/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0070/0004 | LOSS: 0.0130 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0072/0004 | LOSS: 0.0054 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0074/0004 | LOSS: 0.0110 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0076/0004 | LOSS: 0.0120 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0078/0004 | LOSS: 0.0091 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0080/0004 | LOSS: 0.0119 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0082/0004 | LOSS: 0.0100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0084/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0086/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0088/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0090/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0092/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0094/0004 | LOSS: 0.0002 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0004/0200 | BATCH 0096/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0100/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0104/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0106/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0108/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0110/0004 | LOSS: 0.0021 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0112/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0114/0004 | LOSS: 0.0174 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0116/0004 | LOSS: 0.0580 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0118/0004 | LOSS: 0.0353 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0120/0004 | LOSS: 0.0274 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0122/0004 | LOSS: 0.0222 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0170 |  ACC 0.0000\n",
      "\n",
      "Epoch: 5\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0000/0004 | LOSS: 0.4495 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0002/0004 | LOSS: 0.4428 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0006/0004 | LOSS: 0.1879 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0008/0004 | LOSS: 0.1257 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0010/0004 | LOSS: 0.0983 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0012/0004 | LOSS: 0.0389 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0014/0004 | LOSS: 0.0173 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0016/0004 | LOSS: 0.0108 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0018/0004 | LOSS: 0.0047 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0020/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0022/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0024/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0026/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0028/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0030/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0032/0004 | LOSS: 0.0109 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0034/0004 | LOSS: 0.0281 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0036/0004 | LOSS: 0.0455 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0038/0004 | LOSS: 0.0412 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0040/0004 | LOSS: 0.0232 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0042/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0044/0004 | LOSS: 0.0157 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0046/0004 | LOSS: 0.0119 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0048/0004 | LOSS: 0.0135 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0050/0004 | LOSS: 0.0058 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0052/0004 | LOSS: 0.0063 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0054/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0056/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0058/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0060/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0064/0004 | LOSS: 0.0022 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0066/0004 | LOSS: 0.0040 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0068/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0070/0004 | LOSS: 0.0147 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0072/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0074/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0076/0004 | LOSS: 0.0141 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0078/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0080/0004 | LOSS: 0.0142 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0082/0004 | LOSS: 0.0117 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0084/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0086/0004 | LOSS: 0.0039 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0088/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0090/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0094/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0096/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0098/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0102/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0104/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0106/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0108/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0110/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0112/0004 | LOSS: 0.0051 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0114/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0116/0004 | LOSS: 0.0578 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0118/0004 | LOSS: 0.0346 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0120/0004 | LOSS: 0.0273 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0122/0004 | LOSS: 0.0232 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | LOSS: 0.0359 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0188 |  ACC 0.0000\n",
      "\n",
      "Epoch: 6\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0000/0004 | LOSS: 0.4455 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0002/0004 | LOSS: 0.4380 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0004/0004 | LOSS: 0.4127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0006/0004 | LOSS: 0.1916 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0008/0004 | LOSS: 0.1331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0010/0004 | LOSS: 0.1071 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0012/0004 | LOSS: 0.0458 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0014/0004 | LOSS: 0.0232 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0016/0004 | LOSS: 0.0158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0018/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0020/0004 | LOSS: 0.0020 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0022/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0024/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0026/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0028/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0030/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0032/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0034/0004 | LOSS: 0.0241 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0036/0004 | LOSS: 0.0410 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0038/0004 | LOSS: 0.0375 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0040/0004 | LOSS: 0.0210 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0042/0004 | LOSS: 0.0165 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0044/0004 | LOSS: 0.0148 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0046/0004 | LOSS: 0.0113 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0048/0004 | LOSS: 0.0131 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0050/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0054/0004 | LOSS: 0.0072 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0056/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0058/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0060/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0064/0004 | LOSS: 0.0025 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0066/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0068/0004 | LOSS: 0.0061 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0070/0004 | LOSS: 0.0157 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0072/0004 | LOSS: 0.0071 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0074/0004 | LOSS: 0.0138 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0076/0004 | LOSS: 0.0150 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0078/0004 | LOSS: 0.0114 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0006/0200 | BATCH 0080/0004 | LOSS: 0.0151 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0082/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0084/0004 | LOSS: 0.0071 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0086/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0088/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0090/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0094/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0096/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0098/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0102/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0104/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0106/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0108/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0110/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0112/0004 | LOSS: 0.0049 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0114/0004 | LOSS: 0.0174 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0116/0004 | LOSS: 0.0581 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0118/0004 | LOSS: 0.0349 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0120/0004 | LOSS: 0.0279 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0122/0004 | LOSS: 0.0236 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | LOSS: 0.0362 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0195 |  ACC 0.0000\n",
      "\n",
      "Epoch: 7\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0000/0004 | LOSS: 0.4385 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0002/0004 | LOSS: 0.4321 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0004/0004 | LOSS: 0.4089 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0006/0004 | LOSS: 0.1915 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0008/0004 | LOSS: 0.1345 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0010/0004 | LOSS: 0.1097 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0012/0004 | LOSS: 0.0481 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0014/0004 | LOSS: 0.0252 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0016/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0018/0004 | LOSS: 0.0099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0020/0004 | LOSS: 0.0028 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0022/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0024/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0026/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0028/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0030/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0032/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0034/0004 | LOSS: 0.0222 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0036/0004 | LOSS: 0.0387 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0038/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0040/0004 | LOSS: 0.0198 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0042/0004 | LOSS: 0.0156 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0044/0004 | LOSS: 0.0141 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0046/0004 | LOSS: 0.0109 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0048/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0054/0004 | LOSS: 0.0073 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0056/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0058/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0060/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0064/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0066/0004 | LOSS: 0.0048 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0068/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0070/0004 | LOSS: 0.0162 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0072/0004 | LOSS: 0.0075 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0074/0004 | LOSS: 0.0143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0076/0004 | LOSS: 0.0155 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0078/0004 | LOSS: 0.0118 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0080/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0082/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0084/0004 | LOSS: 0.0072 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0086/0004 | LOSS: 0.0047 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0088/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0090/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0094/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0096/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0098/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0102/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0104/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0106/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0108/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0110/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0112/0004 | LOSS: 0.0049 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0114/0004 | LOSS: 0.0175 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0116/0004 | LOSS: 0.0580 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0118/0004 | LOSS: 0.0351 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0120/0004 | LOSS: 0.0279 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0122/0004 | LOSS: 0.0238 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0197 |  ACC 0.0000\n",
      "\n",
      "Epoch: 8\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0000/0004 | LOSS: 0.4335 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0002/0004 | LOSS: 0.4272 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0004/0004 | LOSS: 0.4062 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0006/0004 | LOSS: 0.1907 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0008/0004 | LOSS: 0.1348 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0010/0004 | LOSS: 0.1107 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0012/0004 | LOSS: 0.0491 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0014/0004 | LOSS: 0.0262 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0016/0004 | LOSS: 0.0187 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0018/0004 | LOSS: 0.0106 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0020/0004 | LOSS: 0.0032 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0022/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0024/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0026/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0028/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0030/0004 | LOSS: 0.0040 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0032/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0034/0004 | LOSS: 0.0210 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0036/0004 | LOSS: 0.0371 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0038/0004 | LOSS: 0.0333 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0040/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0042/0004 | LOSS: 0.0140 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0044/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0046/0004 | LOSS: 0.0096 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0048/0004 | LOSS: 0.0115 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0050/0004 | LOSS: 0.0048 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0052/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0054/0004 | LOSS: 0.0063 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0056/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0058/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0060/0004 | LOSS: 0.0003 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0008/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0064/0004 | LOSS: 0.0024 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0066/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0068/0004 | LOSS: 0.0059 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0070/0004 | LOSS: 0.0155 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0072/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0074/0004 | LOSS: 0.0140 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0076/0004 | LOSS: 0.0149 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0078/0004 | LOSS: 0.0115 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0080/0004 | LOSS: 0.0150 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0082/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0084/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0086/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0088/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0090/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0094/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0096/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0098/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0102/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0104/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0106/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0108/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0110/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0112/0004 | LOSS: 0.0051 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0114/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0116/0004 | LOSS: 0.0581 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0118/0004 | LOSS: 0.0347 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0120/0004 | LOSS: 0.0275 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0122/0004 | LOSS: 0.0229 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0187 |  ACC 0.0000\n",
      "\n",
      "Epoch: 9\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0000/0004 | LOSS: 0.4223 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0002/0004 | LOSS: 0.4027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0004/0004 | LOSS: 0.3724 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0006/0004 | LOSS: 0.1616 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0008/0004 | LOSS: 0.1057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0010/0004 | LOSS: 0.0806 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0012/0004 | LOSS: 0.0260 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0014/0004 | LOSS: 0.0071 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0016/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0018/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0020/0004 | LOSS: 0.0084 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0022/0004 | LOSS: 0.0061 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0024/0004 | LOSS: 0.0043 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0026/0004 | LOSS: 0.0012 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0028/0004 | LOSS: 0.0028 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0030/0004 | LOSS: 0.0035 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0032/0004 | LOSS: 0.0038 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0034/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0036/0004 | LOSS: 0.0187 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0038/0004 | LOSS: 0.0099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0040/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0042/0004 | LOSS: 0.0043 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0044/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0046/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0048/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0050/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0052/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0054/0004 | LOSS: 0.0024 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0056/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0058/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0060/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0062/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0064/0004 | LOSS: 0.0020 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0066/0004 | LOSS: 0.0042 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0068/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0070/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0072/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0074/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0076/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0078/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0080/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0082/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0084/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0086/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0088/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0090/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0092/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0094/0004 | LOSS: 0.0024 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0096/0004 | LOSS: 0.0049 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0098/0004 | LOSS: 0.0019 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0100/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0102/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0104/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0106/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0108/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0110/0004 | LOSS: 0.0021 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0112/0004 | LOSS: 0.0021 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0114/0004 | LOSS: 0.0310 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0116/0004 | LOSS: 0.0812 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0118/0004 | LOSS: 0.0329 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0120/0004 | LOSS: 0.0076 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0122/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | LOSS: 0.0288 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0122 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 10\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0000/0004 | LOSS: 0.7638 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0002/0004 | LOSS: 0.6813 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0004/0004 | LOSS: 0.5268 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0006/0004 | LOSS: 0.1853 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0008/0004 | LOSS: 0.0721 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0010/0004 | LOSS: 0.0258 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0012/0004 | LOSS: 0.0018 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0014/0004 | LOSS: 0.0083 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0016/0004 | LOSS: 0.0164 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0018/0004 | LOSS: 0.0233 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0020/0004 | LOSS: 0.0335 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0022/0004 | LOSS: 0.0301 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0024/0004 | LOSS: 0.0284 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0026/0004 | LOSS: 0.0209 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0028/0004 | LOSS: 0.0253 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0030/0004 | LOSS: 0.0280 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0032/0004 | LOSS: 0.0253 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0034/0004 | LOSS: 0.0430 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0036/0004 | LOSS: 0.0566 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0038/0004 | LOSS: 0.0448 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0040/0004 | LOSS: 0.0234 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0042/0004 | LOSS: 0.0161 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0010/0200 | BATCH 0044/0004 | LOSS: 0.0124 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0046/0004 | LOSS: 0.0087 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0048/0004 | LOSS: 0.0091 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0050/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0052/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0054/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0056/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0058/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0060/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0062/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0064/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0066/0004 | LOSS: 0.0024 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0068/0004 | LOSS: 0.0038 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0070/0004 | LOSS: 0.0123 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0072/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0074/0004 | LOSS: 0.0115 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0076/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0078/0004 | LOSS: 0.0100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0080/0004 | LOSS: 0.0137 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0082/0004 | LOSS: 0.0120 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0084/0004 | LOSS: 0.0068 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0086/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0088/0004 | LOSS: 0.0006 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0090/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0092/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0094/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0096/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0098/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0102/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0104/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0106/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0110/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0112/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0114/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0118/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0120/0004 | LOSS: 0.0284 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0122/0004 | LOSS: 0.0237 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | LOSS: 0.0458 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0193 |  ACC 0.0000\n",
      "\n",
      "Epoch: 11\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0000/0004 | LOSS: 0.4449 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0002/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0004/0004 | LOSS: 0.4115 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0006/0004 | LOSS: 0.1927 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0008/0004 | LOSS: 0.1357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0010/0004 | LOSS: 0.1113 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0012/0004 | LOSS: 0.0500 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0014/0004 | LOSS: 0.0270 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0016/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0018/0004 | LOSS: 0.0112 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0020/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0022/0004 | LOSS: 0.0021 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0024/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0026/0004 | LOSS: 0.0003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0028/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0030/0004 | LOSS: 0.0036 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0032/0004 | LOSS: 0.0058 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0034/0004 | LOSS: 0.0206 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0036/0004 | LOSS: 0.0367 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0038/0004 | LOSS: 0.0341 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0040/0004 | LOSS: 0.0189 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0042/0004 | LOSS: 0.0148 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0044/0004 | LOSS: 0.0136 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0050/0004 | LOSS: 0.0054 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0052/0004 | LOSS: 0.0063 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0054/0004 | LOSS: 0.0072 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0056/0004 | LOSS: 0.0009 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0058/0004 | LOSS: 0.0013 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0060/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0064/0004 | LOSS: 0.0028 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0066/0004 | LOSS: 0.0050 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0068/0004 | LOSS: 0.0067 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0070/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0072/0004 | LOSS: 0.0077 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0074/0004 | LOSS: 0.0149 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0076/0004 | LOSS: 0.0162 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0078/0004 | LOSS: 0.0122 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0080/0004 | LOSS: 0.0164 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0082/0004 | LOSS: 0.0139 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0084/0004 | LOSS: 0.0080 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0086/0004 | LOSS: 0.0054 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0088/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0090/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0092/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0094/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0096/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0110/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0112/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0114/0004 | LOSS: 0.0178 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0116/0004 | LOSS: 0.0589 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0118/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0120/0004 | LOSS: 0.0286 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0122/0004 | LOSS: 0.0244 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | LOSS: 0.0365 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0204 |  ACC 0.0000\n",
      "\n",
      "Epoch: 12\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0000/0004 | LOSS: 0.4388 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0002/0004 | LOSS: 0.4322 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0004/0004 | LOSS: 0.4108 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0008/0004 | LOSS: 0.1386 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0010/0004 | LOSS: 0.1145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0012/0004 | LOSS: 0.0518 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0014/0004 | LOSS: 0.0284 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0016/0004 | LOSS: 0.0208 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0018/0004 | LOSS: 0.0122 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0020/0004 | LOSS: 0.0041 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0022/0004 | LOSS: 0.0024 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0024/0004 | LOSS: 0.0006 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0012/0200 | BATCH 0026/0004 | LOSS: 0.0004 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0028/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0030/0004 | LOSS: 0.0033 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0032/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0034/0004 | LOSS: 0.0201 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0036/0004 | LOSS: 0.0365 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0038/0004 | LOSS: 0.0336 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0040/0004 | LOSS: 0.0183 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0042/0004 | LOSS: 0.0148 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0044/0004 | LOSS: 0.0137 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0048/0004 | LOSS: 0.0127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0052/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0064/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0066/0004 | LOSS: 0.0051 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0068/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0074/0004 | LOSS: 0.0150 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0076/0004 | LOSS: 0.0163 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0078/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0080/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0082/0004 | LOSS: 0.0142 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0084/0004 | LOSS: 0.0084 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0086/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0090/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0112/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0114/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0118/0004 | LOSS: 0.0357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0209 |  ACC 0.0000\n",
      "\n",
      "Epoch: 13\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0000/0004 | LOSS: 0.4366 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0002/0004 | LOSS: 0.4303 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0004/0004 | LOSS: 0.4110 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0008/0004 | LOSS: 0.1400 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0010/0004 | LOSS: 0.1161 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0016/0004 | LOSS: 0.0214 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0018/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0022/0004 | LOSS: 0.0026 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0024/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0030/0004 | LOSS: 0.0032 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0034/0004 | LOSS: 0.0199 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0036/0004 | LOSS: 0.0358 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0038/0004 | LOSS: 0.0332 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0040/0004 | LOSS: 0.0184 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0048/0004 | LOSS: 0.0124 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0062/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0064/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0068/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0070/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0072/0004 | LOSS: 0.0079 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0076/0004 | LOSS: 0.0165 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0078/0004 | LOSS: 0.0127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0080/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0082/0004 | LOSS: 0.0142 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0086/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0090/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0112/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0114/0004 | LOSS: 0.0178 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0122/0004 | LOSS: 0.0248 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0209 |  ACC 0.0000\n",
      "\n",
      "Epoch: 14\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0000/0004 | LOSS: 0.4361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0002/0004 | LOSS: 0.4304 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0004/0004 | LOSS: 0.4107 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0008/0004 | LOSS: 0.1392 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0014/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0012/0004 | LOSS: 0.0528 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0016/0004 | LOSS: 0.0218 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0022/0004 | LOSS: 0.0026 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0030/0004 | LOSS: 0.0032 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0032/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0034/0004 | LOSS: 0.0199 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0038/0004 | LOSS: 0.0333 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0040/0004 | LOSS: 0.0185 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0042/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0044/0004 | LOSS: 0.0134 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0050/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0064/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0068/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0080/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0082/0004 | LOSS: 0.0142 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0084/0004 | LOSS: 0.0084 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0086/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0088/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0094/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0112/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0114/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0120/0004 | LOSS: 0.0288 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0209 |  ACC 0.0000\n",
      "\n",
      "Epoch: 15\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0000/0004 | LOSS: 0.4363 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0004/0004 | LOSS: 0.4105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0020/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0032/0004 | LOSS: 0.0054 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0034/0004 | LOSS: 0.0200 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0044/0004 | LOSS: 0.0134 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0046/0004 | LOSS: 0.0103 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0052/0004 | LOSS: 0.0063 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0054/0004 | LOSS: 0.0073 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0064/0004 | LOSS: 0.0029 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0068/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0094/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0015/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0120/0004 | LOSS: 0.0289 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | LOSS: 0.0367 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 16\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0002/0004 | LOSS: 0.4299 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0004/0004 | LOSS: 0.4107 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0006/0004 | LOSS: 0.1953 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0010/0004 | LOSS: 0.1158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0012/0004 | LOSS: 0.0529 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0034/0004 | LOSS: 0.0198 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0036/0004 | LOSS: 0.0359 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0046/0004 | LOSS: 0.0103 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0054/0004 | LOSS: 0.0075 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0076/0004 | LOSS: 0.0165 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0082/0004 | LOSS: 0.0143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0084/0004 | LOSS: 0.0084 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0086/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0114/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0120/0004 | LOSS: 0.0289 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 17\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0000/0004 | LOSS: 0.4361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0002/0004 | LOSS: 0.4301 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0004/0004 | LOSS: 0.4104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0008/0004 | LOSS: 0.1394 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0010/0004 | LOSS: 0.1157 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0018/0004 | LOSS: 0.0127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0036/0004 | LOSS: 0.0357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0038/0004 | LOSS: 0.0332 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0040/0004 | LOSS: 0.0183 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0042/0004 | LOSS: 0.0147 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0074/0004 | LOSS: 0.0152 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0084/0004 | LOSS: 0.0084 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0017/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 18\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0002/0004 | LOSS: 0.4298 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0008/0004 | LOSS: 0.1398 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0022/0004 | LOSS: 0.0026 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0036/0004 | LOSS: 0.0357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0038/0004 | LOSS: 0.0332 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0062/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0082/0004 | LOSS: 0.0143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 19\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0000/0004 | LOSS: 0.4360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0002/0004 | LOSS: 0.4299 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0006/0004 | LOSS: 0.1954 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0008/0004 | LOSS: 0.1398 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0010/0004 | LOSS: 0.1158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0016/0004 | LOSS: 0.0215 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0034/0004 | LOSS: 0.0199 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0038/0004 | LOSS: 0.0332 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0044/0004 | LOSS: 0.0134 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0048/0004 | LOSS: 0.0124 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0019/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0112/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0114/0004 | LOSS: 0.0179 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 20\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0002/0004 | LOSS: 0.4297 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0004/0004 | LOSS: 0.4104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0008/0004 | LOSS: 0.1398 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0012/0004 | LOSS: 0.0529 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0014/0004 | LOSS: 0.0296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0016/0004 | LOSS: 0.0215 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0068/0004 | LOSS: 0.0069 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0112/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 21\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0000/0004 | LOSS: 0.4360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0010/0004 | LOSS: 0.1161 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0012/0004 | LOSS: 0.0529 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0034/0004 | LOSS: 0.0198 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0042/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0058/0004 | LOSS: 0.0015 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0021/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0082/0004 | LOSS: 0.0143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0116/0004 | LOSS: 0.0594 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 22\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0010/0004 | LOSS: 0.1162 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0036/0004 | LOSS: 0.0357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0044/0004 | LOSS: 0.0132 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0086/0004 | LOSS: 0.0058 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 23\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0000/0004 | LOSS: 0.4358 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0004/0004 | LOSS: 0.4098 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0012/0004 | LOSS: 0.0532 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0023/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0052/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0054/0004 | LOSS: 0.0075 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 24\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0002/0004 | LOSS: 0.4298 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0004/0004 | LOSS: 0.4103 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 25\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0002/0004 | LOSS: 0.4298 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0004/0004 | LOSS: 0.4103 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0025/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0044/0004 | LOSS: 0.0134 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0070/0004 | LOSS: 0.0170 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 26\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0000/0004 | LOSS: 0.4353 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0076/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0116/0004 | LOSS: 0.0591 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 27\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0004/0004 | LOSS: 0.4102 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0010/0004 | LOSS: 0.1161 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0027/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0076/0004 | LOSS: 0.0166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0122/0004 | LOSS: 0.0251 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 28\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0008/0004 | LOSS: 0.1394 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0012/0004 | LOSS: 0.0532 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0014/0004 | LOSS: 0.0296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0046/0004 | LOSS: 0.0105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0078/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0080/0004 | LOSS: 0.0168 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0028/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 29\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0002/0004 | LOSS: 0.4297 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0004/0004 | LOSS: 0.4102 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0032/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0116/0004 | LOSS: 0.0594 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 30\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0010/0004 | LOSS: 0.1161 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0030/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 31\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0002/0004 | LOSS: 0.4297 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0052/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 32\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0032/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 33\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0000/0004 | LOSS: 0.4353 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 34\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0040/0004 | LOSS: 0.0183 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0034/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 35\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0004/0004 | LOSS: 0.4098 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0052/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 36\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0036/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 37\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 38\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0004/0004 | LOSS: 0.4098 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0038/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 39\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0012/0004 | LOSS: 0.0532 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 40\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0000/0004 | LOSS: 0.4353 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0040/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0052/0004 | LOSS: 0.0065 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 41\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 42\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0042/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 43\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0002/0004 | LOSS: 0.4297 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0008/0004 | LOSS: 0.1395 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0010/0004 | LOSS: 0.1158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0043/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 44\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0000/0004 | LOSS: 0.4358 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0002/0004 | LOSS: 0.4299 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0008/0004 | LOSS: 0.1395 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0010/0004 | LOSS: 0.1158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0034/0004 | LOSS: 0.0197 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0042/0004 | LOSS: 0.0146 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 45\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0045/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 46\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 47\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0047/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0116/0004 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 48\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0008/0004 | LOSS: 0.1395 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0010/0004 | LOSS: 0.1158 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 49\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0049/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 50\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 51\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0051/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 52\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 53\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0053/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 54\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 55\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0055/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 56\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0056/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 57\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 58\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0058/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 59\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 60\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0060/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 61\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 62\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0062/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 63\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 64\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0064/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 65\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 66\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0066/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 67\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 68\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0068/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 69\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0000/0004 | LOSS: 0.4357 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0004/0004 | LOSS: 0.4101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0120/0004 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0210 |  ACC 0.0000\n",
      "\n",
      "Epoch: 70\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0000/0004 | LOSS: 0.4358 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0002/0004 | LOSS: 0.4303 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0070/0200 | BATCH 0006/0004 | LOSS: 0.1947 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0008/0004 | LOSS: 0.1394 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0010/0004 | LOSS: 0.1157 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0012/0004 | LOSS: 0.0529 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 71\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0071/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 72\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0002/0004 | LOSS: 0.4297 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 73\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0073/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 74\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 75\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0075/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 76\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 77\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0077/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 78\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 79\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0079/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 80\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 81\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0081/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 82\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 83\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0083/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 84\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0084/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 85\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 86\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0086/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 87\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 88\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0088/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 89\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 90\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0090/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 91\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 92\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0092/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 93\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 94\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0094/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 95\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 96\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0096/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 97\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | LOSS: 0.0366 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 98\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 99\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0099/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 100\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 101\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0101/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 102\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 103\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0103/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 104\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 105\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0105/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 106\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 107\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0107/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 108\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 109\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0109/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 110\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 111\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0111/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 112\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0112/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 113\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 114\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0114/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 115\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 116\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0116/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 117\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 118\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0118/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 119\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 120\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0120/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 121\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 122\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0122/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 123\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 124\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0124/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 125\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0125/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 126\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 127\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0127/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 128\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 129\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0129/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 130\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 131\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0131/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 132\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 133\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0133/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 134\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 135\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0135/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 136\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0116/0004 | LOSS: 0.0594 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0122/0004 | LOSS: 0.0249 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 137\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0000/0004 | LOSS: 0.4384 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0002/0004 | LOSS: 0.4298 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0004/0004 | LOSS: 0.4098 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0006/0004 | LOSS: 0.1952 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0008/0004 | LOSS: 0.1394 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0010/0004 | LOSS: 0.1157 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0012/0004 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0014/0004 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0016/0004 | LOSS: 0.0216 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0137/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0030/0004 | LOSS: 0.0031 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | LOSS: 0.0367 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 138\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 139\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0139/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 140\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0140/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 141\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 142\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0142/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 143\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 144\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0144/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 145\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 146\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0032/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0034/0004 | LOSS: 0.0195 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0146/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 147\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0096/0004 | LOSS: 0.0016 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 148\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0148/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0072/0004 | LOSS: 0.0081 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 149\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0008/0004 | LOSS: 0.1404 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0048/0004 | LOSS: 0.0126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 150\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0150/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0036/0004 | LOSS: 0.0356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 151\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0074/0004 | LOSS: 0.0153 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 152\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0152/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0040/0004 | LOSS: 0.0181 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0082/0004 | LOSS: 0.0144 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 153\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0000/0004 | LOSS: 0.4353 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0002/0004 | LOSS: 0.4294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0008/0004 | LOSS: 0.1400 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0153/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 154\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0004/0004 | LOSS: 0.4105 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 155\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0155/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 156\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 157\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0157/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 158\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 159\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0159/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 160\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 161\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0161/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 162\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 163\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0163/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 164\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0038/0004 | LOSS: 0.0331 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 165\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0165/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0062/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 166\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0050/0004 | LOSS: 0.0055 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0054/0004 | LOSS: 0.0075 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0070/0004 | LOSS: 0.0172 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0166/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 167\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 168\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0168/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 169\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 170\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0170/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 171\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 172\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0172/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 173\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0020/0004 | LOSS: 0.0046 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0118/0004 | LOSS: 0.0360 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 174\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0010/0004 | LOSS: 0.1159 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0174/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 175\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0014/0004 | LOSS: 0.0294 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 176\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0002/0004 | LOSS: 0.4293 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0176/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0066/0004 | LOSS: 0.0052 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0074/0004 | LOSS: 0.0155 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0116/0004 | LOSS: 0.0594 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 177\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0002/0004 | LOSS: 0.4296 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0006/0004 | LOSS: 0.1951 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 178\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0178/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 179\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | LOSS: 0.0366 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 180\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0018/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 181\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0181/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 182\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0008/0004 | LOSS: 0.1397 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 183\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0000/0004 | LOSS: 0.4355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0006/0004 | LOSS: 0.1949 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0183/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 184\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 185\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0185/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 186\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 187\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0187/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 188\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 189\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0189/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 190\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 191\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0000/0004 | LOSS: 0.4356 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0191/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 192\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 193\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0193/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 194\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0194/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 195\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0004/0004 | LOSS: 0.4100 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 196\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0196/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 197\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 198\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0198/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 199\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0084/0004 | LOSS: 0.0085 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 200\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0000/0004 | LOSS: 0.4354 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0002/0004 | LOSS: 0.4295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0004/0004 | LOSS: 0.4099 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0006/0004 | LOSS: 0.1950 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0008/0004 | LOSS: 0.1396 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0010/0004 | LOSS: 0.1160 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0012/0004 | LOSS: 0.0531 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0014/0004 | LOSS: 0.0295 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0016/0004 | LOSS: 0.0217 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0018/0004 | LOSS: 0.0128 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0020/0004 | LOSS: 0.0045 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0022/0004 | LOSS: 0.0027 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0024/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0026/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0028/0004 | LOSS: 0.0007 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0030/0004 | LOSS: 0.0030 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0032/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0034/0004 | LOSS: 0.0196 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0036/0004 | LOSS: 0.0355 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0038/0004 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0040/0004 | LOSS: 0.0182 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0042/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0044/0004 | LOSS: 0.0133 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0046/0004 | LOSS: 0.0104 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0048/0004 | LOSS: 0.0125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0050/0004 | LOSS: 0.0056 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0052/0004 | LOSS: 0.0064 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0054/0004 | LOSS: 0.0074 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0056/0004 | LOSS: 0.0010 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0058/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0060/0004 | LOSS: 0.0005 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0062/0004 | LOSS: 0.0000 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0064/0004 | LOSS: 0.0030 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0200/0200 | BATCH 0066/0004 | LOSS: 0.0053 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0068/0004 | LOSS: 0.0070 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0070/0004 | LOSS: 0.0171 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0072/0004 | LOSS: 0.0082 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0074/0004 | LOSS: 0.0154 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0076/0004 | LOSS: 0.0167 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0078/0004 | LOSS: 0.0129 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0080/0004 | LOSS: 0.0169 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0082/0004 | LOSS: 0.0145 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0084/0004 | LOSS: 0.0086 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0086/0004 | LOSS: 0.0057 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0088/0004 | LOSS: 0.0011 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0090/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0092/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0094/0004 | LOSS: 0.0008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0096/0004 | LOSS: 0.0017 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0098/0004 | LOSS: 0.0002 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0100/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0102/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0104/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0106/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0108/0004 | LOSS: 0.0001 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0110/0004 | LOSS: 0.0014 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0112/0004 | LOSS: 0.0044 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0114/0004 | LOSS: 0.0180 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0116/0004 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0118/0004 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0120/0004 | LOSS: 0.0291 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0122/0004 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | LOSS: 0.0366 |  ACC 0.0000\n",
      "TEST:  LOSS: 0.0211 |  ACC 0.0000\n",
      "2068.6506927013397\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + num_epoch):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(range(1, num_epoch+1), history['training_loss'], label='Training Loss')\n",
    "plt.plot(range(1, num_epoch+1), history['test_loss'], label='Validation Loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "pkl.dump(history, open(log_dir+'/history.pkl', 'wb'))\n",
    "\n",
    "\n",
    "if not os.path.isdir(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "torch.save(state, './%s/%s.pth' % (ckpt_dir, experiment_name))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16219343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader, batch_size, n_features, model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        values = []\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            model.eval()\n",
    "            yhat = model(x_test)\n",
    "            #batch_pred = []\n",
    "            #for i in range(batch_size):\n",
    "            #    batch_y_hat = yhat[i].detach().numpy()\n",
    "            #    batch_pred.append(batch_y_hat[-1][-1])\n",
    "            #batch_pred = array(batch_pred)\n",
    "            yhat = torch.flatten(yhat).detach().numpy()\n",
    "            \n",
    "            predictions.append(yhat)\n",
    "            values.append(y_test.to(device).detach().numpy())\n",
    "        #print(yhat.item())\n",
    "        #print('Len pred:/n', len(predictions))\n",
    "        #print('Len vals:/n', len(values))\n",
    "    return predictions, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4804754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, values =  evaluate(test_loader_one, batch_size=1, n_features=input_dim, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f0f626f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full, values_full = evaluate(test_loader, batch_size=batch_size, n_features=input_dim, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "765468ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def format_predictions(predictions, values, df_test, scaler):\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a7952ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-24</th>\n",
       "      <td>16.530001</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-25</th>\n",
       "      <td>16.470999</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>16.372999</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-29</th>\n",
       "      <td>16.524500</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>16.581499</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-15</th>\n",
       "      <td>20.083000</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-16</th>\n",
       "      <td>20.108999</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-17</th>\n",
       "      <td>20.012001</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-20</th>\n",
       "      <td>20.014999</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-21</th>\n",
       "      <td>20.150000</td>\n",
       "      <td>11.462741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                value  prediction\n",
       "Date                             \n",
       "2015-06-24  16.530001   11.462741\n",
       "2015-06-25  16.470999   11.462741\n",
       "2015-06-26  16.372999   11.462741\n",
       "2015-06-29  16.524500   11.462741\n",
       "2015-06-30  16.581499   11.462741\n",
       "...               ...         ...\n",
       "2020-07-15  20.083000   11.462741\n",
       "2020-07-16  20.108999   11.462741\n",
       "2020-07-17  20.012001   11.462741\n",
       "2020-07-20  20.014999   11.462741\n",
       "2020-07-21  20.150000   11.462741\n",
       "\n",
       "[1269 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = format_predictions(predictions, values, X_test, scaler)\n",
    "df_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cfd548de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a03b383a30>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABL/0lEQVR4nO3dd3hUVfrA8e+bEAgk9N6UonRCiKEJIkWKgqCgC+iqiICgqCu7rl1R9Le6YgNRFtaCLooKAiooTUCxgIA0Cb1JkU5CSM+c3x93ZpJJZiaTZGaSkPfzPPNw77ntnZA5uXPuOe8RYwxKKaVKj5CiDkAppVRwacWvlFKljFb8SilVymjFr5RSpYxW/EopVcqUKeoAfFGjRg3TqFGjog5DKaVKlI0bN542xtTMWV4iKv5GjRqxYcOGog5DKaVKFBE55K5cm3qUUqqU0YpfKaVKGa34lVKqlCkRbfzupKenc+TIEVJSUoo6FFXChYeH06BBA8LCwoo6FKWCosRW/EeOHKFixYo0atQIESnqcFQJZYzhzJkzHDlyhMaNGxd1OEoFRZ4Vv4jEAtcA9YBkYDuwwhhzNsCxeZWSkqKVvio0EaF69eqcOnWqqENRKmg8tvGLyEgR2QQ8DpQHdgEngW7AchGZLSKXeTm+oYisEpE4EfldRB6yl08SkaMistn+uqGgwWulr/xBf49UaePtjj8C6GqMSXa3UUSigSuBwx6OzwD+bozZJCIVgY0isty+7XVjzJQCxqyUUpeEJduO07lJdapFlA3qdT3e8RtjpgNpIvKwh+2bjTErvRx/3Bizyb58AYgD6hcy3mKjR48eLF261KXsjTfe4L777vN6TLAHoi1dupTo6Giio6OJjIykefPmREdHc+edd/p8jg8++IBjx4653fbLL7/QqVMnoqOjadmyJZMmTfJ6rs2bN7NkyZL8vAWlLkmnLqRy35xNjPtoY9Cv7bU7pzEmExhc2IuISCOgPbDOXjRBRLaKyHsiUtXDMWNFZIOIbCiO7a8jRoxg7ty5LmVz585lxIgRRRSRe/369WPz5s1s3ryZ2NhY5syZw+bNm/nwww99Poe3iv+uu+5i5syZbN68me3bt/OXv/zF67m04lfKkpqRCcDR824bVQLKl378P4rIWyJyjYjEOF6+XkBEIoH5wN+MMQnAO0BTIBo4Drzq7jhjzExjTKwxJrZmzVypJorcLbfcwtdff01qaioABw8e5NixY3Tr1o3x48cTGxtL69atefbZZ90eHxkZ6VyeN28eI0eOBODUqVMMHTqUDh060KFDB3788UcA1qxZ47xzb9++PRcuXChU/P/73//o2LEj0dHR3HvvvWRmZpKZmcnIkSNp06YNbdu25fXXX2fevHls2LCB22+/nejoaJKTXX9JT548Sd26dQEIDQ2lVatWAFy8eJFRo0bRoUMH2rdvz6JFi0hLS+OZZ57h008/JTo6mk8//bRQ70Gpksxms/49ej6Zl7/dGdRr+9Kd82r7v89nKzNAr7wOFJEwrEp/jjHmCwBjzIls22cBX/scrQfPffU7O44lFPY0LlrVq8SzN7b2uL169ep07NiRb7/9lsGDBzN37lyGDRuGiPDiiy9SrVo1MjMz6d27N1u3biUqKsqn6z700EM8/PDDdOvWjcOHD9OvXz/i4uKYMmUK06dPp2vXriQmJhIeHl7g9xYXF8enn37Kjz/+SFhYGPfddx9z5syhdevWHD16lO3btwNw/vx5qlSpwltvvcWUKVOIjY3Nda6HH36Y5s2b06NHD/r3789dd91FeHg4L774Ir169eK9997j/PnzdOzYkeuuu47nn3+eDRs28NZbbxU4fqUuBbZs096+s3ofj/ZvEbRr51nxG2N6FuTEYnWVeBeIM8a8lq28rjHmuH31ZqzuoSWSo7nHUfG/9957AHz22WfMnDmTjIwMjh8/zo4dO3yu+FesWMGOHTuc6wkJCVy4cIGuXbsyceJEbr/9doYMGUKDBg0KHPfKlSvZuHEjHTp0ACA5OZlatWpx4403sn//fh544AEGDBhA37598zzXM888w+23386yZcv4+OOP+eSTT1i9ejXLli3jyy+/ZMoU6xl+SkoKhw976gegVOljK8L5zn0awCUiA4DWgPM20xjzvOcjAOgK3AFsE5HN9rIngBH2HkEGOAjcm6+I3fB2Zx5IN910ExMnTmTTpk0kJycTExPDgQMHmDJlCr/++itVq1Zl5MiRbkcXZ+9CmH27zWbj559/pnz58i77P/bYYwwYMIAlS5bQuXNnVqxYQYsWWXcI06dPZ9asWQAsWbKEevXqeYzbGMNdd93Fv/71r1zbtmzZwtKlS5k+fTqfffaZ84+ZN02bNmX8+PGMGTOGmjVrcubMGYwxzJ8/n+bNm7vsu27dOg9nUap0KcqKP882fhGZAQwDHgAEuBW4PK/jjDFrjTFijIkyxkTbX0uMMXcYY9raywdlu/svcSIjI+nRowejRo1yPtRNSEggIiKCypUrc+LECb755hu3x9auXZu4uDhsNhsLFixwlvft29elGWTz5s0A7Nu3j7Zt2/Loo48SGxvLzp2ubYL333+/8yGut0ofoHfv3sybN4+TJ08CcPbsWQ4dOsTp06ex2WwMHTqUyZMns2nTJgAqVqzo8ZnC4sWLMfZf4D179hAaGkqVKlXo168f06ZNc2777bff8jyXUqWJrejqfZ8e7l5tjLkTOGeMeQ7oAjQMbFglx4gRI9iyZQvDhw8HoF27drRv357WrVszatQounbt6va4l156iYEDB9KrVy/nw1GAqVOnsmHDBqKiomjVqhUzZswArK6ibdq0oV27dpQvX57rr7++wDG3atWKF154gb59+xIVFUWfPn04fvw4R48epUePHkRHRzNy5EjnN4KRI0cybtw4tw93P/roI2cX0TvuuIM5c+YQGhrK008/TXp6OlFRUbRp04ann34agJ49e7Jjxw59uKtKvcwcNf++U4lBu7aYPL5uiMg6Y0wnEfkFGAKcAbYbY64MRoAAsbGxJmf/97i4OFq2bBmsENQlTn+fVLBtPxrPwGlrnetv3daegVHev63nl4hsNMbk6pXhSxv/1yJSBXgF2ITVNv9fv0anlFKlTM577ozM4LX9+NKrZ7J9cb6IfA2EG2PiAxuWUkpd2jJz1PxlQoOXM8pjxS8iQ7xsw9EvXymlVP7l7NVToWxo0K7t7Y7/Ri/bDKAVv1JKFVBez1cDyWPFb4y5O5iBKKVUaZJp874eSN6aeiZ6OzD7aFyllFL5k7OpJ5gDurz146+Yx6vUCw0NJTo6mjZt2nDrrbeSlJRU4HONHDmSefPmATB69GiXtA05rV69mp9++sm5PmPGjHxl2wyWbdu2ORPLVatWjcaNGxMdHc11113n8zkWLlzo9Wfhq4MHD/Lxxx8X+jxK+UvOij5nv/5A8tbU81zQoiihypcv7xxZe/vttzNjxgwmTsz6opSZmUloaP4f2Pz3v957y65evZrIyEiuvtrKnzdu3Lh8XyMY2rZt6/z5jBw5koEDB3LLLbfk6xwLFy5k4MCBzqyfBeWo+G+77bZCnUcpf7HlaNpJD2Jbjy8pGxqIyAIROSkiJ0RkvogUPEPYJeqaa65h7969rF69mp49e3LbbbfRtm1bMjMzeeSRR+jQoQNRUVH85z//AawHOxMmTKBVq1YMGDDAmT4BXCds+fbbb4mJiaFdu3b07t2bgwcPMmPGDF5//XWio6P54YcfmDRpkjMZ2ubNm+ncuTNRUVHcfPPNnDt3znnORx99lI4dO9KsWTN++OEHn9+bzWajUaNGnD9/3ll2xRVXcOLECT7//HPniOLu3bv7dL5ly5bRpUsXYmJiuPXWW0lMtEYsPvbYY7Rq1YqoqCj+8Y9/8NNPP/Hll1/yyCOPEB0dzb59+1zO4+7ann7ejz32GD/88APR0dG8/vrrPr93pQIlI0fNv/7AWfaeDM7oXV8GcL0PfIyVowfgr/ayPoEKKt++eQz+3Obfc9ZpC9e/5NOuGRkZfPPNN/Tv3x+A9evXs337dho3bszMmTOpXLkyv/76K6mpqXTt2pW+ffvy22+/sWvXLrZt28aJEydo1aoVo0aNcjnvqVOnGDNmDN9//z2NGzfm7NmzVKtWjXHjxhEZGck//vEPwMq26XDnnXcybdo0rr32Wp555hmee+453njjDWec69evZ8mSJTz33HOsWLHCp/cXEhLC4MGDWbBgAXfffTfr1q2jUaNG1K5dm+eff56lS5dSv359lz8Mnpw+fZoXXniBFStWEBERwcsvv8xrr73GhAkTWLBgATt37kREnCmhBw0a5PGbgrtrv/vuu25/3i+99BJTpkzh668LnQVcKb9wNPV0blKNX/afZc66w8xZd5iDLw0I+LV9ydVT0xjzvjEmw/76ACh+M6MUgeTkZKKjo4mNjeWyyy7jnnvuAaBjx440btwYsO5uP/zwQ6Kjo+nUqRNnzpxhz549fP/994wYMYLQ0FDq1atHr165pzf45Zdf6N69u/Nc1apV8xpPfHw858+f59prrwWs2bG+//575/YhQ6yhGVdddRUHDx7M13sdNmyYM7eOY+4BgK5duzJy5EhmzZpFZmZmnuf55Zdf2LFjB127diU6OprZs2dz6NAhKlWqRHh4OKNHj+aLL76gQoUKeZ7L3bU9/byVKm4cLTtjuzcJ+rV9ueM/LSJ/BT6xr4/AytdTfPh4Z+5v2dv4s4uIiHAuG2OYNm0a/fr1c9lnyZIlLqmZ3THG5LlPfpQrVw6wHkpnZGTk2v7kk0+yePFigFzvq0uXLuzdu5dTp06xcOFCnnrqKcB6sLxu3ToWL15MdHQ0mzdvpnr16h5jMMbQp08fPvnkk1zb1q9fz8qVK5k7dy5vvfUW3333ndf34+7ann7eq1ev9noupYIt097UE14meAO3HHy54x8F/AX4E2uqxFvsZcoH/fr145133iE9PR2A3bt3c/HiRbp3787cuXPJzMzk+PHjrFq1KtexXbp0Yc2aNRw4cACw0ieD59TGlStXpmrVqs72+48++sh59++LF1980ZnaOScR4eabb2bixIm0bNnSWbnv27ePTp068fzzz1OjRg3++OMPr9fo3LkzP/74I3v37gUgKSmJ3bt3k5iYSHx8PDfccANvvPGGMwZvaZzdXdvTz1vTQavixnHHX6Gc6/331f9a6WZv//IlV89hYFDAI7lEjR49moMHDxITE4Mxhpo1a7Jw4UJuvvlmvvvuO9q2bUuzZs3cVtA1a9Zk5syZDBkyBJvNRq1atVi+fDk33ngjt9xyC4sWLWLatGkux8yePZtx48aRlJREkyZNeP/99/32XoYNG0aHDh344IMPnGWPPPIIe/bswRhD7969adeunddz1KxZkw8++IARI0Y45yt+4YUXqFixIoMHDyYlJQVjjPMB7PDhwxkzZgxTp05l3rx5NG3a1Ou1o6Ki3P68o6KiKFOmDO3atWPkyJE8/PDDfvu5KFUQjlw9ETlSNRyLzz1xk795TcssIj2xJmBxTKMUB7xljFkd8Miy0bTMKtD090kF24LfjvDwp1tY9Y8e9Jyy2mVbuTIhzLwzlmubFe5xqqe0zB6beuzTLb4HfAXcBtwOLAHeE5EbChWNUkqVco6mnjIhuZ/jpWbYeHPF7oBd21tTzyPATcaYLdnKNovIBmAa1h8BpZRSBWCzj9QNcVPxg5UJM1C8Pdytk6PSt4IxZitQO3AhKaXUpS/DXvGH+rHnnq+8VfwXC7hNKaVUHhwPd0M93PEHMnWPt6aepiLypZtyAYI/4kAppQohMTWDBZuO8NfOl/t1fExBOZp6PFb8Aaz5vVX8g71sm+LvQJRSKpDaPLsUgFqVwunXuk4RR+O+qWfmHVcx9qONQGCzdXps6jHGrPH2ClhEJUSPHj1YunSpS9kbb7zBfffd5/WYnN1SA+3ixYtUr16d+HjXaZJvuukmPvvsM4/HRUZGAnDs2DGPGTV9eT9vvPGGS7rqG264waecPnnZtWsXPXr0IDo6mpYtWzJ27Fiv+2taZuVw9mJaUYcAZLvjzzbXbu+WWY9Pi6TiV96NGDGCuXPnupTNnTuXESNGFFFE7kVERNC3b18WLlzoLIuPj2ft2rUMHDgwz+Pr1avnnCegIHJW/EuWLKFKlSoFPp/Dgw8+yMMPP8zmzZuJi4vjgQce8Lq/VvzKoSgeprrjbOPPFk/2Zp/E1NxpVfxFK/4CuuWWW/j666+do08PHjzIsWPH6NatG+PHjyc2NpbWrVvz7LPPuj3ecUcNMG/ePEaOHAlYGTmHDh1Khw4d6NChAz/++CMAa9ascU5q0r59+3ylH8j5R2rBggX0798fm81G7969iYmJoW3btixatCjXsQcPHqRNmzaAlZRu+PDhREVFMWzYMJKTk537uXvPU6dO5dixY/Ts2ZOePXsC0KhRI06fPg3Aa6+9Rps2bWjTpo0zg+jBgwdp2bIlY8aMoXXr1vTt29flOg7Hjx+nQYOs7OBt27YFNC2zylv1yLJFHQKQdUcfEgL1Kofn2n70fDInEwIziteXJG1OIlIVOG+KcpZgN15e/zI7z+706zlbVGvBox0f9bi9evXqdOzYkW+//ZbBgwc7M1aKCC+++CLVqlUjMzOT3r17s3XrVqKiony67kMPPcTDDz9Mt27dOHz4MP369SMuLo4pU6Ywffp0unbtSmJiIuHhuX9RPOnfvz+jR4/mzJkzVK9enblz5/LAAw8QHh7OggULqFSpEqdPn6Zz584MGjTI44Ovd955hwoVKrB161a2bt1KTEyMc5u79/zggw/y2muvsWrVKmrUqOFyro0bN/L++++zbt06jDF06tSJa6+9lqpVq7Jnzx4++eQTZs2axV/+8hfmz5/PX//6V5fjH374YXr16sXVV19N3759ufvuu6lSpYqmZVZ5KlcESdHccVT8ZUJCWP1Iz1z5+QFGvv8rSx66xu/X9jZy9xkRaWFfLiciq4B9wAkR8X3uvEtY9jvp7M08n332GTExMbRv357ff/89X1MHrlixggkTJhAdHc2gQYNISEjgwoULdO3alYkTJzJ16lTOnz9PmTK+/80uW7YsgwYNYt68eZw+fZrNmzfTt29fjDE88cQTREVFcd1113H06FFOnDjh8Tzff/+9swKOiopy+WOW3/e8du1abr75ZiIiIoiMjGTIkCHO5HKOKRrBcwrpu+++m7i4OG699VZWr15N586dSU1N1bTMKk/H43N/gywKzjt+gbJlQqhQNvdnOlCxeqs9hgGT7ct32f+tCTQDZgO+zeIRBN7uzAPppptuYuLEiWzatInk5GRiYmI4cOAAU6ZM4ddff6Vq1aqMHDmSlJTcX9ey31Vn326z2fj5558pX768y/6PPfYYAwYMYMmSJXTu3JkVK1bQokUL5/bp06cza9YswGpHr1evnsvxI0aM4IUXXsAYw+DBgwkLC+ODDz7g1KlTbNy4kbCwMBo1auQ2Vk9xO/j6nrPz9qXRkT4arBTS7pp6wHr+MGrUKEaNGkWbNm3Yvn27pmVWHoWI1Tc+NSN4Uxx6k2kzhIj7z1T2fQLBWxt/WrYmnX7AXGNMpjEmjnw2EV2qIiMj6dGjB6NGjXLe7SckJBAREUHlypU5ceIE33zzjdtja9euTVxcHDabjQULFjjL+/bty1tvveVcd6Qn3rdvH23btuXRRx8lNjaWnTtdm7buv/9+Z0rlnJU+QM+ePdmzZw/Tp093xhofH0+tWrUICwtj1apVHDp0yOv77d69O3PmzAFg+/btbN26Nc/37Ckdcvfu3Vm4cCFJSUlcvHiRBQsWcM01vn+l/fbbb52pl//880/OnDlD/fr1NS2z8uiyatbkPjknOS8qmcZQJiR3FVy7UtaNT0JKYB7weqv4U0WkjYjUBHoCy7Jty3t6pFJixIgRbNmyheHDhwPQrl072rdvT+vWrRk1ahRdu3Z1e9xLL73EwIED6dWrF3Xr1nWWT506lQ0bNhAVFUWrVq2YMWMGYPWOccwvW758ea6//vp8xRkSEsLQoUM5c+aMc37a22+/nQ0bNhAbG8ucOXNcvkG4M378eBITE4mKiuLf//43HTt2zPM9jx07luuvv975cNchJiaGkSNH0rFjRzp16sTo0aNp3769z+9n2bJlzp9Hv379eOWVV6hTpw6jR4+mVatWxMTE0KZNG+69914yMjJc0jLrw93SLZDdJPPDZjO4qfe5olZk7kI/85iWWUQ6Ax9gNe+8YYyZbC+/AbjDGBO0fouallkFmv4+Xbq2H41n4LS1zvUGVcuz9tHcU50G2+SvdzB3/WF+f76/S/mFlHSeXLCdL7cco2J4GbZN6ufhDHnLd1pmY8wvxpgWxpjqjkrfXr4kmJW+UkoVxjfbj7usHzlXsAemxhgW/naUCynp/giLTJtxm66hYngYU0dY3377B2iEsce2ehGZmKPIAKeBtcaYAwGJRiml/MxfTfq/H0vgb59uZkTHhvxrSFS28nha1KnkMeeOJzbjvuJ3aFC1POmZgXkQ7a2Nv2KOVyUgFvhGRIYHJBqllPIzd036BRmKdC7JSvXwx9msbww/7TvNgKlrafpE/qcnyfBwx+9w5FwyCzcfy/d5feHxjt8Y85y7chGphtWVc6677UopVZykZmTmKtt7MpEra1fM13kcd99r9552lt02a12B47LlUfEHUr5TNhhjzmKlZvZKRBqKyCoRiROR30XkIXt5NRFZLiJ77P9WLUDcSinlE3fpjQvSseeCvWulv1L9ZNiM17xB7qZk9Jd8V/wi0gs458OuGcDfjTEtgc7A/SLSCngMWGmMuRJYaV9XSqmAqFM5azDkuGubAtZgrvxyVPyeWok8NR/FJ6czf+ORXOVWd07PgXS70kpzsmb3qXxGmjdvKRu2icjWHK8jwEuA59zDdsaY48aYTfblC0AcUB8rz/9s+26zgZsK+R6KRElJy7x06VJncrfIyEiaN29OdHQ0d955p0/Hz5gxgw8//NDrPhs2bODBBx/0R7iabln5XeMa1rCjL+67mvaXVQHgXFL+e+ZcyGMwlacRwU98sY2/f76F34+5pka3BnB5rvhrVbQGcp2I93+iNm8jcHPm7DXAGWNMvqddFJFGQHtgHVDbGHMcrD8OIlLLwzFjgbEAl112WX4vGXCOPD3ZUwPMnTuXV155pQijyq1fv37OGHv06MGUKVOIjXXt1puZmUloqPvEVePGjcvzGrGxsbnOWVCOdMuDB1vzAG3bts3r/o6K/7bbbvPL9dWlJSElncRUq40/omwZdl+0Rm/f//Emfn3S95Rjxhhe/tZ7IsjTiak0qJp7bOsf56y05Cnprn8YMvK447+zSyM2HjpHpybVfI7TV9768R/K8TpcwEo/EpgP/M0Yk+DrccaYmcaYWGNMbM2aNfN72YArSWmZ3WnUqBHPP/883bp14/PPP2fWrFl06NCBdu3aMXToUGcO/UmTJjFlijXhWo8ePXj00Ufp2LEjzZo1cyZVW716tTO3/6RJkxg1ahQ9evSgSZMmTJ061XnNyZMn06JFC/r06cOIESOc581O0y0rf4qatIx/fL4FsJp30uwPaE9dSM3z2OxNN77k9zmZ45w/7zuDzWbYesS60/92+3GXc9ryaONvU78yK//eg8urR+R57fwKaM4dEQnDqvTnGGO+sBefEJG69rv9usDJwl7nz//7P1Lj/JuWuVzLFtR54gmP20tSWmZPwsPDWbvWGtF45swZxowZA8BTTz3Fu+++63Zyk4yMDNavX8+SJUt47rnnWLEid66+nTt3smrVKi5cuEDz5s0ZP348W7ZsYf78+fz2229kZGQQExPDVVddletYTbesAkVEqFrBt1z8L3+7k/fWHmDXC1ZqlKS03D2DckrOts+KHScY/eEG2tav7Cyb9cMB+rWuQ2wj6w7+m+1/5id8vwrYRCxipZx7F4gzxryWbdOXZGX7vAvIPftHCVFS0jJ7MmzYMOfy9u3bueaaa2jbti1z5szh999/d3vMkCFDAM/pkgEGDBhAuXLlqFGjBrVq1eLEiROsXbuWwYMHU758eSpWrMiNN97o9lhNt6z8JWdOnhCBgVF1Pezt6p3V+0jNsJGSblXmi7cdd7tfuTIhXGN/CLv1SDzPffU7CSnp7DphfSPfdtS1XX/lzpNuH/QGW561h4hEAMnGGJuINANaAN8YY/J6OtIVuAPYJiKb7WVPYD0c/kxE7gEOA7cWNHgHb3fmgVSS0jK7ExGR9RVy5MiRLFy4kHbt2vHBBx94TGPsSJkcGhpKRob7h1050ypnZGTka8CMpltW/pBzYpPQEPGaAtmd5LRMwsNCeXPFbpfy+OR04pPSSc2wEWHPo//J+sMcPpuEMXDV5e57qb+zeh8AN7Wvn684/M2XO/7vgXARqY/V/fJurORtXhlj1hpjxBgTZYyJtr+WGGPOGGN6G2OutP97tnBvoeiUpLTMeblw4QJ169YlPT3dmXrZn7p168ZXX31FSkoKiYmJLF682O1+mm5Z+UvuO36r0m9S0/c2c8e8tzn7/d84bS3dX1kFwI/7rAFdh89az8U++Okg1SOsJqVyZdxXsQnJ/sn3U1C+VPxijEkChgDTjDE3A60CG1bJUVLSMudl8uTJdOrUiT59+uSZnrkgOnTowKBBg2jXrh1DhgwhNjaWypUr59pP0y2r/Dp3Mc1tTpuMHLW142b/mitqUKVCmMfzvbkiqwnx30t3AdDQnsu/QVXrm7ijkgeYPLhNrnPc9l9rRK+nh8KO9A9FxWNaZucOIr9h9dt/HbjHGPO7iGwzxrQNRoCgaZkvFYmJiURGRpKUlET37t2ZOXOmy7y9RUl/n0omYwyNH1/CTdH1eGO4ldFyxY4TfPTLIZ69sRW9Xl3j3Penx3pRr0p5nl20ndk/W5MOvXVbewZGZX1DbvSY6zfRsd2b8MQNLZm2cg+vLt9Nk5oR7D/l2rnx3btiuWe29/E5n4zpzIhZvzjX54+/mqHv/MRdXS7nOTd/OPwl32mZs3kIeBxYYK/0mwCr/B2guvSNHTuW6OhoYmJiGDp0aLGp9FXJlZ5p3bgu2pKVzGz0hxtYs/sU8TmaUxxNPY5KH2DCx795PX9D+x3+f77fD5Cr0gd8yrdzOtG1q+f+U4kAfPHb0TyPDQRfuoZcMMYMcqwYY/YD/hmmqUoVHWGr/M3RL99dw8XNb//ksu6Y7eqOzpfz0S9ZlX96po2wUPf3wP9euosuTWs42/of6n0lb6507U3my4xezetUZMF9V7Nq1ymmrtzDI/OsaUtv73R5nscGgi93/K+JyE4RmSwirQMeUT4UJLWqUjnp71HJlZ6PidMF9w93D53xPC71QkoG172W1VzkrlNQeqbhywld+Wtn1wwDn47tDMA/+zenWe2KtL+sKg/0usJln6b5eNDsT3lW/MaYnkAP4BQw057D56lAB5aX8PBwzpw5ox9aVSjGGM6cOeOXAXEq+HI+1PX17ju7Xw/6knPS4m4cQOt6lYhqUIUXbmrLT49lTenYqUl1Dr40gPt6ZFX2Ob9ZXEwNzGTqefFpFJAx5k9gqoisAv4JPAO8EMjA8tKgQQOOHDnCqVP+z1ynSpfw8HCXNBGq5Hhy4XaX9Rlr9nnc12D9UWhVt5JL+eNfbGNER+tuvVpEWc5e9Nzj5oparn80+rWu7ezxA1CvSnnWPtqTSuU99xo68K8baPy4NXFLQh6J3wLFlwFcLYFhwC3AGawJWP4e4LjyFBYWRuPGjYs6DKVUEVq+44TL+iv27pdu2b8MVPGStiHZS2qGMde41jebn+nj9lzuErVlJyJ8OrYzf313HTcX0UAuX9r438fKv9/XGHOtMeYdY0yh8+sopVQwVQzPugv/ckJXhsRkVbp/nE3CGENKRiZ3dbmc+eOvznW8o5nm/bs70LlJNSLLFTxtSqcm1dnz4g0u3xaCyZc2/s7GmDeNMYGZ/FEppQJo09N9OPjSAMqXzUo9HtWgCq/9Jdq5fs2/V3EuKR1joEK5Mlx1eVUW3d+Vsd2bOPdx5N3p2bwWc8d2oYyHnkAlQcmNXCmlsnE3ehesdntfrNltNWQ4Jkdp17AKT9yQNajvoJfePyWNVvxKqRKrbLa77p/2nXEuzxvXJd/nOnwmGSBXu/sdna2+9hXLeX5gW9LkWfGLSODGEyulVCGkZbvLv+u99c5lR87769vU8flcr9szcEaGu7bdT7D3vb+mWY0Cx1nc+PJ0YoaIlMXKyPmxMeZ8QCNSSikfeOqz//RAK4fkpqf75PkAdmKfZry23DXlsiPNskPtSuH88M+e1K186Yz18OXhbjfgdqAhsEFEPhaRPgGPTCmlvEhKc98HvoV9gFa1iLKU9ZAW2eHB3lfmytRZPiz3/NMNq1Uo0Q9zc/LpnRhj9gBPAY8C12IN5topIkMCGZxSSnnimA5x0o2uWeLDw/JXQZ9PypHMzYekayWdLwO4orAmXxkALAduNMZsEpF6wM/AF96OV0qpQHBU/JVz3LGHu7lj98Wj/Vsw+prSMSjUlzb+t4BZwBPGmGRHoTHmWHHI2aOUKp3e+m4vAOFlXCt6d0013qz8+7V8ufkY465tku+pGUsqXyr+G7Dm3M0EEJEQINwYk2SM+Sig0SmllAfzN1mTlq/e5ZqvK793/E1rRvJwn2Z+i6sk8KUxbAWQfebvCvYypZQqcte3rcO4a5s613P2ylG5+fITCjfGJDpWjDGJIlI0CSaUUiqHHs1r0aN5Lf7etxknElJytfmr3Hy5478oIs458kTkKiDZy/5KKRVQ591MVh4WGpJnZkxl8eWO/2/A5yLiSNJWFytNs1JKFYno55cDcH/PpnnsqdzxZQDXr0ALYDxwH9DSGLMx0IEppVReFm3WpMEF4etTkA5AI/v+7UUEY8yHAYtKKaU8SEnPmiwltBQMtgoEXwZwfQQ0BTYDjp+4AbTiV0oF3YVs0xU+fn1LL3sqT3y5448FWhmd1VwpVQxUyDahSvdLKGNmMPlS8W8H6gDHAxyLUkrlKaJcGf41pC3XXFmDCtpnv0B8+anVAHaIyHog1VFojBkUsKiUUsqLER0vK+oQSjRfKv5JgQ5CKaVU8ORZ8Rtj1ojI5cCVxpgV9lG7BUt/p5RSqsj5MvXiGGAe8B97UX1gYQBjUkopFUC+pGy4H+gKJIBzUpZagQxKKaU8+e7wd7zy6ytFHUaJ5kvFn2qMcSbGEJEyWP34lVIqKPaf3899K+5j9R+reWjVQ3y4Q4cRFYYvD3fXiMgTQHn7XLv3AV8FNiylSrf0kycpU6UKUrZsUYdSLNy99G7Oppzlh6M/OMtsxkaIXDrz4AaTLz+1R4FTwDbgXmAJ1vy7SqkAMMawt/u17IxqV9ShFBtnU87mKvt6/9dFEMmlwWvFb59ta5sxZpYx5lZjzC325TybekTkPRE5KSLbs5VNEpGjIrLZ/rrBD+9BqUtLRkbe+5Qyt7e8PVfZp7s+LYJILg1eK35jjA3YIiIFGS3xAdDfTfnrxpho+2tJAc6r1CXN2GxFHUKxYjM25sTNcSmLDIvkw/7azl9QvrTx1wV+t4/cvegozGvkrjHmexFpVLjwlCp9TFruSUZKqwxbBhNWTshVfkerOwgN0eFEBeVLxf+cn685QUTuBDYAfzfGnHO3k4iMBcYCXHaZDs9WpUfm2dzt2aXVO1ve4cdjP+YqH9BkQBFEc+nwWvHb2/inG2Pa+Ol67wCTsbqDTgZeBUa529EYMxOYCRAbG6vdR1WpkZlwoahDKBaMMczcOjNX+dY7tyKiefgLw2vFb4yxicgWEbnMGHO4sBczxpxwLIvILEAfyyuVQ8aJP4s6hGIhMT3RZX1qz6kcvnBYK30/CFgbvzsiUtcY40jvfDNWymelVDZHJjxQ1CEUC4lprhV/z8t6FlEkl56AtfGLyCdAD6CGiBwBngV6iEg0VlPPQaxxAUoplUtCWoJzuU5EnSKM5NLjU3bOgpzYGDPCTfG7BTmXUqVVwrJlVOrbt6jDAGDCygl0qtuJO1rdEZTrLT6wGIB+jfox5dopQblmaeFLds4LIpJgf6WISKaIJOR1nFKq8I4//kTQr/nU2qeYumlqrvI1R9bw71//HbQ42tWwRi4Pbz48aNcsLXy546+YfV1EbgI6BiogpUqzU9PeclmveF3voMewaN8iAB6MeTDo184uNdOa8K96+epFGselKN8ZjowxC4Fe/g9FKXV6+nSX9bCGRTeGZfvprL4Xf17M6mnkQ8YWv7iYYfUlqVCmQlCuV5r40tQzJNvrFhF5CU3LrJRfZSYkENeiZa7ys++/jy011c0R/vf31X+n7ey2zvURi7Me0/14NGsQ1cc7Pw5KPEnpSQBEhEUE5XqliS93/Ddme/UDLgCDAxmUUqVN+pEjLuvN1v0CgO3iRQ7fPYqTU6Zwbu7cgMaw7NAyj9sW7l3oXN5yaktA43CIT40nVEK14g8AX9r47w5GIEqVZjnz84RWruxcTtm5k+RNmwCo2K8fZz/8kOqjRhFa0eXxW0AkpSdRIawCO87scJZ9c+Ab7mlzD82rNQ/otbef3k5k2UgdsBUAHu/4ReTfIjLOTfnDIvJyYMNSqvSwpaZycLi73s8Wk5TkXN7T5WrOvDODxFWrghEam09uBmBkm5Eu5YW9609ISyA5I9nj9raz2/Lz8Z+JT40v1HWUe96aegZiz5WTw5uAZkhSyk9s2Sp2X6UdKnQGFd+uY7O+ieTMmXMm+UyeD3n3n9/P6eTT7Dizg8X7FzvLM2wZdP2kKx3nuO8c+OxPzzqXw0PDCxq68sJbU4+x5+PPWWgT/e6llP9kZub7kNPTpxPR9WoqxMQEICAr++Xi/YvJsLmfFObtLW9TJbwKI1p4/qYyeNFgyoSUcZ7DkVHzt5O/Off5/fTvtK7R2rkenxrPF3u+cK7/OCJ3Zk5VeN7u+JNE5MqchfYyz9/RlFL5YjILNvHK+fnzybBlsO74OrfbUzNTybTl/48KwNiosQAciD/gbO6pWq6qyz5L9i/hlV9f8TqoK/sfjraz29J9bneX/PrDFw/nYrrVbTPuTBzd5nZzbvt+2PeUDdU5hwPBW8X/DPCNiIwUkbb2193AYvs2pZQfnPvfRy7r1Uff49Nx8fO/YM6Slxi9bDS//vkrAH/56i/8d9t/OZRwiNj/xTLhu9yTmPiiTgUrN06GLYM7vrFSNJxLdZ064/jF43y440M+2vFRruM9OZd6jqQM16atzh935ocjP+Q6T9Vw1z80yn88VvzGmG+Am4CeWNMofoCVdG2oTpmolP+cmfVfl/Vq9/hW8QN0/MccyqUZ/rjwB2mZacSdjePNTW8ycMFAANYeXZvveK6pfw0VwqxBU29vedtlW/acOSeSnFnWeWDlA6Tb0vN1ndta3OZcvm/lfXy1/yvneuPKjfN1LpU/ec25u90Yc5cx5ir76y5jzLZgBadUaXPFmtWUqWrd6V7x3UpneYutnnvRvPx+Jr+f/p1jiccKfF3HyNzyZcrz9nVve9yvX6N+fDPkm1zlq4+sZsn+JSzZb90T7o/fn+c1H+v4mNvy+6PvZ+HghT5ErQoq3ykblFKBE1qlinM5rF496v7f/1EhNhYpm9XWXfelf7kcE54Gn+3+jIdXP+z2nH9c+CPP66ZkpABwd2vPw3Ze7PYiAA0qNnC7/akfn+LRHx4lKT2JwQu9j/HccucWRITltyx3Ke99WW/GtRtHiGjVFEi+5ONXSgVJSLlyLutVhtxMlSE3A3DFyhWk/fEHEZ07k7T+V+K/sHq/VLPPV7L3/F6359x/fj8NKzb0et2UTKviv7Jqrv4cToOaZs291LJaS+LOxrnd70DCAY/n+GTAJ1xe6XJnxV4nog5b79zKwYSD2rwTRPpnVakSIqx+fSI6dwag0vXXO8v3drvc63ETvpvAMz8+4/XO3zFQytG2DzCs+TDn8k1X3OSy/5wb5vDqta+yZMgSlg11TfVw4uIJmlRu4lL2dOen2XrnVtrUaEPFsq4jjkVEK/0gk7wGYYjIbOAhY8x5+3pV4FVjjNtJ0gMhNjbWbNiwIViXUyqosidna7nT/V20O5kXLhBasSLrj6/nnmW+PRDedpf7R3SO5Gxv9XqLaxteC1jdQeNT40nLTPPYvOPw3eHv+PXPX/lf3P+IqRVDUkYSO8/udG5fd9s6lz8qKjhEZKMxJjZnuS93/FGOSh/AGHMOaO/H2JRSQJ1Jz+a9UzaOXD2xdVw/1w0rNmT5LcvdVvKf7fosV1n29MtXVL3CuVwutBy1KtTKs9IH6HVZL8ZHjwdg08lN7Dy7k0FNB7Fo8CKt9IshXyr+EPtdPgAiUg19NqCU31QaaHW9rDq8YDNNhUgI1cOzJiv5+uavnXPUvtvXdbbTyb9MZve53S5l51Ky+ufnHKSVH5XKVnJZrxNRhyZVmmilXwz5UvG/CvwkIpNFZDLwExC8+deUusSFVqrk0punIAZfkdWLJnuPmI51OzKs+TCGXjnUWTb0y6F8vvvzrOuHhDqXC1tJT++dNZFMjfI1CnUuFTi+pGX+UEQ2YM26JcAQY8yOPA5TSvnIGBsUMv3VQzEPUb5MeW5semOubU91fgqA+XvmO8ue//l5bm12K9tObeNwgpXw7dOBnxYqBoCmVZo6l225U32pYsJbWuZK9n+rAX8CHwNzgD/tZUopfzCm0BV/iIQwrt046kfW97jPrL6zXNb3x+/ntiW38eI6q39+xbDC5/evH1mfV659BYDOdTsX+nwqMLw19TjmV9sIbMj2cqwrpfzBACGB71nduW5nNt+x2ZlRM+cgq/Jh5f1ynf6N+rPtrm0ud/+qePGWq2eg/d/Gxpgm2V6NjTFNPB2nVLCk7NpN+vHjznWTlha0icD9ymazGlGDIDQklIlXTXS7LefDWXXp8mWy9ZW+lCkVbAcGD2Zvz14cGDKUhKXL2BnVjn19+3Hus89K2B8AgwSr5gfCy7if3ERTIJceHh/uikg4UAGoYe/O6fjNrATUC0JsSjml7j9AaOVKlKludVs02SYvSdmxg6MPPQRA+h9/8OczzxISEUGZatWI6NKlQNczGRnsbGMNasrPoKoCXcuYoDT1ZHdrs1v5fPfndKjTgbIhZXmmSwnKtH7xDLzbp6ijCJ5B06BRV7+e0luvnnuBv2FV8hvJqvgTgOkejlHKr1L37SPtwAGOTHgAgBZxOxARTk2b5vW4Y3//BwA1J06kTK2alKlWjcju3X2+7vFn8zeYysHYbGCzIWXyMdTFVviHu/n1dOenuaPVHSUzVUJoGahXisaQhvu/Cc7jb6cx5k3gTRF5wBjj/VOmVCGknzjBn5Oeo97LLxFayfWXfP+AgS7rO1u2ovroezjzX9eBSZ6ceu0157Kvd+62lBTi53/hsh4Snrt5JHXPHlIPHqRSn6y7zyMTHiDxu+/y9y3BD7168qtE58cJrwy3+Pb/r9zz5fvlnyJSEUBEnhKRL0QkMBN9qlLp1OtvkLhqFfELF7mUZ1644Hb/7JV+y51xtNi+zfo3bgdVhg/z2Gxy7PEn8ozFlpbGrmjXu8mMkyc5PWMGJ998E1tSEraUFC7+so79Nw7i6AMPcvHnn537Jn73HeCafyfPa6YkB+3hrlLgW+qFp40xn4tIN6AfMAV4B+gU0MhUqZBx6hTxCxcCkHnedWq/3R06ej22zuTnAZzNKiJC3UmTqDFmDHt7X0dIhQrYkrKm+YtfsICIzp2oPNjqxmhsNkxKCiEVskar2hIScl1nX99+zuUz78zItf3w3aOo9+oUl/MAJG3YwMVf1lGmdi3Kt21LeIsWbt9H5tlzlKmuo1xV8PhS8Tueog0A3jHGLBKRSYELSZUme67JandPP3bc435lmzQhbb/rrE6R3bq53Tesfn1nU8vxZydx/tOsEanHHn2MyJ492d0x676lwdvTqdirFwCn3/Y8+5Q3jmcK2R366x0u643mfkJ4mzYu7f8mI4Okdeso365dga6rVEH40tRzVET+A/wFWCIi5Xw8Tql8iV+4kIxz57i4br1L/3yApksWu6w3+vwzwurWzfOcdZ+bRMudcTRbv85Zlr3SBzhy3/3svrormYmJnPv4E2d51dtvz/P8LXb8nquszvPPud334PARHL5ntEvZhVWrAEje4nlqRaX8zZcK/C/AUqC/PT1zNeCRQAal8mZLSiLpt9+c68YYly6OJYWEhbms7+t/PYfvuou9PXs5yxr+15qMvMmSxVQfP46WO+Mo37Ztvq4TWqkS9adN9bg98+xZ/nwmqyfPFWvWUPuJx2mx3UptHNmzp8v+4a1a0XJnHBISQr0pU1y2OZqSHCKyfTNJWrfOZVvGiZP5eh9K+UOeE7EA2Nv3rzTGvC8iNYFIY4zn+dX8TCdiye3oI/8k4auvaLp8GWUbNuT4c89x/pO5Ae9z7m8Hhw1HwsMJrVyZC8uW5drefMvmXNMRFsa+gQNJ27svz/2y/xxtKSlIuXKkHzqELSXFbVt9yo4dhFSqhIgQVr8+mQkJHH/yKWo/8Thhdety8eefOXx31txFV3y3krB69dgZ1Q6Tlpbrmkr5Q4EnYhGRZ4FHgcftRWHA//wbnsqvJPsfwtS91jyr5z+ZC+CsREoCW2oqyVu2ULZRI+q/+YbbffxZ6QM0njfPudwibgfNN23MtU/OppqQ8HBEhLKNGnl8QBveqhVlGzQgrL6VJC20UiUaTJvqbI6K6NKFBjPece6/t1dv0k+edO7fdHnuP3pKBYovTT03A4OAiwDGmGNA4dP4qUJxVChHxt9nFdgfGGYmJhZVSD5J2riRg8OGc/K119nVLhqA+EWLEBEie/QI+PVDwsNpuTPOaqYRIaRCBaRcOSpe39+5T6V+/bycoeAq5nh/e7tfS9of1jy4ZRt6nwxdKX/ypeJPM1Z7kAEQkQhfTiwi74nISRHZnq2smogsF5E99n8LPt1PKZe8aZNzOXHNGsjIAODshx8WVUg+OfbEEyRv2cKZmTOdZfVefhmAxNWrnWXlmjXjipUrghJTiy2bafD6684/CKGVKwfsWrmac+z/b0oFky8V/2f2Xj1VRGQMsAKYlccxAB8A/XOUPQasNMZcCay0r6tC+uPecc4ZnM7M+E+Bz3Nh9WrSjhz1U1TupR86nKusYl9r5Gtozay+7E2+XORsBrnUtPh9O/Vffy3vHZUKkDwrfmPMFGAeMB9oDjzjSwoHY8z3wNkcxYOB2fbl2cBN+QlWeZZ5/rxzOXVf3g8vczI2G0fGjeegm3lf0w4fdj5TKAiTkUFci5bEL1qUa1vTZUsRe7qCpl9/TaUbb6TZLz/n2u9SIqGhVLr+eud63RdfKMJoVGnkUyYpY8xyEVnn2F9EqhljclbqvqhtjDluP+dxEanlaUcRGQuMBbjssssKcKnSa/+AgfnuIfLHveMAyDx9Otc2x8jVgvY6Of6kNfXfsUddv+Bd+eNaZ7ZNgNDKlan/Sumbzjln90+lAs2XXj33isgJYCtBnIHLGDPTGBNrjImtWbNmoC9X4oRWrkz5mBiuWLM617awevVI3bOHuBYtSd62zVmeduQIGWfd/72++MMPbsuz9xI6PGZsgWLNeadf829/o9Hnn7lU+qXRFStXUH/a1Pxl8lTKD3xp4/8H0NoY08gPM3CdEJG6APZ/dfRKARhjyIyPJ3nTJsJq16bpiuUAhEdFAZB+7Bhn/zcHgIRvvnUet++6Puy52srrnXbkCIk/rHVuC7VXwhU6W/Okpp84QVyLlpx46WXnPhd/+CFfycfASnqWU/WxY/I9AOtSFFa/vktmT6WCxZeKfx+QlOdevvkSuMu+fBeQu9FX5ckkuf53lG3QgJY742j82afOUaKO/DRn33uPC6tWkRkf79z/yN8eZt91ffhjzBiMMRy+914yz5wBIOmXXwDYe20PAM59/DE52VJSXNYPDhtOXIuWZLhpJkre9JvLeuOFC5AgTzqilHLlyyfwceAnEfmPiEx1vPI6SEQ+AX4GmovIERG5B3gJ6CMie4A+9nWVTxn2StqdOpMm5So7Mv4+dnfq7Fy/8G3Wt4CDt/6Fi2u+d9k/eXvu/DMNZ2V1v7ywfLlzOTPxojPPTNrBg7mOOzxyJAD1/v0yV6xc4XEAlFIqeHyp+P8DfAf8gtW+73h5ZYwZYYypa4wJM8Y0MMa8a4w5Y4zpbYy50v5vQR4Ql3rpx//0uK1sg/qEVPJ9xp6U7c5hFoREWEM0Dt5yS679KnTsSJPFXwNw7JF/YktKYldsB85kG416+u13SNqY9auRcS4rzXLlQYMu2e6ZSpU0vlT8GcaYicaY940xsx2vgEemPErZttXr9soDB3rcVj462trn5ptdyquPH0eTr79yKWu+cQMhlStT94XJhJQrR7mmTZ3bdsVchS0x0WVSlIs//cSh2/9KXIuWnJ09m+TNm53nVkoVH750J1hl71r5FZDqKNS79aJxYfVqMuOtyUIq33ST231qP/UkaUePUOPee6kQY02WZtLSMJmZhJQv79yv7nOT2BXbgfC2balln6y8wfS3OHL/BMD6BtB83S8FivPEv7Ja8ardeWeBzqGUCow8s3OKiLssnKYQPXvyTbNzWpI2buTQ7X91rufsB18QJiMDRJDQ0KyytDSkbFmPx7jr2dNyZxwJ337L0b897HabUir4PGXnzPOO3xhTQmdkvvRkr/QBv/SDd9eH3FulDxASGYktMZFqI0dS69F/OkfeVurfn0o7+2NsNi7++COnZ/yHck2Cdn+glPJRnhW/iIQB4wHHHHmrgf8YY9IDGJcqxq5YvQpsNkI9PESWkBAir7mGyGuuCXJkSilf+PJw9x3gKuBt++sqe5kKAscI3JSdO51ltf75T674bmWRxRQaGemx0ldKFX++PNztYIzJPhP0dyKiE4QGyf4bBwFw4CarF07Zxo2pPuruogxJKVXC+XLHnykizn58ItIEKHmTu5YQxhjOzp5NxtmznM82W5SDozumUkoVlC93/I9gdencDwhwOaC3nAFy9r33OPnKFJfukBX79ydxzRpMcjJ1n5tUdMEppS4JvvTqWSkiV2Ll4hdgpzEmNY/DVAElb92Wq6z+K/9GwsKKIBql1KXIa8UvItWB2wBHgpU44A+yDeQqrTJOncKWmkrZBg3y3NeWloZJSyc00kqJkJl4EYyN0Iq5py6O6NKFC0uXupRppa+U8iePFb+ItMTK0bMU+A3rbr8D8ISI9DLG7PR0bGmw5xqrd6svg5N2d+yESUmh+dYthJQty+5YazxFlVtvIaRCBGdnz6bJN0so17gxIRXKuxxbffQ9/g9eKVWqebvjnww8ZIz5LHuhiAwFXgSGBjKwksKWnOySBsEdY09jvCuqnUv5+c+zHt7uv/4Grli5gpQ46+9p0xXLST92jArt2/s5YqVUaeet4m9rjMmVptEYM19E/i+AMZUou9rHWMnM7Jktc7Il+T6Vwd7e1zmXJawsER07Fjo+pZTKyVt3zosF3HZJMDabywTm3px89VX+GH8f6SetCcWOPPgQcS1acvTv/+DiL+sACK1Rg8ZfZs07U/W2EbTcGUfLnXE0W78u1znL1Cjd0xIqpQLHY5I2ETkCvOZuE/A3Y0zDQAaWXVEkaTs1dRqn337bYyI0T1MQhlSqhC0hIVf55R9/TIUYq9nGGOPMb5OdsdnIOHUKMjI0d71SqtAKkqRtFpC724nlv36Jqhi7sHwZYM12lZ9kaO4qfYDw5s2cy+4qfbBy3ITVrp2PKJVSKv88VvzGmOeCGUjxY6+cvWet9uiK1avIOHGCtEOHqNi7t8dnAEopFWwe2/hF5CkRqepley8R8TzVUwmXfuwYAMefeTrXNpORAUDFvn1pNH8eEhZGi61buPLnn7h8zv+48se1hNWpQ/l27ag8aJBW+kqpYsVbU8824GsRSQE2AaeAcOBKIBpYAVyyvXtsF63n1ylbck9z6JjsPOPsGcq3bk0L+1SIZcqWpcxVVwUvSKWUKgBvTT2LgEX2dA1dgbpAAvA/YKwxJjk4IRY/Kb//DkDyhjznnFdKqWLHl1w9e4A9QYilxMg4ccJa0FQKSqkSyJe0zCqHP597HoAGr7vr7aqUUsWbVvyFEaI/PqVUyaM1lxuZ8fE+7RfRrVuAI1FKKf/Ls+IXkWYislJEttvXo0TkqcCHVnT2D77JZT376GaTmTX5WEjZssEKSSml/MaXO/5ZwONAOoAxZiswPJBBFbWMP/90Wb/4/ffEtWhJwrJl7GzdpoiiUkop//Cl4q9gjFmfoywjEMEUV3/cOw6Aow8+5Cy7Ys3qIopGKaUKx5eK/7R9snUDICK3AMcDGlUxV3PiRM2po5QqsXyZbP1+YCbQQkSOAgeA2wMaVTFXY+yYog5BKaUKzJeK3xhjrhORCCDEGHNBRBoHOrDipsqI4YRGRlLzoYfy3lkppYoxXyr++UCMMSb75CvzgEsyKc35+V+4La/9yCOEVKgQ5GiUUsr/vE223gJoDVQWkSHZNlXCStZ2STr+5JMu61eu/QEJC9NKXyl1yfB2x98cGAhUAW7MVn4BKDWN3GVq1CjqEJRSyq98yc7ZxRjzcxBjUkopFUC+tPH/JiL3YzX7OJt4jDGjAhZVMVFz4sSiDkEppfzOl378HwF1gH7AGqABVnNPgYnIQRHZJiKbRSS4s6jnQ/Uxo4s6BKWU8jtf7vivMMbcKiKDjTGzReRjYKkfrt3TGHPaD+cJiGbr13mcFF0ppUoyX+740+3/nheRNkBloFHAIiompFy5og5BKaUCwpeKf6Z90vWngC+BHcDLhbyuAZaJyEYRGetuBxEZKyIbRGTDqVOnCnm5/AvRil8pdYnyZerF/9oXvweaAIjI5YW8bldjzDERqQUsF5Gdxpjvc1x3JlaqCGJjY427kyillMo/r3f8ItJFRG6xV9COXPwfA2sLc1FjzDH7vyeBBUDHwpxPKaWU7zxW/CLyCvAeMBRYLCLPAsuBdcCVBb2giESISEXHMtAX2F7Q8/lbaOXKhLeLKuowlFIqYLw19QwA2htjUuxt/MeAKGPMnkJeszawwN5jpgzwsTHm20Ke029Cq1WjbP36RR2GUkoFjLeKP9kYkwJgjDknIrv8UOljjNkPtCvseQLGZgPRqYiVUpcubxV/UxH5Mtt6o+zrxphBgQur6BhjIEQrfqXUpctbxT84x/qrgQyk2LDZkBAduKWUunR5S9K2JpiBFBva1KOUusRpDZeDMQY0VYNS6hKmFX9OxoA29SilLmHe+vF721YlINEUBzYbog93lVKXMG813AYR6ZSzUERGA5sCF1LRMkbb+JVSlzZvvXoexErQth54FLgceBs4AnQPQmwBkRkfj0lLw5aUxPEnn4KQEJLWrwesUbuZ8fFIuCZoU0pdurz16lkrIjHAc8A+IBG4xxizLFjB+YNJS0PKlgXg6CP/JOGrrzzuW7ZRI8o1b071kSODFJ1SSgVfXtk5bwVGAO8A1wHDRGSDMeZswCPzg3Off86fz0/myu9WQpkyuSr9eq9OQULLkLp7N1WGDyOsVq0iilQppYLHY8UvIiuAZOA6Y8wBEXkSmAD8KiIv29MmF2tn//supKez55qslqlKg26k9iOPUKZmzawd+/crguiUUqpoeHuKOd0Yc6Mx5gCAsUwDugLXBiW6Qmo48z8ASHg4YQ0bUuOBCdR9/nnXSl8ppUoZb009G90VGmP+BG4PTDj+Vfbyy2m5M66ow1BKqWLF2x3/QseCiMwPfChKKaWCwVvFn334apNAB6KUUio4vFX8xsOyUkqpEsxbG387EUnAuvMvb1/Gvm6MMZUCHp1SSim/8zaAKzSYgSillAoOTUqjlFKljFb8SilVymjFr5RSpYwYU/w77IjIKeBQUcfhRQ3gdFEHkU8lMWYomXGXxJhB4w6mQMV8uTEmV6qCElHxF3f2xHWxRR1HfpTEmKFkxl0SYwaNO5iCHbM29SilVCmjFb9SSpUyWvH7R7FPUe1GSYwZSmbcJTFm0LiDKagxaxu/UkqVMnrHr5RSpYxW/EopVcpoxe+GiLwnIidFZHu2snYi8rOIbBORr0Skkr28rIi8by/fIiI9sh1TVkRmishuEdkpIkMDGHNDEVklInEi8ruIPGQvryYiy0Vkj/3fqtmOeVxE9orILhHpl638Kvv72SsiU0VE3F2zuMWdbfuX2f/vinPMIjLC/rPeKiLfikiN4hK3iFS3758oIm9lO08FEVls/53+XUReClTM/ozbvi0on8kCxNxHRDbafxc2ikivbOfy/+fRGKOvHC+gOxADbM9W9itwrX15FDDZvnw/8L59uRbWzGUh9vXngBfsyyFAjQDGXBeIsS9XBHYDrYB/A4/Zyx8DXrYvtwK2AOWAxsA+INS+bT3QBSsT6zfA9SUhbvv2IcDH2f/vimvMWEkSTzp+L+zHTypGcUcA3YBxwFvZzlMB6GlfLgv8UMx+R9zGbd8WlM9kAWJuD9SzL7cBjmY7l98/jwH5j7oUXkAjXCv+BLIehjcEdtiXpwN/zbbfSqCjffkPIKKI4l8E9AF2AXXtZXWBXfblx4HHs+2/1P7LVRfYma18BPCf4h63fTkSWGv/gAWs4vfjzzoMOAVcbv9QzwDGFpe4s+03MmcFmmP7m8CYkhB3UX0mfY3ZXi7AGawbhYB8HrWpx3fbgUH25VuxKn+w7uQGi0gZEWkMXAU0FJEq9u2TRWSTiHwuIrWDEaiINMK6g1gH1DbGHAew/1vLvlt9rA+BwxF7WX37cs7ygCtk3ACTgVeBpGDEC4WL2RiTDowHtgHHsP5gvVuM4vblPFWAG7FueAKuMHEX1WeyADEPBX4zxqQSoM+jVvy+GwXcLyIbsb66pdnL38P6z9gAvAH8BGRgfY1vAPxojIkBfgamBDpIEYkE5gN/M8YkeNvVTZnxUh5QhY1bRKKBK4wxCwIRn9tACh9zGFbF3x6oB2zF+nYQUPmIO6/zlAE+AaYaY/b7Kz4v1yts3EH/TOY3ZhFpDbwM3OsocrNboT+PWvH7yBiz0xjT1xhzFdYv+z57eYYx5mFjTLQxZjBQBdiD9VUtCXBURJ9jPTcIGHtFMh+YY4z5wl58QkTq2rfXxWpTBuuPVcNshzfAuus8Yl/OWV7c4+4CXCUiB7Gae5qJyOpiHnM0gDFmn7G+x38GXB2omAsQd15mAnuMMW/4PdAc/BR3UD+T+Y1ZRBrYY7vTGLPPXhyQz6NW/D4SkVr2f0OAp7DaYx09HCLsy32ADGPMDvsH+Sugh/0UvYEdAYxPsJoJ4owxr2Xb9CVwl335Lqy2Rkf5cBEpZ2+iuhJYb//6eUFEOtvPeWe2Y4pz3O8YY+oZYxphPdjbbYzpUZxjBo4CrUTEkT2xDxAXiJgLGLe3c70AVAb+5ucw3V3LL3EH8zOZ35jtzVCLsZ4F/Zgt5sB8HoP9kKMkvLDu6I8D6Vh/ce8BHsJ6Mr8beImsB72NsB7YxAErsNKgOs5zOfA91lf4lcBlAYy5G9ZXwK3AZvvrBqC6/dp77P9Wy3bMk1jfXHaRracAEIv1TGMf8JbjvRb3uLNtb0Rge/X482c9zv67sxWrUqpezOI+CJwFEu2fhVZYd53GHrfjPKOLe9z28qB8JvMbM9bN5MVs+24GagXq86gpG5RSqpTRph6llCpltOJXSqlSRit+pZQqZbTiV0qpUkYrfqWUKmW04lcqG3tmx832158ictS+nCgibxd1fEr5g3bnVMoDEZkEJBpjAp5qQ6lg0jt+pXwgIj1E5Gv78iQRmS0iy0TkoIgMEZF/23Omf2sfqu/Io77Gnl99qWOovlJFTSt+pQqmKTAAGAz8D1hljGkLJAMD7JX/NOAWY+V3eg94saiCVSq7MkUdgFIl1DfGmHQR2YY1qcq39vJtWCkjmmNNqLHcPmFSKFYaEKWKnFb8ShVMKoAxxiYi6SbrYZkN63MlwO/GmC5FFaBSnmhTj1KBsQuoKSJdwErRa8+1rlSR04pfqQAwxqQBtwAvi8gWrGyLAc21r5SvtDunUkqVMnrHr5RSpYxW/EopVcpoxa+UUqWMVvxKKVXKaMWvlFKljFb8SilVymjFr5RSpcz/A8A/kkhaKnBbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(df_result.index, df_result['value'], label='Values - Test Set')\n",
    "plt.plot(df_result.index, df_result['prediction'], label='Prediction - vs Test set')\n",
    "plt.plot(X_val.index, X_val.iloc[:,0], label='Values - Validation Set')\n",
    "plt.plot(X_train.index, X_train.iloc[:,0], label='Values - Training Set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Rate (Domestic Currency vs US Dollar)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "35d06fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a03b3d8790>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(df_result.index, df_result['value'], label='Values - Test Set')\n",
    "plt.plot(df_result.index, df_result['prediction'], label='Prediction - vs Test set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Rate (Domestic Currency vs US Dollar)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "321b4c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a02afdd7c0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result_full = format_predictions(predictions_full, values_full, X_test, scaler)\n",
    "df_result_full\n",
    "plt.figure(1)\n",
    "plt.plot(df_result_full.index, df_result_full['value'], label='Values - Test Set')\n",
    "plt.plot(df_result_full.index, df_result_full['prediction'], label='Prediction - vs Test set')\n",
    "plt.plot(X_val.index, X_val.iloc[:,0], label='Values - Validation Set')\n",
    "plt.plot(X_train.index, X_train.iloc[:,0], label='Values - Training Set')\n",
    "plt.xlabel('FX Rate')\n",
    "plt.ylabel('Time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8fbccdc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-24</th>\n",
       "      <td>16.530001</td>\n",
       "      <td>13.495135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-25</th>\n",
       "      <td>16.471001</td>\n",
       "      <td>13.497020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>16.373001</td>\n",
       "      <td>13.474046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-29</th>\n",
       "      <td>16.524500</td>\n",
       "      <td>13.472877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>16.581499</td>\n",
       "      <td>13.473238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-01</th>\n",
       "      <td>16.843000</td>\n",
       "      <td>13.474079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-02</th>\n",
       "      <td>16.854000</td>\n",
       "      <td>13.473812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-06</th>\n",
       "      <td>16.762501</td>\n",
       "      <td>13.473747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-07</th>\n",
       "      <td>16.732000</td>\n",
       "      <td>13.473709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-08</th>\n",
       "      <td>16.696501</td>\n",
       "      <td>13.473578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-09</th>\n",
       "      <td>16.814501</td>\n",
       "      <td>13.473419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-10</th>\n",
       "      <td>16.770000</td>\n",
       "      <td>13.473085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-13</th>\n",
       "      <td>16.765499</td>\n",
       "      <td>13.473014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-14</th>\n",
       "      <td>16.570000</td>\n",
       "      <td>13.472890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-15</th>\n",
       "      <td>16.507999</td>\n",
       "      <td>13.473070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-16</th>\n",
       "      <td>16.524000</td>\n",
       "      <td>13.473007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-17</th>\n",
       "      <td>16.457001</td>\n",
       "      <td>13.472907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-20</th>\n",
       "      <td>16.545000</td>\n",
       "      <td>13.472941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-21</th>\n",
       "      <td>16.588501</td>\n",
       "      <td>13.472734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-22</th>\n",
       "      <td>16.600500</td>\n",
       "      <td>13.472648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-23</th>\n",
       "      <td>16.530500</td>\n",
       "      <td>13.481049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-24</th>\n",
       "      <td>16.587999</td>\n",
       "      <td>13.497867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-27</th>\n",
       "      <td>16.718000</td>\n",
       "      <td>13.501778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-28</th>\n",
       "      <td>16.655500</td>\n",
       "      <td>13.501987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-29</th>\n",
       "      <td>16.900000</td>\n",
       "      <td>13.501857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-30</th>\n",
       "      <td>17.024500</td>\n",
       "      <td>13.501346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>17.050501</td>\n",
       "      <td>13.501103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-03</th>\n",
       "      <td>17.094500</td>\n",
       "      <td>13.501044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-04</th>\n",
       "      <td>17.357000</td>\n",
       "      <td>13.500968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-05</th>\n",
       "      <td>17.358000</td>\n",
       "      <td>13.500568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-06</th>\n",
       "      <td>17.149000</td>\n",
       "      <td>13.500541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-07</th>\n",
       "      <td>17.180000</td>\n",
       "      <td>13.500813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>17.118999</td>\n",
       "      <td>13.500771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>16.993000</td>\n",
       "      <td>13.500834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-12</th>\n",
       "      <td>17.164000</td>\n",
       "      <td>13.500957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-13</th>\n",
       "      <td>17.185501</td>\n",
       "      <td>13.500720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-14</th>\n",
       "      <td>17.186501</td>\n",
       "      <td>13.500670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-17</th>\n",
       "      <td>17.276001</td>\n",
       "      <td>13.500663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-18</th>\n",
       "      <td>17.261000</td>\n",
       "      <td>13.500504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-19</th>\n",
       "      <td>17.206501</td>\n",
       "      <td>13.500517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-20</th>\n",
       "      <td>17.339001</td>\n",
       "      <td>13.500577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-21</th>\n",
       "      <td>17.195000</td>\n",
       "      <td>13.500429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-24</th>\n",
       "      <td>17.360001</td>\n",
       "      <td>13.502762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-25</th>\n",
       "      <td>17.359501</td>\n",
       "      <td>13.504814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-26</th>\n",
       "      <td>17.436001</td>\n",
       "      <td>13.505452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-27</th>\n",
       "      <td>17.652500</td>\n",
       "      <td>13.505555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-28</th>\n",
       "      <td>17.914499</td>\n",
       "      <td>13.505528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-31</th>\n",
       "      <td>17.955999</td>\n",
       "      <td>13.505502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-01</th>\n",
       "      <td>17.923000</td>\n",
       "      <td>13.505409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-02</th>\n",
       "      <td>17.859501</td>\n",
       "      <td>13.505434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-03</th>\n",
       "      <td>17.893000</td>\n",
       "      <td>13.505471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-04</th>\n",
       "      <td>18.247499</td>\n",
       "      <td>13.505498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-08</th>\n",
       "      <td>18.184500</td>\n",
       "      <td>13.505467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-09</th>\n",
       "      <td>18.594500</td>\n",
       "      <td>13.505484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-10</th>\n",
       "      <td>18.465500</td>\n",
       "      <td>13.505486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-11</th>\n",
       "      <td>18.450001</td>\n",
       "      <td>13.505528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-14</th>\n",
       "      <td>18.559999</td>\n",
       "      <td>13.505569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-15</th>\n",
       "      <td>18.475000</td>\n",
       "      <td>13.505612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-16</th>\n",
       "      <td>18.378000</td>\n",
       "      <td>13.505704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-09-17</th>\n",
       "      <td>18.312000</td>\n",
       "      <td>13.505810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value  prediction\n",
       "Date                             \n",
       "2015-06-24  16.530001   13.495135\n",
       "2015-06-25  16.471001   13.497020\n",
       "2015-06-26  16.373001   13.474046\n",
       "2015-06-29  16.524500   13.472877\n",
       "2015-06-30  16.581499   13.473238\n",
       "2015-07-01  16.843000   13.474079\n",
       "2015-07-02  16.854000   13.473812\n",
       "2015-07-06  16.762501   13.473747\n",
       "2015-07-07  16.732000   13.473709\n",
       "2015-07-08  16.696501   13.473578\n",
       "2015-07-09  16.814501   13.473419\n",
       "2015-07-10  16.770000   13.473085\n",
       "2015-07-13  16.765499   13.473014\n",
       "2015-07-14  16.570000   13.472890\n",
       "2015-07-15  16.507999   13.473070\n",
       "2015-07-16  16.524000   13.473007\n",
       "2015-07-17  16.457001   13.472907\n",
       "2015-07-20  16.545000   13.472941\n",
       "2015-07-21  16.588501   13.472734\n",
       "2015-07-22  16.600500   13.472648\n",
       "2015-07-23  16.530500   13.481049\n",
       "2015-07-24  16.587999   13.497867\n",
       "2015-07-27  16.718000   13.501778\n",
       "2015-07-28  16.655500   13.501987\n",
       "2015-07-29  16.900000   13.501857\n",
       "2015-07-30  17.024500   13.501346\n",
       "2015-07-31  17.050501   13.501103\n",
       "2015-08-03  17.094500   13.501044\n",
       "2015-08-04  17.357000   13.500968\n",
       "2015-08-05  17.358000   13.500568\n",
       "2015-08-06  17.149000   13.500541\n",
       "2015-08-07  17.180000   13.500813\n",
       "2015-08-10  17.118999   13.500771\n",
       "2015-08-11  16.993000   13.500834\n",
       "2015-08-12  17.164000   13.500957\n",
       "2015-08-13  17.185501   13.500720\n",
       "2015-08-14  17.186501   13.500670\n",
       "2015-08-17  17.276001   13.500663\n",
       "2015-08-18  17.261000   13.500504\n",
       "2015-08-19  17.206501   13.500517\n",
       "2015-08-20  17.339001   13.500577\n",
       "2015-08-21  17.195000   13.500429\n",
       "2015-08-24  17.360001   13.502762\n",
       "2015-08-25  17.359501   13.504814\n",
       "2015-08-26  17.436001   13.505452\n",
       "2015-08-27  17.652500   13.505555\n",
       "2015-08-28  17.914499   13.505528\n",
       "2015-08-31  17.955999   13.505502\n",
       "2015-09-01  17.923000   13.505409\n",
       "2015-09-02  17.859501   13.505434\n",
       "2015-09-03  17.893000   13.505471\n",
       "2015-09-04  18.247499   13.505498\n",
       "2015-09-08  18.184500   13.505467\n",
       "2015-09-09  18.594500   13.505484\n",
       "2015-09-10  18.465500   13.505486\n",
       "2015-09-11  18.450001   13.505528\n",
       "2015-09-14  18.559999   13.505569\n",
       "2015-09-15  18.475000   13.505612\n",
       "2015-09-16  18.378000   13.505704\n",
       "2015-09-17  18.312000   13.505810"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_full.head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc72a93",
   "metadata": {},
   "source": [
    "## Investigation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e95217b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________BATCH # 0 _________________\n",
      " - - - - - -  Inputs - - - - - - - - \n",
      " - - - - - - Inputs size: - - - - - - \n",
      " torch.Size([64, 300, 28])\n",
      " - - - - - - targets size: - - - - - - \n",
      " torch.Size([64])\n",
      "Test_hidden_state shape : torch.Size([5, 64, 64])\n",
      "Test_cell_state shape : torch.Size([5, 64, 64])\n",
      "test_hidden shape : torch.Size([5, 64, 64]) torch.Size([5, 64, 64])\n",
      "Output shape:  torch.Size([300, 64])\n",
      "Output shape:  tensor([[-0.1103, -0.0130, -0.0122,  ..., -0.0736, -0.0051,  0.0046],\n",
      "        [-0.1103, -0.0130, -0.0122,  ..., -0.0736, -0.0051,  0.0046],\n",
      "        [-0.1103, -0.0130, -0.0123,  ..., -0.0736, -0.0051,  0.0046],\n",
      "        ...,\n",
      "        [-0.1106, -0.0136, -0.0143,  ..., -0.0734, -0.0056,  0.0040],\n",
      "        [-0.1106, -0.0136, -0.0143,  ..., -0.0734, -0.0056,  0.0040],\n",
      "        [-0.1106, -0.0136, -0.0143,  ..., -0.0734, -0.0056,  0.0040]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "Hidden:  (tensor([[[-6.2387e-01, -9.2464e-02, -1.9033e-01,  ...,  1.2900e-02,\n",
      "          -1.2019e-01, -1.2189e-01],\n",
      "         [-6.2168e-01, -9.5991e-02, -1.9210e-01,  ...,  1.2398e-02,\n",
      "          -1.2148e-01, -1.2134e-01],\n",
      "         [-6.1846e-01, -1.0676e-01, -1.9520e-01,  ...,  3.9000e-03,\n",
      "          -1.2422e-01, -1.2556e-01],\n",
      "         ...,\n",
      "         [-6.3226e-01, -1.5541e-01,  4.4318e-01,  ...,  1.0729e-01,\n",
      "          -7.7121e-02, -9.6247e-02],\n",
      "         [-6.3286e-01, -1.5429e-01,  4.4487e-01,  ...,  1.0813e-01,\n",
      "          -7.6793e-02, -9.5961e-02],\n",
      "         [-6.3349e-01, -1.5304e-01,  4.4667e-01,  ...,  1.0911e-01,\n",
      "          -7.5700e-02, -9.5580e-02]],\n",
      "\n",
      "        [[ 2.1749e-02, -1.2598e-01,  5.7588e-02,  ...,  1.0730e-01,\n",
      "           1.8019e-02,  2.1149e-02],\n",
      "         [ 2.2090e-02, -1.2557e-01,  5.7571e-02,  ...,  1.0758e-01,\n",
      "           1.8236e-02,  2.1668e-02],\n",
      "         [ 2.2184e-02, -1.2609e-01,  5.7561e-02,  ...,  1.0815e-01,\n",
      "           1.7988e-02,  2.1568e-02],\n",
      "         ...,\n",
      "         [ 5.9177e-02, -6.1954e-02,  4.9975e-02,  ...,  2.7773e-02,\n",
      "           9.0532e-02,  1.9634e-02],\n",
      "         [ 5.9320e-02, -6.1723e-02,  4.9870e-02,  ...,  2.7951e-02,\n",
      "           9.0601e-02,  1.9497e-02],\n",
      "         [ 5.9435e-02, -6.1529e-02,  4.9784e-02,  ...,  2.8106e-02,\n",
      "           9.0694e-02,  1.9347e-02]],\n",
      "\n",
      "        [[-5.2146e-02, -1.3468e-03, -1.4952e-01,  ..., -4.2881e-02,\n",
      "          -3.8941e-02, -9.6267e-02],\n",
      "         [-5.2013e-02, -1.5018e-03, -1.4932e-01,  ..., -4.2930e-02,\n",
      "          -3.8817e-02, -9.6264e-02],\n",
      "         [-5.1959e-02, -1.7524e-03, -1.4912e-01,  ..., -4.2982e-02,\n",
      "          -3.8617e-02, -9.6208e-02],\n",
      "         ...,\n",
      "         [-4.0533e-02, -2.7273e-02, -1.4685e-01,  ..., -6.6087e-02,\n",
      "          -3.9753e-02, -1.0809e-01],\n",
      "         [-4.0494e-02, -2.7247e-02, -1.4676e-01,  ..., -6.6041e-02,\n",
      "          -3.9690e-02, -1.0814e-01],\n",
      "         [-4.0444e-02, -2.7215e-02, -1.4670e-01,  ..., -6.6005e-02,\n",
      "          -3.9647e-02, -1.0820e-01]],\n",
      "\n",
      "        [[-8.1893e-04, -3.6787e-02,  1.6986e-04,  ...,  3.9951e-02,\n",
      "           2.8228e-02, -7.6919e-03],\n",
      "         [-7.6959e-04, -3.6824e-02,  1.4446e-04,  ...,  3.9958e-02,\n",
      "           2.8226e-02, -7.6910e-03],\n",
      "         [-7.2507e-04, -3.6860e-02,  1.2900e-04,  ...,  3.9961e-02,\n",
      "           2.8227e-02, -7.6942e-03],\n",
      "         ...,\n",
      "         [ 2.8815e-03, -4.1470e-02,  9.3721e-04,  ...,  3.2400e-02,\n",
      "           3.7879e-02, -1.3785e-02],\n",
      "         [ 2.8545e-03, -4.1470e-02,  9.1663e-04,  ...,  3.2418e-02,\n",
      "           3.7878e-02, -1.3836e-02],\n",
      "         [ 2.8378e-03, -4.1468e-02,  9.0046e-04,  ...,  3.2429e-02,\n",
      "           3.7875e-02, -1.3874e-02]],\n",
      "\n",
      "        [[-1.1032e-01, -1.3029e-02, -1.2207e-02,  ..., -7.3597e-02,\n",
      "          -5.0567e-03,  4.6016e-03],\n",
      "         [-1.1032e-01, -1.3036e-02, -1.2234e-02,  ..., -7.3577e-02,\n",
      "          -5.0709e-03,  4.5914e-03],\n",
      "         [-1.1032e-01, -1.3047e-02, -1.2263e-02,  ..., -7.3558e-02,\n",
      "          -5.0844e-03,  4.5855e-03],\n",
      "         ...,\n",
      "         [-1.1055e-01, -1.3607e-02, -1.4304e-02,  ..., -7.3429e-02,\n",
      "          -5.5594e-03,  4.0145e-03],\n",
      "         [-1.1056e-01, -1.3600e-02, -1.4310e-02,  ..., -7.3421e-02,\n",
      "          -5.5558e-03,  4.0207e-03],\n",
      "         [-1.1057e-01, -1.3592e-02, -1.4313e-02,  ..., -7.3415e-02,\n",
      "          -5.5517e-03,  4.0260e-03]]], grad_fn=<StackBackward>), tensor([[[-1.3606e+00, -2.6371e-01, -3.9132e-01,  ...,  2.1479e-02,\n",
      "          -3.0446e-01, -5.0435e-01],\n",
      "         [-1.3545e+00, -2.7370e-01, -3.9406e-01,  ...,  2.0605e-02,\n",
      "          -3.0912e-01, -5.0016e-01],\n",
      "         [-1.3502e+00, -3.0381e-01, -4.0367e-01,  ...,  6.5117e-03,\n",
      "          -3.2528e-01, -5.1575e-01],\n",
      "         ...,\n",
      "         [-9.4687e-01, -8.2489e-01,  6.7897e-01,  ...,  1.7511e-01,\n",
      "          -1.7141e-01, -8.4883e-01],\n",
      "         [-9.4803e-01, -8.1706e-01,  6.8249e-01,  ...,  1.7646e-01,\n",
      "          -1.7030e-01, -8.4624e-01],\n",
      "         [-9.4920e-01, -8.0864e-01,  6.8618e-01,  ...,  1.7803e-01,\n",
      "          -1.6737e-01, -8.4276e-01]],\n",
      "\n",
      "        [[ 4.2962e-02, -2.3071e-01,  1.3217e-01,  ...,  1.9935e-01,\n",
      "           3.6065e-02,  4.2081e-02],\n",
      "         [ 4.3625e-02, -2.3002e-01,  1.3210e-01,  ...,  1.9985e-01,\n",
      "           3.6512e-02,  4.3091e-02],\n",
      "         [ 4.3758e-02, -2.3116e-01,  1.3227e-01,  ...,  2.0131e-01,\n",
      "           3.6034e-02,  4.2822e-02],\n",
      "         ...,\n",
      "         [ 1.3453e-01, -1.1385e-01,  1.1735e-01,  ...,  5.5958e-02,\n",
      "           1.6474e-01,  3.5837e-02],\n",
      "         [ 1.3489e-01, -1.1341e-01,  1.1712e-01,  ...,  5.6303e-02,\n",
      "           1.6487e-01,  3.5590e-02],\n",
      "         [ 1.3521e-01, -1.1303e-01,  1.1693e-01,  ...,  5.6599e-02,\n",
      "           1.6504e-01,  3.5322e-02]],\n",
      "\n",
      "        [[-1.0959e-01, -2.5504e-03, -3.1575e-01,  ..., -8.5983e-02,\n",
      "          -7.4345e-02, -1.9829e-01],\n",
      "         [-1.0930e-01, -2.8440e-03, -3.1529e-01,  ..., -8.6072e-02,\n",
      "          -7.4097e-02, -1.9823e-01],\n",
      "         [-1.0916e-01, -3.3183e-03, -3.1483e-01,  ..., -8.6180e-02,\n",
      "          -7.3695e-02, -1.9802e-01],\n",
      "         ...,\n",
      "         [-8.3020e-02, -5.1805e-02, -3.0041e-01,  ..., -1.3003e-01,\n",
      "          -7.6536e-02, -2.2150e-01],\n",
      "         [-8.2937e-02, -5.1754e-02, -3.0020e-01,  ..., -1.2994e-01,\n",
      "          -7.6421e-02, -2.2163e-01],\n",
      "         [-8.2835e-02, -5.1693e-02, -3.0004e-01,  ..., -1.2987e-01,\n",
      "          -7.6342e-02, -2.2176e-01]],\n",
      "\n",
      "        [[-1.5827e-03, -7.3192e-02,  3.6376e-04,  ...,  8.5995e-02,\n",
      "           5.3379e-02, -1.5100e-02],\n",
      "         [-1.4873e-03, -7.3269e-02,  3.0934e-04,  ...,  8.6015e-02,\n",
      "           5.3373e-02, -1.5098e-02],\n",
      "         [-1.4013e-03, -7.3343e-02,  2.7621e-04,  ...,  8.6030e-02,\n",
      "           5.3373e-02, -1.5103e-02],\n",
      "         ...,\n",
      "         [ 5.5852e-03, -8.2335e-02,  1.9949e-03,  ...,  6.9858e-02,\n",
      "           7.2060e-02, -2.7058e-02],\n",
      "         [ 5.5329e-03, -8.2334e-02,  1.9511e-03,  ...,  6.9899e-02,\n",
      "           7.2057e-02, -2.7158e-02],\n",
      "         [ 5.5004e-03, -8.2328e-02,  1.9167e-03,  ...,  6.9921e-02,\n",
      "           7.2050e-02, -2.7234e-02]],\n",
      "\n",
      "        [[-2.2984e-01, -2.8078e-02, -2.5434e-02,  ..., -1.4910e-01,\n",
      "          -9.9222e-03,  9.3791e-03],\n",
      "         [-2.2984e-01, -2.8093e-02, -2.5491e-02,  ..., -1.4906e-01,\n",
      "          -9.9501e-03,  9.3582e-03],\n",
      "         [-2.2984e-01, -2.8116e-02, -2.5551e-02,  ..., -1.4902e-01,\n",
      "          -9.9766e-03,  9.3461e-03],\n",
      "         ...,\n",
      "         [-2.3027e-01, -2.9310e-02, -2.9755e-02,  ..., -1.4866e-01,\n",
      "          -1.0878e-02,  8.1514e-03],\n",
      "         [-2.3029e-01, -2.9293e-02, -2.9767e-02,  ..., -1.4864e-01,\n",
      "          -1.0871e-02,  8.1638e-03],\n",
      "         [-2.3031e-01, -2.9276e-02, -2.9773e-02,  ..., -1.4863e-01,\n",
      "          -1.0863e-02,  8.1746e-03]]], grad_fn=<StackBackward>))\n"
     ]
    }
   ],
   "source": [
    "#==========================================\n",
    "## TESTING EVALUATION / OUTPUT OF THE MODEL\n",
    "#==========================================\n",
    "input_dim = len(X_train.columns) #sequence length\n",
    "output_dim = 1\n",
    "seq_length = 300\n",
    "hidden_dim = 64\n",
    "layer_dim = 5\n",
    "batch_size = 64\n",
    "dropout = 0.2\n",
    "n_epochs = 100\n",
    "#learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'seq_length' : seq_length,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n",
    "\n",
    "#Create NN\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "#Set up model \n",
    "LSTM_Mod = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
    "\n",
    "\n",
    "#print('Input - Train Loader:',train.shape)\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    if batch_idx == 1:\n",
    "        break    \n",
    "    print('________BATCH #',batch_idx,'_________________')\n",
    "    print(' - - - - - -  Inputs - - - - - - - - ')\n",
    "    print(' - - - - - - Inputs size: - - - - - - \\n',inputs.size())\n",
    "    print(' - - - - - - targets size: - - - - - - \\n',targets.size())    \n",
    "    adjusted_input = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "    \n",
    "    \n",
    "Test_hidden_state = torch.randn(layer_dim, batch_size, hidden_dim)\n",
    "Test_cell_state = torch.randn(layer_dim, batch_size, hidden_dim)\n",
    "test_hidden = (Test_hidden_state,Test_cell_state)\n",
    "\n",
    "print('Test_hidden_state shape :',Test_hidden_state.shape)\n",
    "print('Test_cell_state shape :',Test_cell_state.shape)\n",
    "print('test_hidden shape :',test_hidden[0].shape,test_hidden[1].shape)\n",
    "fc = nn.Linear(hidden_dim, output_dim)\n",
    "out, test_hidden = LSTM_Mod(adjusted_input, test_hidden)\n",
    "print(\"Output shape: \", out.squeeze()[-1, :].shape)\n",
    "print(\"Output shape: \", out.squeeze()[:, -1, :])\n",
    "#print(\"Hidden: \", test_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fa59d437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________BATCH________ 0 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.4095],\n",
      "         [-0.7014],\n",
      "         [-0.9768],\n",
      "         ...,\n",
      "         [-1.1086],\n",
      "         [-1.1109],\n",
      "         [-1.1180]],\n",
      "\n",
      "        [[-0.6710],\n",
      "         [-0.6634],\n",
      "         [-1.0301],\n",
      "         ...,\n",
      "         [-1.1114],\n",
      "         [-1.1331],\n",
      "         [-1.1154]],\n",
      "\n",
      "        [[-0.6923],\n",
      "         [-0.4908],\n",
      "         [-0.5807],\n",
      "         ...,\n",
      "         [-1.1197],\n",
      "         [-1.1102],\n",
      "         [-1.1123]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5125],\n",
      "         [-0.5504],\n",
      "         [-0.5479],\n",
      "         ...,\n",
      "         [-1.1252],\n",
      "         [-1.0533],\n",
      "         [-1.0490]],\n",
      "\n",
      "        [[-0.9195],\n",
      "         [-1.0772],\n",
      "         [-1.1065],\n",
      "         ...,\n",
      "         [-1.0535],\n",
      "         [-1.0421],\n",
      "         [-1.1152]],\n",
      "\n",
      "        [[-0.8702],\n",
      "         [-1.0802],\n",
      "         [-1.0949],\n",
      "         ...,\n",
      "         [-1.0311],\n",
      "         [-1.1086],\n",
      "         [-1.0612]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0067],\n",
      "         [0.0050],\n",
      "         [0.0038],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0050],\n",
      "         [0.0051],\n",
      "         [0.0035],\n",
      "         ...,\n",
      "         [0.0032],\n",
      "         [0.0032],\n",
      "         [0.0032]],\n",
      "\n",
      "        [[0.0048],\n",
      "         [0.0058],\n",
      "         [0.0053],\n",
      "         ...,\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0060],\n",
      "         [0.0058],\n",
      "         [0.0058],\n",
      "         ...,\n",
      "         [0.0032],\n",
      "         [0.0035],\n",
      "         [0.0035]],\n",
      "\n",
      "        [[0.0040],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0036],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0042],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0036],\n",
      "         [0.0033],\n",
      "         [0.0035]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.1282, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n",
      "________BATCH________ 1 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.9806],\n",
      "         [-1.0811],\n",
      "         [-1.1063],\n",
      "         ...,\n",
      "         [-1.0596],\n",
      "         [-1.1069],\n",
      "         [-1.0974]],\n",
      "\n",
      "        [[-0.9139],\n",
      "         [-1.0738],\n",
      "         [-1.1043],\n",
      "         ...,\n",
      "         [-1.0427],\n",
      "         [-1.0262],\n",
      "         [-1.0664]],\n",
      "\n",
      "        [[-0.3519],\n",
      "         [-1.0462],\n",
      "         [-1.1188],\n",
      "         ...,\n",
      "         [-1.0711],\n",
      "         [-1.0461],\n",
      "         [-1.0506]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4813],\n",
      "         [-0.5109],\n",
      "         [-0.5750],\n",
      "         ...,\n",
      "         [-0.5560],\n",
      "         [-0.5479],\n",
      "         [-0.5705]],\n",
      "\n",
      "        [[-0.5844],\n",
      "         [-0.5055],\n",
      "         [-0.5579],\n",
      "         ...,\n",
      "         [-0.5484],\n",
      "         [-0.5660],\n",
      "         [-0.5499]],\n",
      "\n",
      "        [[-0.3578],\n",
      "         [-0.4196],\n",
      "         [-0.6133],\n",
      "         ...,\n",
      "         [-0.5579],\n",
      "         [-0.5481],\n",
      "         [-0.5662]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0038],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         [0.0034]],\n",
      "\n",
      "        [[0.0040],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0036],\n",
      "         [0.0035]],\n",
      "\n",
      "        [[0.0070],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0034],\n",
      "         [0.0035],\n",
      "         [0.0035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0036],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0034],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0032],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         [0.0034]],\n",
      "\n",
      "        [[0.0041],\n",
      "         [0.0038],\n",
      "         [0.0031],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0034],\n",
      "         [0.0033]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.3352, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n",
      "________BATCH________ 2 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.6058],\n",
      "         [-0.6453],\n",
      "         [-0.5296],\n",
      "         ...,\n",
      "         [-0.5516],\n",
      "         [-0.5539],\n",
      "         [-0.5636]],\n",
      "\n",
      "        [[-0.5541],\n",
      "         [-0.4845],\n",
      "         [-0.5767],\n",
      "         ...,\n",
      "         [-0.5604],\n",
      "         [-0.5526],\n",
      "         [-0.5584]],\n",
      "\n",
      "        [[-0.6148],\n",
      "         [-0.5255],\n",
      "         [-0.5708],\n",
      "         ...,\n",
      "         [-0.5604],\n",
      "         [-0.5526],\n",
      "         [-0.5565]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3922],\n",
      "         [-0.5191],\n",
      "         [-0.5173],\n",
      "         ...,\n",
      "         [-0.5521],\n",
      "         [-0.5554],\n",
      "         [-0.5533]],\n",
      "\n",
      "        [[-0.5183],\n",
      "         [-0.5320],\n",
      "         [-0.5297],\n",
      "         ...,\n",
      "         [-0.5588],\n",
      "         [-0.5550],\n",
      "         [-0.5480]],\n",
      "\n",
      "        [[-0.3827],\n",
      "         [-0.5289],\n",
      "         [-0.5309],\n",
      "         ...,\n",
      "         [-0.5606],\n",
      "         [-0.5790],\n",
      "         [-0.5568]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0032],\n",
      "         [0.0030],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0033],\n",
      "         [0.0036],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0031],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0039],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0034],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0039],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0032],\n",
      "         [0.0033]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.5238, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n"
     ]
    }
   ],
   "source": [
    "#==========================================\n",
    "## TESTING EVALUATION / OUTPUT OF THE MODEL DEF TRAIN\n",
    "#==========================================\n",
    "\n",
    "fn_acc_alt = lambda pred, label: ((pred.max(dim=1)[0] == label).type(torch.float)).mean()\n",
    "net.train()\n",
    "train_loss = []\n",
    "acc_arr = []\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print('________BATCH________',batch_idx,'_________')\n",
    "    print(' - - - - - - - - - - - Inputs - - - - - - - - - - - ')\n",
    "    print('Inputs size:',inputs.size())\n",
    "    print('targets size:',targets.size())\n",
    "    print('Adjusted Inputs:',inputs.view([batch_size, -1, input_dim]).size())\n",
    "    \n",
    "    print(' - - - - - - - - - - - outputs - - - - - - - - - - - ')\n",
    "    inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "    targets = targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    print('Outputs size:',outputs.size())\n",
    "    print('Outputs:',outputs)\n",
    "    pred = fn_pred(outputs)\n",
    "    print('Predictions :',pred)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "    print('Loss :',loss)\n",
    "    acc = fn_acc(pred, targets)\n",
    "    acc_alt = fn_acc_alt(pred, targets)\n",
    "    print('Accuracy :',acc)\n",
    "    print('Alternative Accuracy :',acc)\n",
    "    print('Accuracy Breakdown :',(pred.max(dim=1)[1]).size())\n",
    "    #print('Accuracy no [1] :',pred.max(dim=1))#[1])\n",
    "    print('Accuracy dim=-1 :',(pred.max(dim=-1)[1]).size())\n",
    "    if batch_idx == 2:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52066622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(28, 64, num_layers=5, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#==========================================\n",
    "## TESTING TRAINING THE MODEL\n",
    "#==========================================\n",
    "# Defining inspeting net as to not interupt the main model \n",
    "net_test = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d7e07468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________BATCH # 0 _________________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      " - - - - - - Inputs size: - - - - - - \n",
      " torch.Size([64, 300, 28])\n",
      " - - - - - - Inputs size(0): - - - - - - \n",
      " 64\n",
      " - - - - - - Inputs size(0): - - - - - - \n",
      " tensor([[-2.6513, -1.1220, -2.6526,  ..., -0.3018,  3.3898, -0.3124],\n",
      "        [-2.6143, -1.1070, -2.6526,  ..., -0.3018,  3.3898, -0.3124],\n",
      "        [-2.6143, -1.0759, -2.6526,  ..., -0.3018,  3.3898, -0.3124],\n",
      "        ...,\n",
      "        [-1.5386,  0.5639, -1.6603,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [-1.5806,  0.5861, -1.6603,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [-1.5974,  0.6081, -1.6603,  ..., -0.3018, -0.2950, -0.3124]])\n",
      " - - - - - - targets size: - - - - - - \n",
      " torch.Size([64])\n",
      " - - - - - - adjusted_input size: - - - - - - \n",
      " torch.Size([64, 300, 28])\n",
      " - - - - - - outputs size: - - - - - - \n",
      " torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "#==========================================\n",
    "## TESTING TRAINING THE MODEL\n",
    "#==========================================\n",
    "\n",
    "fn_acc_alt = lambda pred, label: ((pred.max(dim=1)[0] == label).type(torch.float)).mean()\n",
    "net_test.train()\n",
    "train_loss = []\n",
    "acc_arr = []\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    if batch_idx == 1:\n",
    "        break    \n",
    "    print('________BATCH #',batch_idx,'_________________')\n",
    "    print(' - - - - - - - - - - - Inputs - - - - - - - - - - - ')\n",
    "    print(' - - - - - - Inputs size: - - - - - - \\n',inputs.size())\n",
    "    print(' - - - - - - Inputs size(0): - - - - - - \\n',inputs.size(0))\n",
    "    print(' - - - - - - Inputs size(0): - - - - - - \\n',inputs[0])\n",
    "    print(' - - - - - - targets size: - - - - - - \\n',targets.size())\n",
    "    \n",
    "    adjusted_input = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "    print(' - - - - - - adjusted_input size: - - - - - - \\n',adjusted_input.size())\n",
    "    \n",
    "    targets = targets.to(device)\n",
    "    outputs = net(adjusted_input)\n",
    "    print(' - - - - - - outputs size: - - - - - - \\n',outputs.size())\n",
    "    #print(' - - - - - - outputs: - - - - - - \\n',outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "174cb96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xtest size: torch.Size([64, 300, 28])\n",
      "ytest size: torch.Size([64])\n",
      "yhat size: torch.Size([64, 1])\n",
      "________print values____________\n",
      "--------xtest[0] - the first of 64 2D arrays :--------\n",
      " tensor([[ 2.4941,  0.2024,  2.5239,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [ 2.5143,  0.1783,  2.5239,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [ 2.5315,  0.1541,  2.5239,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        ...,\n",
      "        [ 3.7119, -1.1902,  3.7947,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [ 3.8243, -1.2032,  3.7947,  ..., -0.3018, -0.2950, -0.3124],\n",
      "        [ 3.9178, -1.2159,  3.7947,  ..., -0.3018, -0.2950, -0.3124]])\n",
      "--------ytest size--------:\n",
      " tensor([3.9460, 3.9364, 3.8598, 3.7314, 3.7364, 3.8455, 3.9420, 4.0392, 4.0789,\n",
      "        4.0968])\n",
      "--------yhat size:--------\n",
      " tensor([[0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068],\n",
      "        [0.3068]])\n"
     ]
    }
   ],
   "source": [
    "#==========================================\n",
    "## TESTING EVALUATION / OUTPUT OF THE MODEL\n",
    "#==========================================\n",
    "with torch.no_grad():\n",
    "    Pr = []\n",
    "    Va = []\n",
    "    for batch_idx, (x_test, y_test) in enumerate(test_loader):\n",
    "        if batch_idx ==1:\n",
    "            break\n",
    "        x_test = x_test.view([batch_size, -1, input_dim]).to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        model.eval()\n",
    "        yhat = model(x_test)\n",
    "        print('xtest size:',x_test.size())\n",
    "        print('ytest size:',y_test.size())\n",
    "        print('yhat size:',yhat.size())\n",
    "        print('________print values____________')\n",
    "        print('--------xtest[0] - the first of 64 2D arrays :--------\\n',x_test[0])\n",
    "        print('--------ytest size--------:\\n',y_test[0:10])\n",
    "        print('--------yhat size:--------\\n',yhat)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fb85299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied - To prove this is suitable for multivariate\n",
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
    "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        model_path = 'RNN_Test'\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "                predictions.append(yhat.to(device).detach().numpy())\n",
    "                values.append(y_test.to(device).detach().numpy())\n",
    "\n",
    "        return predictions, values\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
