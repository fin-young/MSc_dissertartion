{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "affbafda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import FX_DATA_GEN as DG\n",
    "from THEO_POULA_Model import LSTMModel, get_model\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import hstack, array\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "from THEO_POULA_Optim import THEOPOULA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6a3f97e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: ...working... failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\S1026623\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - tensorboard\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    absl-py-0.13.0             |   py38haa95532_0         175 KB\n",
      "    blinker-1.4                |   py38haa95532_0          23 KB\n",
      "    cachetools-4.2.2           |     pyhd3eb1b0_0          13 KB\n",
      "    coverage-5.5               |   py38h2bbff1b_2         272 KB\n",
      "    google-auth-1.21.3         |             py_0          57 KB\n",
      "    google-auth-oauthlib-0.4.1 |             py_2          20 KB\n",
      "    grpcio-1.36.1              |   py38hc60d5dd_1         1.7 MB\n",
      "    libprotobuf-3.17.2         |       h23ce68f_1         1.9 MB\n",
      "    markdown-3.3.4             |   py38haa95532_0         144 KB\n",
      "    oauthlib-3.1.1             |     pyhd3eb1b0_0          90 KB\n",
      "    protobuf-3.17.2            |   py38hd77b12b_0         257 KB\n",
      "    pyasn1-0.4.8               |             py_0          57 KB\n",
      "    pyasn1-modules-0.2.8       |             py_0          72 KB\n",
      "    pyjwt-2.1.0                |   py38haa95532_0          32 KB\n",
      "    requests-oauthlib-1.3.0    |             py_0          23 KB\n",
      "    rsa-4.7.2                  |     pyhd3eb1b0_1          28 KB\n",
      "    tensorboard-2.5.0          |             py_0         5.3 MB\n",
      "    tensorboard-plugin-wit-1.6.0|             py_0         630 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        10.7 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  absl-py            pkgs/main/win-64::absl-py-0.13.0-py38haa95532_0\n",
      "  blinker            pkgs/main/win-64::blinker-1.4-py38haa95532_0\n",
      "  cachetools         pkgs/main/noarch::cachetools-4.2.2-pyhd3eb1b0_0\n",
      "  coverage           pkgs/main/win-64::coverage-5.5-py38h2bbff1b_2\n",
      "  google-auth        pkgs/main/noarch::google-auth-1.21.3-py_0\n",
      "  google-auth-oauth~ pkgs/main/noarch::google-auth-oauthlib-0.4.1-py_2\n",
      "  grpcio             pkgs/main/win-64::grpcio-1.36.1-py38hc60d5dd_1\n",
      "  libprotobuf        pkgs/main/win-64::libprotobuf-3.17.2-h23ce68f_1\n",
      "  markdown           pkgs/main/win-64::markdown-3.3.4-py38haa95532_0\n",
      "  oauthlib           pkgs/main/noarch::oauthlib-3.1.1-pyhd3eb1b0_0\n",
      "  protobuf           pkgs/main/win-64::protobuf-3.17.2-py38hd77b12b_0\n",
      "  pyasn1             pkgs/main/noarch::pyasn1-0.4.8-py_0\n",
      "  pyasn1-modules     pkgs/main/noarch::pyasn1-modules-0.2.8-py_0\n",
      "  pyjwt              pkgs/main/win-64::pyjwt-2.1.0-py38haa95532_0\n",
      "  requests-oauthlib  pkgs/main/noarch::requests-oauthlib-1.3.0-py_0\n",
      "  rsa                pkgs/main/noarch::rsa-4.7.2-pyhd3eb1b0_1\n",
      "  tensorboard        pkgs/main/noarch::tensorboard-2.5.0-py_0\n",
      "  tensorboard-plugi~ pkgs/main/noarch::tensorboard-plugin-wit-1.6.0-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "coverage-5.5         | 272 KB    |            |   0% \n",
      "coverage-5.5         | 272 KB    | 5          |   6% \n",
      "coverage-5.5         | 272 KB    | #####2     |  53% \n",
      "coverage-5.5         | 272 KB    | ########## | 100% \n",
      "coverage-5.5         | 272 KB    | ########## | 100% \n",
      "\n",
      "protobuf-3.17.2      | 257 KB    |            |   0% \n",
      "protobuf-3.17.2      | 257 KB    | ###7       |  37% \n",
      "protobuf-3.17.2      | 257 KB    | ########## | 100% \n",
      "protobuf-3.17.2      | 257 KB    | ########## | 100% \n",
      "\n",
      "absl-py-0.13.0       | 175 KB    |            |   0% \n",
      "absl-py-0.13.0       | 175 KB    | #######3   |  73% \n",
      "absl-py-0.13.0       | 175 KB    | ########## | 100% \n",
      "\n",
      "oauthlib-3.1.1       | 90 KB     |            |   0% \n",
      "oauthlib-3.1.1       | 90 KB     | #######1   |  71% \n",
      "oauthlib-3.1.1       | 90 KB     | ########## | 100% \n",
      "\n",
      "pyasn1-0.4.8         | 57 KB     |            |   0% \n",
      "pyasn1-0.4.8         | 57 KB     | ########## | 100% \n",
      "pyasn1-0.4.8         | 57 KB     | ########## | 100% \n",
      "\n",
      "pyasn1-modules-0.2.8 | 72 KB     |            |   0% \n",
      "pyasn1-modules-0.2.8 | 72 KB     | ########## | 100% \n",
      "pyasn1-modules-0.2.8 | 72 KB     | ########## | 100% \n",
      "\n",
      "requests-oauthlib-1. | 23 KB     |            |   0% \n",
      "requests-oauthlib-1. | 23 KB     | ########## | 100% \n",
      "requests-oauthlib-1. | 23 KB     | ########## | 100% \n",
      "\n",
      "grpcio-1.36.1        | 1.7 MB    |            |   0% \n",
      "grpcio-1.36.1        | 1.7 MB    |            |   1% \n",
      "grpcio-1.36.1        | 1.7 MB    | ###2       |  32% \n",
      "grpcio-1.36.1        | 1.7 MB    | #######4   |  74% \n",
      "grpcio-1.36.1        | 1.7 MB    | ########## | 100% \n",
      "\n",
      "pyjwt-2.1.0          | 32 KB     |            |   0% \n",
      "pyjwt-2.1.0          | 32 KB     | ########## | 100% \n",
      "pyjwt-2.1.0          | 32 KB     | ########## | 100% \n",
      "\n",
      "cachetools-4.2.2     | 13 KB     |            |   0% \n",
      "cachetools-4.2.2     | 13 KB     | ########## | 100% \n",
      "cachetools-4.2.2     | 13 KB     | ########## | 100% \n",
      "\n",
      "tensorboard-plugin-w | 630 KB    |            |   0% \n",
      "tensorboard-plugin-w | 630 KB    | 5          |   5% \n",
      "tensorboard-plugin-w | 630 KB    | ########8  |  89% \n",
      "tensorboard-plugin-w | 630 KB    | ########## | 100% \n",
      "\n",
      "markdown-3.3.4       | 144 KB    |            |   0% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "markdown-3.3.4       | 144 KB    | ########## | 100% \n",
      "\n",
      "tensorboard-2.5.0    | 5.3 MB    |            |   0% \n",
      "tensorboard-2.5.0    | 5.3 MB    | 2          |   2% \n",
      "tensorboard-2.5.0    | 5.3 MB    | #1         |  12% \n",
      "tensorboard-2.5.0    | 5.3 MB    | #7         |  18% \n",
      "tensorboard-2.5.0    | 5.3 MB    | ###1       |  31% \n",
      "tensorboard-2.5.0    | 5.3 MB    | ####       |  40% \n",
      "tensorboard-2.5.0    | 5.3 MB    | ######3    |  63% \n",
      "tensorboard-2.5.0    | 5.3 MB    | ########2  |  83% \n",
      "tensorboard-2.5.0    | 5.3 MB    | #########7 |  97% \n",
      "tensorboard-2.5.0    | 5.3 MB    | ########## | 100% \n",
      "\n",
      "blinker-1.4          | 23 KB     |            |   0% \n",
      "blinker-1.4          | 23 KB     | ########## | 100% \n",
      "blinker-1.4          | 23 KB     | ########## | 100% \n",
      "\n",
      "google-auth-1.21.3   | 57 KB     |            |   0% \n",
      "google-auth-1.21.3   | 57 KB     | ########## | 100% \n",
      "google-auth-1.21.3   | 57 KB     | ########## | 100% \n",
      "\n",
      "rsa-4.7.2            | 28 KB     |            |   0% \n",
      "rsa-4.7.2            | 28 KB     | ########## | 100% \n",
      "rsa-4.7.2            | 28 KB     | ########## | 100% \n",
      "\n",
      "libprotobuf-3.17.2   | 1.9 MB    |            |   0% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #          |  11% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ###3       |  34% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #####3     |  54% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #######5   |  76% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | #########7 |  98% \n",
      "libprotobuf-3.17.2   | 1.9 MB    | ########## | 100% \n",
      "\n",
      "google-auth-oauthlib | 20 KB     |            |   0% \n",
      "google-auth-oauthlib | 20 KB     | ########## | 100% \n",
      "google-auth-oauthlib | 20 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " conda install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32371ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\S1026623\\Anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pytorch\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    cudatoolkit-10.1.243       |       h74a9793_0       300.3 MB\n",
      "    libuv-1.40.0               |       he774522_0         255 KB\n",
      "    ninja-1.10.2               |       h6d14046_1         250 KB\n",
      "    pytorch-1.8.1              |py3.8_cuda10.1_cudnn7_0       835.7 MB  pytorch\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        1.11 GB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/win-64::cudatoolkit-10.1.243-h74a9793_0\n",
      "  libuv              pkgs/main/win-64::libuv-1.40.0-he774522_0\n",
      "  ninja              pkgs/main/win-64::ninja-1.10.2-h6d14046_1\n",
      "  pytorch            pytorch/win-64::pytorch-1.8.1-py3.8_cuda10.1_cudnn7_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libuv-1.40.0         | 255 KB    |            |   0% \n",
      "libuv-1.40.0         | 255 KB    | 6          |   6% \n",
      "libuv-1.40.0         | 255 KB    | ###7       |  38% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "libuv-1.40.0         | 255 KB    | ########## | 100% \n",
      "\n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   0% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  |            |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   1% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 1          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   2% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 2          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   3% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 3          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   4% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 4          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   5% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 5          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   6% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 6          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   7% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 7          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   8% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 8          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |   9% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | 9          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  10% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #          |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  11% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #1         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  12% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #2         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  13% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #3         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  14% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #4         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  15% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #5         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  16% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #6         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  17% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #7         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  18% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #8         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  19% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | #9         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  20% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##         |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  21% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##1        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  22% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##2        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  23% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##3        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  24% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##4        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  25% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##5        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  26% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##6        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  27% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##7        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  28% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##8        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  29% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ##9        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  30% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###        |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  31% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###1       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  32% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###2       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  33% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###3       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  34% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###4       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  35% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###5       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  36% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  37% \n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.pytorch-1.8.1        | 835.7 MB  | ###6       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###6       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  37% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###7       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  38% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###8       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  39% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  40% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ###9       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  40% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####       |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  41% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####1      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  42% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####2      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  43% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####3      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  44% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####4      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  45% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####5      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  46% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####6      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  47% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####7      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  48% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####8      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  49% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | ####9      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  50% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####      |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  51% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####1     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  52% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####2     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  53% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####3     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  54% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####4     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  55% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####5     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  56% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####6     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  57% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####7     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  58% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####8     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  59% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | #####9     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  60% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######     |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  61% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######1    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  62% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######2    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  63% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######3    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  64% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######4    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  65% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######5    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  66% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######6    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  67% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######7    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  68% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######8    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  69% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | ######9    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  70% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######    |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  71% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######1   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  72% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######2   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  73% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######3   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  74% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######4   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  75% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######5   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  76% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######6   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  77% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######7   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  78% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######8   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  79% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | #######9   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  80% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########   |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  81% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########1  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  82% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########2  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  83% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########3  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  84% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########4  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  85% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########5  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  86% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########6  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  87% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########7  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  88% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########8  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  89% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########9  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  90% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########  |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  91% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########1 |  92% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  92% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########2 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  93% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########3 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  94% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########4 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  95% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########5 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  96% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########6 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  97% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########7 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  98% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########8 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 |  99% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 | 100% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 | 100% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 | 100% \n",
      "pytorch-1.8.1        | 835.7 MB  | #########9 | 100% \n",
      "pytorch-1.8.1        | 835.7 MB  | ########## | 100% \n",
      "\n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   0% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  |            |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   1% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 1          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   2% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 2          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   3% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 3          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   4% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 4          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   5% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 5          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   6% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 6          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 7          |   7% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 7          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 7          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 8          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 8          |   8% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 8          |   9% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |   9% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |   9% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |  10% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | 9          |  10% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #          |  10% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #          |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #          |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #1         |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #1         |  11% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #1         |  12% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #1         |  12% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #2         |  12% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #2         |  12% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #2         |  13% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  13% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  13% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  14% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #3         |  14% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #4         |  14% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #4         |  14% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #4         |  15% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  15% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  15% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  16% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #5         |  16% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #6         |  16% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #6         |  17% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #6         |  17% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #7         |  17% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #7         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #7         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  18% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #8         |  19% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #9         |  19% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #9         |  19% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #9         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  20% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  21% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##         |  21% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  21% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##1        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  22% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##2        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  23% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##3        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  24% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##4        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##5        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##5        |  25% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##5        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  26% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  27% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##6        |  27% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##7        |  27% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##7        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##7        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  28% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  29% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##8        |  29% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  29% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ##9        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  30% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###        |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###1       |  31% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###1       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###1       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  32% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###2       |  33% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  33% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  33% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  34% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###3       |  34% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###4       |  34% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###4       |  35% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  35% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  35% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  36% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###5       |  36% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###6       |  36% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###6       |  37% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###7       |  37% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###7       |  37% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###7       |  38% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  38% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  38% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  39% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###8       |  39% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###9       |  39% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###9       |  40% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ###9       |  40% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####       |  40% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####       |  40% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####       |  41% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####1      |  41% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####1      |  41% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####1      |  42% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  42% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  42% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####2      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####3      |  43% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####3      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####3      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  44% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####4      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  45% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####5      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  46% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####6      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  47% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####7      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  48% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####8      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  49% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ####9      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  50% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####      |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  51% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####1     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  52% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####2     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  53% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####3     |  54% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  54% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####4     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####5     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####5     |  55% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####5     |  56% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####6     |  56% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####6     |  56% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####6     |  57% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####6     |  57% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####7     |  57% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####7     |  58% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####7     |  58% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####8     |  58% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####8     |  58% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####8     |  59% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####9     |  59% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####9     |  59% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####9     |  60% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #####9     |  60% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######     |  60% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######     |  61% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######     |  61% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######1    |  61% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######1    |  61% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######1    |  62% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  62% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  62% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######2    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######3    |  63% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######3    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######3    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  64% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######4    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  65% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######5    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  66% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######6    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  67% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######7    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  68% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######8    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######9    |  69% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ######9    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  70% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######    |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######1   |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######1   |  71% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######1   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  72% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######2   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  73% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######3   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  74% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######4   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  75% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######5   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  76% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  77% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######6   |  77% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######7   |  77% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######7   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######7   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  78% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  79% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######8   |  79% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######9   |  79% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######9   |  80% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #######9   |  80% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########   |  80% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########   |  81% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########   |  81% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########1  |  81% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########1  |  82% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########1  |  82% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########2  |  82% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########2  |  82% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########2  |  83% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  83% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  83% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  84% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########3  |  84% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########4  |  84% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########4  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########4  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  85% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  86% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########5  |  86% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  86% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########6  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  87% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########7  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  88% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########8  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  89% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########9  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  90% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########  |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  91% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########1 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  92% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########2 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  93% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########3 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  94% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########4 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  95% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########5 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  96% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########6 |  97% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########7 |  97% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########7 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  98% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  99% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########8 |  99% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########9 |  99% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########9 | 100% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | #########9 | 100% \n",
      "cudatoolkit-10.1.243 | 300.3 MB  | ########## | 100% \n",
      "\n",
      "ninja-1.10.2         | 250 KB    |            |   0% \n",
      "ninja-1.10.2         | 250 KB    | ######3    |  64% \n",
      "ninja-1.10.2         | 250 KB    | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n"
     ]
    }
   ],
   "source": [
    "conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#daily FX Rate dataset call\n",
    "#DG.Get_curr_data('MX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0df15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Macro economic dataset call\n",
    "#MEX = DG.MacEcon_TS('MX',1980, 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5feef7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of Macro economic dataset\n",
    "#DG.describe_MacEcon_TS(MEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be2b3b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joint dataset of Macro economic & FX Rates combined\n",
    "mex_full = DG.Get_FX_MacEcon_Data('MX')\n",
    "#mex_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393723a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description to know which columns to remove from dataframe\n",
    "DG.describe_MacEcon_TS(mex_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74174106",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEX_copy = mex_full.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe210396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add one hot dummy columns for month\n",
    "MEX_copy = (DG.Add_dummy_MoY(MEX_copy))\n",
    "#MEX_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a15233ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>First Valid</th>\n",
       "      <th>Last Valid</th>\n",
       "      <th>Null Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MXN</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sin_DoY</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ave Monthly USD FX Rate</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inflation (CPI) %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deposit Interest Rate %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lending Interest Rate %</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NY.GDP.MKTP.CD</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Real Interest Rate(%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Foreign Exchange Reserves(%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M2 Multiplier Growth (%)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>REED 12mth std dev</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Current Account(%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>FDI(%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Capital Formations(USD)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Gov Consumption Expendature (%GDP)</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GDP % Growth</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MoY_is_1</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MoY_is_2</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MoY_is_3</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MoY_is_4</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MoY_is_5</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MoY_is_6</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MoY_is_7</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MoY_is_8</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MoY_is_9</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MoY_is_10</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MoY_is_11</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoY_is_12</td>\n",
       "      <td>1993-11-08</td>\n",
       "      <td>2020-11-30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Features First Valid Last Valid  Null Values\n",
       "0                                  MXN  1993-11-08 2020-11-30            0\n",
       "1                              sin_DoY  1993-11-08 2020-11-30            0\n",
       "2              Ave Monthly USD FX Rate  1993-11-08 2020-11-30            0\n",
       "3                    Inflation (CPI) %  1993-11-08 2020-11-30            0\n",
       "4              Deposit Interest Rate %  1993-11-08 2020-11-30            0\n",
       "5              Lending Interest Rate %  1993-11-08 2020-11-30            0\n",
       "6                       NY.GDP.MKTP.CD  1993-11-08 2020-11-30            0\n",
       "7                Real Interest Rate(%)  1993-11-08 2020-11-30            0\n",
       "8         Foreign Exchange Reserves(%)  1993-11-08 2020-11-30            0\n",
       "9             M2 Multiplier Growth (%)  1993-11-08 2020-11-30            0\n",
       "10                  REED 12mth std dev  1993-11-08 2020-11-30            0\n",
       "11               Current Account(%GDP)  1993-11-08 2020-11-30            0\n",
       "12                           FDI(%GDP)  1993-11-08 2020-11-30            0\n",
       "13             Capital Formations(USD)  1993-11-08 2020-11-30            0\n",
       "14  Gov Consumption Expendature (%GDP)  1993-11-08 2020-11-30            0\n",
       "15                        GDP % Growth  1993-11-08 2020-11-30            0\n",
       "16                            MoY_is_1  1993-11-08 2020-11-30            0\n",
       "17                            MoY_is_2  1993-11-08 2020-11-30            0\n",
       "18                            MoY_is_3  1993-11-08 2020-11-30            0\n",
       "19                            MoY_is_4  1993-11-08 2020-11-30            0\n",
       "20                            MoY_is_5  1993-11-08 2020-11-30            0\n",
       "21                            MoY_is_6  1993-11-08 2020-11-30            0\n",
       "22                            MoY_is_7  1993-11-08 2020-11-30            0\n",
       "23                            MoY_is_8  1993-11-08 2020-11-30            0\n",
       "24                            MoY_is_9  1993-11-08 2020-11-30            0\n",
       "25                           MoY_is_10  1993-11-08 2020-11-30            0\n",
       "26                           MoY_is_11  1993-11-08 2020-11-30            0\n",
       "27                           MoY_is_12  1993-11-08 2020-11-30            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description of cleaned and one-hott'ed dataset\n",
    "MEX_copy.drop(columns = ['M2/Reserves','Domestic Credit to GDP','Portfolio Investments(USD)','Total Debt(USD)','Short Term Debt(USD)','cos_DoY','Yr','DoM'], inplace = True)\n",
    "DG.describe_MacEcon_TS(MEX_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d747a891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MXN_X</th>\n",
       "      <th>sin_DoY</th>\n",
       "      <th>Ave Monthly USD FX Rate</th>\n",
       "      <th>Inflation (CPI) %</th>\n",
       "      <th>Deposit Interest Rate %</th>\n",
       "      <th>Lending Interest Rate %</th>\n",
       "      <th>NY.GDP.MKTP.CD</th>\n",
       "      <th>Real Interest Rate(%)</th>\n",
       "      <th>Foreign Exchange Reserves(%)</th>\n",
       "      <th>M2 Multiplier Growth (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>MoY_is_4</th>\n",
       "      <th>MoY_is_5</th>\n",
       "      <th>MoY_is_6</th>\n",
       "      <th>MoY_is_7</th>\n",
       "      <th>MoY_is_8</th>\n",
       "      <th>MoY_is_9</th>\n",
       "      <th>MoY_is_10</th>\n",
       "      <th>MoY_is_11</th>\n",
       "      <th>MoY_is_12</th>\n",
       "      <th>MXN_Y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1993-11-09</th>\n",
       "      <td>3.152</td>\n",
       "      <td>-0.790946</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-10</th>\n",
       "      <td>3.240</td>\n",
       "      <td>-0.780296</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-11-12</th>\n",
       "      <td>3.240</td>\n",
       "      <td>-0.758306</td>\n",
       "      <td>3.1553</td>\n",
       "      <td>18.715507</td>\n",
       "      <td>14.74</td>\n",
       "      <td>17.95</td>\n",
       "      <td>5.007361e+11</td>\n",
       "      <td>-0.765507</td>\n",
       "      <td>3.788303</td>\n",
       "      <td>4.49811</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            MXN_X   sin_DoY  Ave Monthly USD FX Rate  Inflation (CPI) %  \\\n",
       "Date                                                                      \n",
       "1993-11-09  3.152 -0.790946                   3.1553          18.715507   \n",
       "1993-11-10  3.240 -0.780296                   3.1553          18.715507   \n",
       "1993-11-12  3.240 -0.758306                   3.1553          18.715507   \n",
       "\n",
       "            Deposit Interest Rate %  Lending Interest Rate %  NY.GDP.MKTP.CD  \\\n",
       "Date                                                                           \n",
       "1993-11-09                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-10                    14.74                    17.95    5.007361e+11   \n",
       "1993-11-12                    14.74                    17.95    5.007361e+11   \n",
       "\n",
       "            Real Interest Rate(%)  Foreign Exchange Reserves(%)  \\\n",
       "Date                                                              \n",
       "1993-11-09              -0.765507                      3.788303   \n",
       "1993-11-10              -0.765507                      3.788303   \n",
       "1993-11-12              -0.765507                      3.788303   \n",
       "\n",
       "            M2 Multiplier Growth (%)  ...  MoY_is_4  MoY_is_5  MoY_is_6  \\\n",
       "Date                                  ...                                 \n",
       "1993-11-09                   4.49811  ...         0         0         0   \n",
       "1993-11-10                   4.49811  ...         0         0         0   \n",
       "1993-11-12                   4.49811  ...         0         0         0   \n",
       "\n",
       "            MoY_is_7  MoY_is_8  MoY_is_9  MoY_is_10  MoY_is_11  MoY_is_12  \\\n",
       "Date                                                                        \n",
       "1993-11-09         0         0         0          0          1          0   \n",
       "1993-11-10         0         0         0          0          1          0   \n",
       "1993-11-12         0         0         0          0          1          0   \n",
       "\n",
       "            MXN_Y  \n",
       "Date               \n",
       "1993-11-09   3.24  \n",
       "1993-11-10   3.24  \n",
       "1993-11-12   3.24  \n",
       "\n",
       "[3 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shift DF so that there is a FX_X and FX_Y at the start & end of the DF, respectively. \n",
    "MEX_SHF = DG.shift_FX(MEX_copy)\n",
    "MEX_SHF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ee7d48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "#Set split param\n",
    "test_ratio = 0.2\n",
    "val_ratio = test_ratio / (1 - test_ratio)\n",
    "\n",
    "#Cut into Features and Target Variable\n",
    "y_name = MEX_SHF.iloc[:,-1].name\n",
    "X, y = MEX_SHF.drop([y_name], axis=1) , MEX_SHF[[y_name]]\n",
    "\n",
    "#Train & Test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_ratio, shuffle=False)\n",
    "#Train & Validation \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=val_ratio, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90a4ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalise data using standard scalar\n",
    "#Fit each row of data as an array\n",
    "scaler = DG.get_scaler('standard')\n",
    "X_train_arr = scaler.fit_transform(X_train)\n",
    "X_val_arr = scaler.transform(X_val)\n",
    "X_test_arr = scaler.transform(X_test)\n",
    "\n",
    "y_train_arr = scaler.fit_transform(y_train)\n",
    "y_val_arr = scaler.transform(y_val)\n",
    "y_test_arr = scaler.transform(y_test)\n",
    "\n",
    "#Stack the data back together before splitting the sequence\n",
    "train_arr = hstack((X_train_arr, y_train_arr))\n",
    "val_arr = hstack((X_val_arr, y_val_arr))\n",
    "test_arr = hstack((X_test_arr, y_test_arr))\n",
    "\n",
    "#split sequence will create a lag of the past 300 entries of the dataframe\n",
    "#\n",
    "n_steps = 300\n",
    "X_train_split, y_train_split = DG.split_sequences(train_arr,n_steps)\n",
    "X_val_split, y_val_split = DG.split_sequences(val_arr,n_steps)\n",
    "X_test_split, y_test_split = DG.split_sequences(test_arr,n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5fd2fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_split[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e943103",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_features = torch.Tensor(X_train_split)\n",
    "train_targets = torch.Tensor(y_train_split)\n",
    "val_features = torch.Tensor(X_val_split)\n",
    "val_targets = torch.Tensor(y_val_split)\n",
    "test_features = torch.Tensor(X_test_split)\n",
    "test_targets = torch.Tensor(y_test_split)\n",
    "\n",
    "#Joint Tensor of \n",
    "train = TensorDataset(train_features, train_targets)\n",
    "val = TensorDataset(val_features, val_targets)\n",
    "test = TensorDataset(test_features, test_targets)\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4360a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "input_dim = len(X_train.columns) #sequence length\n",
    "output_dim = 1\n",
    "seq_length = 300\n",
    "hidden_dim = 64\n",
    "layer_dim = 3\n",
    "batch_size = 64\n",
    "dropout = 0.2\n",
    "n_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6\n",
    "\n",
    "model_params = {'input_dim': input_dim,\n",
    "                'hidden_dim' : hidden_dim,\n",
    "                'seq_length' : seq_length,\n",
    "                'layer_dim' : layer_dim,\n",
    "                'output_dim' : output_dim,\n",
    "                'dropout_prob' : dropout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d78bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LSTMModel(\n",
      "  (lstm): LSTM(28, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Call the LSTM Model from THEO_PULA_Model\n",
    "model = get_model(\"lstm\", model_params)\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "print(\"Model:\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b98cc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify Optimizer\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46246f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "#opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_dim)\n",
    "#opt.plot_losses()\n",
    "\n",
    "#predictions, values = opt.evaluate(test_loader_one, batch_size=1, n_features=input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeaa746f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "\n",
    "parser = argparse.ArgumentParser(description = 'pytorch CIFAR10')\n",
    "parser.add_argument('-f','--file',help='Path for input file. First line should contain number of lines to search in')\n",
    "parser.add_argument('--trial', default='trial1', type=str)\n",
    "parser.add_argument('--lr', default=1e-2, type=float, help='learning rate')\n",
    "parser.add_argument('--resume', '-r', action='store_true', help='resume from checkpoint')\n",
    "parser.add_argument('--batch_size', default=64, type=int)\n",
    "parser.add_argument('--model_name', default='lstm', type=str)\n",
    "parser.add_argument('--num_epoch', default=200, type=int, dest='num_epoch')\n",
    "parser.add_argument('--optimizer_name', default='THEOPOULA', type=str)\n",
    "parser.add_argument('--eta', default='0', type=float)\n",
    "parser.add_argument('--beta', default='1e14', type=float)\n",
    "parser.add_argument('--r', default=5, type=int)\n",
    "parser.add_argument('--eps', default=1e-4, type=float)\n",
    "parser.add_argument('--act_fn', default='silu', type=str)\n",
    "\n",
    "parser.add_argument('--log_dir', default='./log/', type=str)\n",
    "parser.add_argument('--ckpt_dir', default='./ckpt/', type=str)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "best_loss = 999\n",
    "state = []\n",
    "start_epoch = 1\n",
    "trial = args.trial\n",
    "batch_size = args.batch_size\n",
    "num_epoch = args.num_epoch \n",
    "optimizer_name = args.optimizer_name\n",
    "act_fn = args.act_fn\n",
    "model_name = args.model_name\n",
    "model = get_model(args.model_name, model_params)\n",
    "lr = args.lr\n",
    "eta = args.eta\n",
    "beta = args.beta\n",
    "r = args.r\n",
    "eps = args.eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "547f9b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Len of a dataloader is the number of batches: len(dataloader) = dataset size / batch size\n",
    "num_data = len(train_loader)\n",
    "\n",
    "num_batch = np.ceil(num_data / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e34a09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model.. on {cpu}\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model.. on {%s}'%device)\n",
    "net = model\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5592788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(28, 64, num_layers=3, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3e7f949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Setting optimizer.. {ADAM}\n"
     ]
    }
   ],
   "source": [
    "# To specfy when calling \n",
    "optimizer_name = 'ADAM'\n",
    "#_______________________________________________\n",
    "print('==> Setting optimizer.. {%s}'%optimizer_name)\n",
    "if optimizer_name == 'SGD':\n",
    "    optimizer = optim.SGD(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'RMSProp':\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'ADAM':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "elif optimizer_name == 'AMSGrad':\n",
    "    optimizer = optim.Adam(net.parameters(), lr=lr, amsgrad=True)\n",
    "elif optimizer_name == 'THEOPOULA':\n",
    "    optimizer = THEOPOULA(net.parameters(), lr=lr, eta=eta, beta=args.beta, r=r, eps=eps)\n",
    "\n",
    "\n",
    "\n",
    "if optimizer_name == 'THEOPOULA':\n",
    "    experiment_name = '%s_%s_bs{%d}_lr{%.1e}_epoch{%d}_eta{%.1e}_beta{%.1e}_r{%d}_eps{%.1e}' \\\n",
    "                      %(optimizer_name, model, batch_size, lr, num_epoch, eta, beta, r, eps)\n",
    "else:\n",
    "    experiment_name = '%s_%s_bs{%d}_lr{%.1e}_eps{%.1e}_epoch{%d}'%(optimizer_name, model_name, batch_size, lr, eps, num_epoch)\n",
    "    \n",
    "\n",
    "\n",
    "log_dir = args.log_dir + experiment_name\n",
    "ckpt_dir = args.ckpt_dir + experiment_name\n",
    "\n",
    "fn_pred = lambda output: torch.softmax(output, dim=1)\n",
    "fn_acc = lambda pred, label: ((pred.max(dim=1)[1] == label).type(torch.float)).mean()\n",
    "\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "## Training\n",
    "\n",
    "history = {'training_loss': [],\n",
    "           'test_loss': [],\n",
    "           'training_acc': [],\n",
    "           'test_acc': [],\n",
    "           }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e63ea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________BATCH________ 0 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.4095],\n",
      "         [-0.7014],\n",
      "         [-0.9768],\n",
      "         ...,\n",
      "         [-1.1086],\n",
      "         [-1.1109],\n",
      "         [-1.1180]],\n",
      "\n",
      "        [[-0.6710],\n",
      "         [-0.6634],\n",
      "         [-1.0301],\n",
      "         ...,\n",
      "         [-1.1114],\n",
      "         [-1.1331],\n",
      "         [-1.1154]],\n",
      "\n",
      "        [[-0.6923],\n",
      "         [-0.4908],\n",
      "         [-0.5807],\n",
      "         ...,\n",
      "         [-1.1197],\n",
      "         [-1.1102],\n",
      "         [-1.1123]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.5125],\n",
      "         [-0.5504],\n",
      "         [-0.5479],\n",
      "         ...,\n",
      "         [-1.1252],\n",
      "         [-1.0533],\n",
      "         [-1.0490]],\n",
      "\n",
      "        [[-0.9195],\n",
      "         [-1.0772],\n",
      "         [-1.1065],\n",
      "         ...,\n",
      "         [-1.0535],\n",
      "         [-1.0421],\n",
      "         [-1.1152]],\n",
      "\n",
      "        [[-0.8702],\n",
      "         [-1.0802],\n",
      "         [-1.0949],\n",
      "         ...,\n",
      "         [-1.0311],\n",
      "         [-1.1086],\n",
      "         [-1.0612]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0067],\n",
      "         [0.0050],\n",
      "         [0.0038],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0050],\n",
      "         [0.0051],\n",
      "         [0.0035],\n",
      "         ...,\n",
      "         [0.0032],\n",
      "         [0.0032],\n",
      "         [0.0032]],\n",
      "\n",
      "        [[0.0048],\n",
      "         [0.0058],\n",
      "         [0.0053],\n",
      "         ...,\n",
      "         [0.0031],\n",
      "         [0.0031],\n",
      "         [0.0031]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0060],\n",
      "         [0.0058],\n",
      "         [0.0058],\n",
      "         ...,\n",
      "         [0.0032],\n",
      "         [0.0035],\n",
      "         [0.0035]],\n",
      "\n",
      "        [[0.0040],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0036],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0042],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0036],\n",
      "         [0.0033],\n",
      "         [0.0035]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.1282, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n",
      "________BATCH________ 1 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.9806],\n",
      "         [-1.0811],\n",
      "         [-1.1063],\n",
      "         ...,\n",
      "         [-1.0596],\n",
      "         [-1.1069],\n",
      "         [-1.0974]],\n",
      "\n",
      "        [[-0.9139],\n",
      "         [-1.0738],\n",
      "         [-1.1043],\n",
      "         ...,\n",
      "         [-1.0427],\n",
      "         [-1.0262],\n",
      "         [-1.0664]],\n",
      "\n",
      "        [[-0.3519],\n",
      "         [-1.0462],\n",
      "         [-1.1188],\n",
      "         ...,\n",
      "         [-1.0711],\n",
      "         [-1.0461],\n",
      "         [-1.0506]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4813],\n",
      "         [-0.5109],\n",
      "         [-0.5750],\n",
      "         ...,\n",
      "         [-0.5560],\n",
      "         [-0.5479],\n",
      "         [-0.5705]],\n",
      "\n",
      "        [[-0.5844],\n",
      "         [-0.5055],\n",
      "         [-0.5579],\n",
      "         ...,\n",
      "         [-0.5484],\n",
      "         [-0.5660],\n",
      "         [-0.5499]],\n",
      "\n",
      "        [[-0.3578],\n",
      "         [-0.4196],\n",
      "         [-0.6133],\n",
      "         ...,\n",
      "         [-0.5579],\n",
      "         [-0.5481],\n",
      "         [-0.5662]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0038],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         [0.0034]],\n",
      "\n",
      "        [[0.0040],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0035],\n",
      "         [0.0036],\n",
      "         [0.0035]],\n",
      "\n",
      "        [[0.0070],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0034],\n",
      "         [0.0035],\n",
      "         [0.0035]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0036],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0034],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0032],\n",
      "         [0.0035],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         [0.0034]],\n",
      "\n",
      "        [[0.0041],\n",
      "         [0.0038],\n",
      "         [0.0031],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0034],\n",
      "         [0.0033]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.3352, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n",
      "________BATCH________ 2 _________\n",
      " - - - - - - - - - - - Inputs - - - - - - - - - - - \n",
      "Inputs size: torch.Size([64, 300, 28])\n",
      "targets size: torch.Size([64])\n",
      "Adjusted Inputs: torch.Size([64, 300, 28])\n",
      " - - - - - - - - - - - outputs - - - - - - - - - - - \n",
      "Outputs size: torch.Size([64, 300, 1])\n",
      "Outputs: tensor([[[-0.6058],\n",
      "         [-0.6453],\n",
      "         [-0.5296],\n",
      "         ...,\n",
      "         [-0.5516],\n",
      "         [-0.5539],\n",
      "         [-0.5636]],\n",
      "\n",
      "        [[-0.5541],\n",
      "         [-0.4845],\n",
      "         [-0.5767],\n",
      "         ...,\n",
      "         [-0.5604],\n",
      "         [-0.5526],\n",
      "         [-0.5584]],\n",
      "\n",
      "        [[-0.6148],\n",
      "         [-0.5255],\n",
      "         [-0.5708],\n",
      "         ...,\n",
      "         [-0.5604],\n",
      "         [-0.5526],\n",
      "         [-0.5565]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3922],\n",
      "         [-0.5191],\n",
      "         [-0.5173],\n",
      "         ...,\n",
      "         [-0.5521],\n",
      "         [-0.5554],\n",
      "         [-0.5533]],\n",
      "\n",
      "        [[-0.5183],\n",
      "         [-0.5320],\n",
      "         [-0.5297],\n",
      "         ...,\n",
      "         [-0.5588],\n",
      "         [-0.5550],\n",
      "         [-0.5480]],\n",
      "\n",
      "        [[-0.3827],\n",
      "         [-0.5289],\n",
      "         [-0.5309],\n",
      "         ...,\n",
      "         [-0.5606],\n",
      "         [-0.5790],\n",
      "         [-0.5568]]], grad_fn=<AddBackward0>)\n",
      "Predictions : tensor([[[0.0032],\n",
      "         [0.0030],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0033],\n",
      "         [0.0036],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0031],\n",
      "         [0.0034],\n",
      "         [0.0033],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.0039],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0034],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0033],\n",
      "         [0.0033]],\n",
      "\n",
      "        [[0.0039],\n",
      "         [0.0034],\n",
      "         [0.0034],\n",
      "         ...,\n",
      "         [0.0033],\n",
      "         [0.0032],\n",
      "         [0.0033]]], grad_fn=<SoftmaxBackward>)\n",
      "Loss : tensor(0.5238, grad_fn=<MseLossBackward>)\n",
      "Accuracy : tensor(0.)\n",
      "Alternative Accuracy : tensor(0.)\n",
      "Accuracy Breakdown : torch.Size([64, 1])\n",
      "Accuracy dim=-1 : torch.Size([64, 300])\n"
     ]
    }
   ],
   "source": [
    "fn_acc_alt = lambda pred, label: ((pred.max(dim=1)[0] == label).type(torch.float)).mean()\n",
    "net.train()\n",
    "train_loss = []\n",
    "acc_arr = []\n",
    "for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "    print('________BATCH________',batch_idx,'_________')\n",
    "    print(' - - - - - - - - - - - Inputs - - - - - - - - - - - ')\n",
    "    print('Inputs size:',inputs.size())\n",
    "    print('targets size:',targets.size())\n",
    "    print('Adjusted Inputs:',inputs.view([batch_size, -1, input_dim]).size())\n",
    "    \n",
    "    print(' - - - - - - - - - - - outputs - - - - - - - - - - - ')\n",
    "    inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "    targets = targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = net(inputs)\n",
    "    print('Outputs size:',outputs.size())\n",
    "    print('Outputs:',outputs)\n",
    "    pred = fn_pred(outputs)\n",
    "    print('Predictions :',pred)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "    print('Loss :',loss)\n",
    "    acc = fn_acc(pred, targets)\n",
    "    acc_alt = fn_acc_alt(pred, targets)\n",
    "    print('Accuracy :',acc)\n",
    "    print('Alternative Accuracy :',acc)\n",
    "    print('Accuracy Breakdown :',(pred.max(dim=1)[1]).size())\n",
    "    #print('Accuracy no [1] :',pred.max(dim=1))#[1])\n",
    "    print('Accuracy dim=-1 :',(pred.max(dim=-1)[1]).size())\n",
    "    if batch_idx == 2:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #loss.backward()\n",
    "    #optimizer.step()\n",
    "\n",
    "    #train_loss += [loss.item()]\n",
    "    #acc_arr += [acc.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39a84365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = []\n",
    "    acc_arr = []\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        #inputs = inputs.to(device)\n",
    "        inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        pred = fn_pred(outputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        acc = fn_acc(pred, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += [loss.item()]\n",
    "        acc_arr += [acc.item()]\n",
    "\n",
    "        if batch_idx%200 == 0:\n",
    "            print('TRAIN: EPOCH %04d/%04d | BATCH %04d/%04d | LOSS: %.4f |  ACC %.4f' %\n",
    "              (epoch, args.num_epoch, batch_idx, num_batch, train_loss[-1], acc_arr[-1]))\n",
    "    print('TRAIN: EPOCH %04d/%04d | LOSS: %.4f |  ACC %.4f' %\n",
    "          (epoch, args.num_epoch, np.mean(train_loss), np.mean(acc_arr)))\n",
    "    writer.add_scalar('Training loss', np.mean(train_loss), epoch)\n",
    "    writer.add_scalar('Training accuracy', np.mean(acc_arr), epoch)\n",
    "\n",
    "    history['training_loss'].append(np.mean(train_loss))\n",
    "    history['training_acc'].append(np.mean(acc_arr))\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    global best_loss, state\n",
    "    net.eval()\n",
    "    test_loss = []\n",
    "    acc_arr = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(val_loader):\n",
    "            inputs = inputs.view([batch_size, -1, input_dim]).to(device)\n",
    "            targets = targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            pred = fn_pred(outputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            acc = fn_acc(pred, targets)\n",
    "\n",
    "            test_loss += [loss.item()]\n",
    "            acc_arr += [acc.item()]\n",
    "\n",
    "        print('TEST:  LOSS: %.4f |  ACC %.4f' %\n",
    "                  (np.mean(test_loss),  np.mean(acc_arr)))\n",
    "\n",
    "    if np.mean(test_loss) < best_loss:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': np.mean(test_loss),\n",
    "            'epoch': epoch,\n",
    "            'optim': optimizer.state_dict()\n",
    "        }\n",
    "        best_loss = np.mean(test_loss)\n",
    "\n",
    "    writer.add_scalar('Test loss', np.mean(test_loss), epoch)\n",
    "    writer.add_scalar('Test accuracy', np.mean(acc_arr), epoch)\n",
    "\n",
    "    history['test_loss'].append(np.mean(test_loss))\n",
    "    history['test_acc'].append(np.mean(acc_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "043e0728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\S1026623\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:528: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 300, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0001/0200 | BATCH 0000/0001 | LOSS: 1.9663 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0001/0200 | LOSS: 0.2346 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.6492 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 2\n",
      "TRAIN: EPOCH 0002/0200 | BATCH 0000/0001 | LOSS: 4.7251 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0002/0200 | LOSS: 0.6169 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.2385 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      "TRAIN: EPOCH 0003/0200 | BATCH 0000/0001 | LOSS: 5.5789 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0003/0200 | LOSS: 0.8846 |  ACC 0.0000\n",
      "TEST:  LOSS: 17.7282 |  ACC 0.0000\n",
      "\n",
      "Epoch: 4\n",
      "TRAIN: EPOCH 0004/0200 | BATCH 0000/0001 | LOSS: 2.2458 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0004/0200 | LOSS: 0.5378 |  ACC 0.0000\n",
      "TEST:  LOSS: 17.3423 |  ACC 0.0000\n",
      "\n",
      "Epoch: 5\n",
      "TRAIN: EPOCH 0005/0200 | BATCH 0000/0001 | LOSS: 2.3870 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0005/0200 | LOSS: 0.5319 |  ACC 0.0000\n",
      "TEST:  LOSS: 17.0233 |  ACC 0.0000\n",
      "\n",
      "Epoch: 6\n",
      "TRAIN: EPOCH 0006/0200 | BATCH 0000/0001 | LOSS: 2.5071 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0006/0200 | LOSS: 0.4141 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.8986 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 7\n",
      "TRAIN: EPOCH 0007/0200 | BATCH 0000/0001 | LOSS: 3.3857 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0007/0200 | LOSS: 0.3896 |  ACC 0.0000\n",
      "TEST:  LOSS: 5.3985 |  ACC 0.0000\n",
      "Saving..\n",
      "\n",
      "Epoch: 8\n",
      "TRAIN: EPOCH 0008/0200 | BATCH 0000/0001 | LOSS: 4.1248 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0008/0200 | LOSS: 0.5351 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.0329 |  ACC 0.0000\n",
      "\n",
      "Epoch: 9\n",
      "TRAIN: EPOCH 0009/0200 | BATCH 0000/0001 | LOSS: 4.9650 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0009/0200 | LOSS: 0.7626 |  ACC 0.0000\n",
      "TEST:  LOSS: 16.8864 |  ACC 0.0000\n",
      "\n",
      "Epoch: 10\n",
      "TRAIN: EPOCH 0010/0200 | BATCH 0000/0001 | LOSS: 2.7050 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0010/0200 | LOSS: 0.5562 |  ACC 0.0000\n",
      "TEST:  LOSS: 15.8639 |  ACC 0.0000\n",
      "\n",
      "Epoch: 11\n",
      "TRAIN: EPOCH 0011/0200 | BATCH 0000/0001 | LOSS: 2.6032 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0011/0200 | LOSS: 0.4286 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.2324 |  ACC 0.0000\n",
      "\n",
      "Epoch: 12\n",
      "TRAIN: EPOCH 0012/0200 | BATCH 0000/0001 | LOSS: 4.0766 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0012/0200 | LOSS: 0.4387 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.5322 |  ACC 0.0000\n",
      "\n",
      "Epoch: 13\n",
      "TRAIN: EPOCH 0013/0200 | BATCH 0000/0001 | LOSS: 2.0651 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0013/0200 | LOSS: 0.3325 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.4123 |  ACC 0.0000\n",
      "\n",
      "Epoch: 14\n",
      "TRAIN: EPOCH 0014/0200 | BATCH 0000/0001 | LOSS: 2.2597 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0014/0200 | LOSS: 0.3428 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.8758 |  ACC 0.0000\n",
      "\n",
      "Epoch: 15\n",
      "TRAIN: EPOCH 0015/0200 | BATCH 0000/0001 | LOSS: 1.8087 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0015/0200 | LOSS: 0.3544 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.8952 |  ACC 0.0000\n",
      "\n",
      "Epoch: 16\n",
      "TRAIN: EPOCH 0016/0200 | BATCH 0000/0001 | LOSS: 1.5382 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0016/0200 | LOSS: 0.3372 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.9185 |  ACC 0.0000\n",
      "\n",
      "Epoch: 17\n",
      "TRAIN: EPOCH 0017/0200 | BATCH 0000/0001 | LOSS: 1.6143 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0017/0200 | LOSS: 0.2730 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.2684 |  ACC 0.0000\n",
      "\n",
      "Epoch: 18\n",
      "TRAIN: EPOCH 0018/0200 | BATCH 0000/0001 | LOSS: 1.3780 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0018/0200 | LOSS: 0.2549 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.2797 |  ACC 0.0000\n",
      "\n",
      "Epoch: 19\n",
      "TRAIN: EPOCH 0019/0200 | BATCH 0000/0001 | LOSS: 1.3401 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0019/0200 | LOSS: 0.2939 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.3235 |  ACC 0.0000\n",
      "\n",
      "Epoch: 20\n",
      "TRAIN: EPOCH 0020/0200 | BATCH 0000/0001 | LOSS: 1.2416 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0020/0200 | LOSS: 0.2828 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.7181 |  ACC 0.0000\n",
      "\n",
      "Epoch: 21\n",
      "TRAIN: EPOCH 0021/0200 | BATCH 0000/0001 | LOSS: 1.5310 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0021/0200 | LOSS: 0.3171 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.9766 |  ACC 0.0000\n",
      "\n",
      "Epoch: 22\n",
      "TRAIN: EPOCH 0022/0200 | BATCH 0000/0001 | LOSS: 1.3092 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0022/0200 | LOSS: 0.2544 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.4659 |  ACC 0.0000\n",
      "\n",
      "Epoch: 23\n",
      "TRAIN: EPOCH 0023/0200 | BATCH 0000/0001 | LOSS: 1.2873 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0023/0200 | LOSS: 0.2563 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.5593 |  ACC 0.0000\n",
      "\n",
      "Epoch: 24\n",
      "TRAIN: EPOCH 0024/0200 | BATCH 0000/0001 | LOSS: 1.2115 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0024/0200 | LOSS: 0.2556 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.5319 |  ACC 0.0000\n",
      "\n",
      "Epoch: 25\n",
      "TRAIN: EPOCH 0025/0200 | BATCH 0000/0001 | LOSS: 1.4711 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0025/0200 | LOSS: 0.2547 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.5093 |  ACC 0.0000\n",
      "\n",
      "Epoch: 26\n",
      "TRAIN: EPOCH 0026/0200 | BATCH 0000/0001 | LOSS: 1.1924 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0026/0200 | LOSS: 0.2388 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.0785 |  ACC 0.0000\n",
      "\n",
      "Epoch: 27\n",
      "TRAIN: EPOCH 0027/0200 | BATCH 0000/0001 | LOSS: 1.2366 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0027/0200 | LOSS: 0.2632 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.6038 |  ACC 0.0000\n",
      "\n",
      "Epoch: 28\n",
      "TRAIN: EPOCH 0028/0200 | BATCH 0000/0001 | LOSS: 1.0986 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0028/0200 | LOSS: 0.2291 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.3195 |  ACC 0.0000\n",
      "\n",
      "Epoch: 29\n",
      "TRAIN: EPOCH 0029/0200 | BATCH 0000/0001 | LOSS: 1.0498 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0029/0200 | LOSS: 0.2401 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.4946 |  ACC 0.0000\n",
      "\n",
      "Epoch: 30\n",
      "TRAIN: EPOCH 0030/0200 | BATCH 0000/0001 | LOSS: 1.0865 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0030/0200 | LOSS: 0.2216 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.2472 |  ACC 0.0000\n",
      "\n",
      "Epoch: 31\n",
      "TRAIN: EPOCH 0031/0200 | BATCH 0000/0001 | LOSS: 1.0586 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0031/0200 | LOSS: 0.2294 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.2894 |  ACC 0.0000\n",
      "\n",
      "Epoch: 32\n",
      "TRAIN: EPOCH 0032/0200 | BATCH 0000/0001 | LOSS: 1.2423 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0032/0200 | LOSS: 0.2468 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.5681 |  ACC 0.0000\n",
      "\n",
      "Epoch: 33\n",
      "TRAIN: EPOCH 0033/0200 | BATCH 0000/0001 | LOSS: 0.9562 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0033/0200 | LOSS: 0.2042 |  ACC 0.0000\n",
      "TEST:  LOSS: 13.3153 |  ACC 0.0000\n",
      "\n",
      "Epoch: 34\n",
      "TRAIN: EPOCH 0034/0200 | BATCH 0000/0001 | LOSS: 1.3429 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0034/0200 | LOSS: 0.1815 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.4211 |  ACC 0.0000\n",
      "\n",
      "Epoch: 35\n",
      "TRAIN: EPOCH 0035/0200 | BATCH 0000/0001 | LOSS: 1.6127 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0035/0200 | LOSS: 0.2084 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.9324 |  ACC 0.0000\n",
      "\n",
      "Epoch: 36\n",
      "TRAIN: EPOCH 0036/0200 | BATCH 0000/0001 | LOSS: 0.3891 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0036/0200 | LOSS: 0.1464 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.7494 |  ACC 0.0000\n",
      "\n",
      "Epoch: 37\n",
      "TRAIN: EPOCH 0037/0200 | BATCH 0000/0001 | LOSS: 0.6590 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0037/0200 | LOSS: 0.1405 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.6271 |  ACC 0.0000\n",
      "\n",
      "Epoch: 38\n",
      "TRAIN: EPOCH 0038/0200 | BATCH 0000/0001 | LOSS: 0.1488 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0038/0200 | LOSS: 0.1304 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.2973 |  ACC 0.0000\n",
      "\n",
      "Epoch: 39\n",
      "TRAIN: EPOCH 0039/0200 | BATCH 0000/0001 | LOSS: 0.6463 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0039/0200 | LOSS: 0.1199 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.5869 |  ACC 0.0000\n",
      "\n",
      "Epoch: 40\n",
      "TRAIN: EPOCH 0040/0200 | BATCH 0000/0001 | LOSS: 0.3727 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0040/0200 | LOSS: 0.1429 |  ACC 0.0000\n",
      "TEST:  LOSS: 12.1676 |  ACC 0.0000\n",
      "\n",
      "Epoch: 41\n",
      "TRAIN: EPOCH 0041/0200 | BATCH 0000/0001 | LOSS: 0.2529 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0041/0200 | LOSS: 0.1164 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.9522 |  ACC 0.0000\n",
      "\n",
      "Epoch: 42\n",
      "TRAIN: EPOCH 0042/0200 | BATCH 0000/0001 | LOSS: 0.5763 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0042/0200 | LOSS: 0.1445 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.6132 |  ACC 0.0000\n",
      "\n",
      "Epoch: 43\n",
      "TRAIN: EPOCH 0043/0200 | BATCH 0000/0001 | LOSS: 0.4206 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0043/0200 | LOSS: 0.1431 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.0997 |  ACC 0.0000\n",
      "\n",
      "Epoch: 44\n",
      "TRAIN: EPOCH 0044/0200 | BATCH 0000/0001 | LOSS: 0.1639 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0044/0200 | LOSS: 0.1240 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.2777 |  ACC 0.0000\n",
      "\n",
      "Epoch: 45\n",
      "TRAIN: EPOCH 0045/0200 | BATCH 0000/0001 | LOSS: 0.9161 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0045/0200 | LOSS: 0.1313 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.5423 |  ACC 0.0000\n",
      "\n",
      "Epoch: 46\n",
      "TRAIN: EPOCH 0046/0200 | BATCH 0000/0001 | LOSS: 0.3767 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0046/0200 | LOSS: 0.0880 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.3227 |  ACC 0.0000\n",
      "\n",
      "Epoch: 47\n",
      "TRAIN: EPOCH 0047/0200 | BATCH 0000/0001 | LOSS: 0.1935 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0047/0200 | LOSS: 0.0811 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.2045 |  ACC 0.0000\n",
      "\n",
      "Epoch: 48\n",
      "TRAIN: EPOCH 0048/0200 | BATCH 0000/0001 | LOSS: 0.1288 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0048/0200 | LOSS: 0.0953 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.0570 |  ACC 0.0000\n",
      "\n",
      "Epoch: 49\n",
      "TRAIN: EPOCH 0049/0200 | BATCH 0000/0001 | LOSS: 0.0562 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0049/0200 | LOSS: 0.1071 |  ACC 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST:  LOSS: 11.5925 |  ACC 0.0000\n",
      "\n",
      "Epoch: 50\n",
      "TRAIN: EPOCH 0050/0200 | BATCH 0000/0001 | LOSS: 0.1959 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0050/0200 | LOSS: 0.0903 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.6513 |  ACC 0.0000\n",
      "\n",
      "Epoch: 51\n",
      "TRAIN: EPOCH 0051/0200 | BATCH 0000/0001 | LOSS: 0.0781 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0051/0200 | LOSS: 0.0626 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.6724 |  ACC 0.0000\n",
      "\n",
      "Epoch: 52\n",
      "TRAIN: EPOCH 0052/0200 | BATCH 0000/0001 | LOSS: 0.2824 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0052/0200 | LOSS: 0.0786 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.4654 |  ACC 0.0000\n",
      "\n",
      "Epoch: 53\n",
      "TRAIN: EPOCH 0053/0200 | BATCH 0000/0001 | LOSS: 0.0915 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0053/0200 | LOSS: 0.0755 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.9280 |  ACC 0.0000\n",
      "\n",
      "Epoch: 54\n",
      "TRAIN: EPOCH 0054/0200 | BATCH 0000/0001 | LOSS: 0.3135 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0054/0200 | LOSS: 0.0732 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.8505 |  ACC 0.0000\n",
      "\n",
      "Epoch: 55\n",
      "TRAIN: EPOCH 0055/0200 | BATCH 0000/0001 | LOSS: 0.0875 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0055/0200 | LOSS: 0.0980 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.3587 |  ACC 0.0000\n",
      "\n",
      "Epoch: 56\n",
      "TRAIN: EPOCH 0056/0200 | BATCH 0000/0001 | LOSS: 0.1561 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0056/0200 | LOSS: 0.0604 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.1323 |  ACC 0.0000\n",
      "\n",
      "Epoch: 57\n",
      "TRAIN: EPOCH 0057/0200 | BATCH 0000/0001 | LOSS: 0.0548 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0057/0200 | LOSS: 0.0636 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.8856 |  ACC 0.0000\n",
      "\n",
      "Epoch: 58\n",
      "TRAIN: EPOCH 0058/0200 | BATCH 0000/0001 | LOSS: 0.0629 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0058/0200 | LOSS: 0.0959 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.7954 |  ACC 0.0000\n",
      "\n",
      "Epoch: 59\n",
      "TRAIN: EPOCH 0059/0200 | BATCH 0000/0001 | LOSS: 0.1232 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0059/0200 | LOSS: 0.0563 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.1926 |  ACC 0.0000\n",
      "\n",
      "Epoch: 60\n",
      "TRAIN: EPOCH 0060/0200 | BATCH 0000/0001 | LOSS: 0.0613 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0060/0200 | LOSS: 0.0607 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.5386 |  ACC 0.0000\n",
      "\n",
      "Epoch: 61\n",
      "TRAIN: EPOCH 0061/0200 | BATCH 0000/0001 | LOSS: 0.0809 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0061/0200 | LOSS: 0.0468 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.2511 |  ACC 0.0000\n",
      "\n",
      "Epoch: 62\n",
      "TRAIN: EPOCH 0062/0200 | BATCH 0000/0001 | LOSS: 0.0553 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0062/0200 | LOSS: 0.0358 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.3124 |  ACC 0.0000\n",
      "\n",
      "Epoch: 63\n",
      "TRAIN: EPOCH 0063/0200 | BATCH 0000/0001 | LOSS: 0.0689 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0063/0200 | LOSS: 0.0488 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.2845 |  ACC 0.0000\n",
      "\n",
      "Epoch: 64\n",
      "TRAIN: EPOCH 0064/0200 | BATCH 0000/0001 | LOSS: 0.0550 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0064/0200 | LOSS: 0.1006 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.5354 |  ACC 0.0000\n",
      "\n",
      "Epoch: 65\n",
      "TRAIN: EPOCH 0065/0200 | BATCH 0000/0001 | LOSS: 0.0625 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0065/0200 | LOSS: 0.0989 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.8103 |  ACC 0.0000\n",
      "\n",
      "Epoch: 66\n",
      "TRAIN: EPOCH 0066/0200 | BATCH 0000/0001 | LOSS: 0.0612 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0066/0200 | LOSS: 0.0767 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.0507 |  ACC 0.0000\n",
      "\n",
      "Epoch: 67\n",
      "TRAIN: EPOCH 0067/0200 | BATCH 0000/0001 | LOSS: 0.0566 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0067/0200 | LOSS: 0.1002 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.6375 |  ACC 0.0000\n",
      "\n",
      "Epoch: 68\n",
      "TRAIN: EPOCH 0068/0200 | BATCH 0000/0001 | LOSS: 0.1351 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0068/0200 | LOSS: 0.0650 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.7351 |  ACC 0.0000\n",
      "\n",
      "Epoch: 69\n",
      "TRAIN: EPOCH 0069/0200 | BATCH 0000/0001 | LOSS: 0.0711 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0069/0200 | LOSS: 0.0455 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.7190 |  ACC 0.0000\n",
      "\n",
      "Epoch: 70\n",
      "TRAIN: EPOCH 0070/0200 | BATCH 0000/0001 | LOSS: 0.1283 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0070/0200 | LOSS: 0.1478 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.1045 |  ACC 0.0000\n",
      "\n",
      "Epoch: 71\n",
      "TRAIN: EPOCH 0071/0200 | BATCH 0000/0001 | LOSS: 0.0615 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0071/0200 | LOSS: 0.0850 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.0046 |  ACC 0.0000\n",
      "\n",
      "Epoch: 72\n",
      "TRAIN: EPOCH 0072/0200 | BATCH 0000/0001 | LOSS: 0.0793 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0072/0200 | LOSS: 0.1250 |  ACC 0.0000\n",
      "TEST:  LOSS: 10.6807 |  ACC 0.0000\n",
      "\n",
      "Epoch: 73\n",
      "TRAIN: EPOCH 0073/0200 | BATCH 0000/0001 | LOSS: 0.0554 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0073/0200 | LOSS: 0.0711 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.7207 |  ACC 0.0000\n",
      "\n",
      "Epoch: 74\n",
      "TRAIN: EPOCH 0074/0200 | BATCH 0000/0001 | LOSS: 0.2101 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0074/0200 | LOSS: 0.0953 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.9847 |  ACC 0.0000\n",
      "\n",
      "Epoch: 75\n",
      "TRAIN: EPOCH 0075/0200 | BATCH 0000/0001 | LOSS: 0.1138 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0075/0200 | LOSS: 0.0952 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.2236 |  ACC 0.0000\n",
      "\n",
      "Epoch: 76\n",
      "TRAIN: EPOCH 0076/0200 | BATCH 0000/0001 | LOSS: 0.2037 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0076/0200 | LOSS: 0.0712 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.9970 |  ACC 0.0000\n",
      "\n",
      "Epoch: 77\n",
      "TRAIN: EPOCH 0077/0200 | BATCH 0000/0001 | LOSS: 0.0619 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0077/0200 | LOSS: 0.0528 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.8855 |  ACC 0.0000\n",
      "\n",
      "Epoch: 78\n",
      "TRAIN: EPOCH 0078/0200 | BATCH 0000/0001 | LOSS: 0.1003 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0078/0200 | LOSS: 0.0429 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.4669 |  ACC 0.0000\n",
      "\n",
      "Epoch: 79\n",
      "TRAIN: EPOCH 0079/0200 | BATCH 0000/0001 | LOSS: 0.0545 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0079/0200 | LOSS: 0.0506 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.0399 |  ACC 0.0000\n",
      "\n",
      "Epoch: 80\n",
      "TRAIN: EPOCH 0080/0200 | BATCH 0000/0001 | LOSS: 0.0700 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0080/0200 | LOSS: 0.1452 |  ACC 0.0000\n",
      "TEST:  LOSS: 11.0327 |  ACC 0.0000\n",
      "\n",
      "Epoch: 81\n",
      "TRAIN: EPOCH 0081/0200 | BATCH 0000/0001 | LOSS: 0.0547 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0081/0200 | LOSS: 0.0942 |  ACC 0.0000\n",
      "TEST:  LOSS: 9.0176 |  ACC 0.0000\n",
      "\n",
      "Epoch: 82\n",
      "TRAIN: EPOCH 0082/0200 | BATCH 0000/0001 | LOSS: 0.0803 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0082/0200 | LOSS: 0.0737 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.9004 |  ACC 0.0000\n",
      "\n",
      "Epoch: 83\n",
      "TRAIN: EPOCH 0083/0200 | BATCH 0000/0001 | LOSS: 0.0545 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0083/0200 | LOSS: 0.0535 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.4401 |  ACC 0.0000\n",
      "\n",
      "Epoch: 84\n",
      "TRAIN: EPOCH 0084/0200 | BATCH 0000/0001 | LOSS: 0.0685 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0084/0200 | LOSS: 0.0521 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.3814 |  ACC 0.0000\n",
      "\n",
      "Epoch: 85\n",
      "TRAIN: EPOCH 0085/0200 | BATCH 0000/0001 | LOSS: 0.0567 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0085/0200 | LOSS: 0.0632 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.9582 |  ACC 0.0000\n",
      "\n",
      "Epoch: 86\n",
      "TRAIN: EPOCH 0086/0200 | BATCH 0000/0001 | LOSS: 0.0735 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0086/0200 | LOSS: 0.0485 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.4579 |  ACC 0.0000\n",
      "\n",
      "Epoch: 87\n",
      "TRAIN: EPOCH 0087/0200 | BATCH 0000/0001 | LOSS: 0.0830 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0087/0200 | LOSS: 0.0657 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.7024 |  ACC 0.0000\n",
      "\n",
      "Epoch: 88\n",
      "TRAIN: EPOCH 0088/0200 | BATCH 0000/0001 | LOSS: 0.0710 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0088/0200 | LOSS: 0.0603 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.3686 |  ACC 0.0000\n",
      "\n",
      "Epoch: 89\n",
      "TRAIN: EPOCH 0089/0200 | BATCH 0000/0001 | LOSS: 0.0561 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0089/0200 | LOSS: 0.0657 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.2017 |  ACC 0.0000\n",
      "\n",
      "Epoch: 90\n",
      "TRAIN: EPOCH 0090/0200 | BATCH 0000/0001 | LOSS: 0.1461 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0090/0200 | LOSS: 0.0555 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.9915 |  ACC 0.0000\n",
      "\n",
      "Epoch: 91\n",
      "TRAIN: EPOCH 0091/0200 | BATCH 0000/0001 | LOSS: 0.0651 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0091/0200 | LOSS: 0.0650 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.5505 |  ACC 0.0000\n",
      "\n",
      "Epoch: 92\n",
      "TRAIN: EPOCH 0092/0200 | BATCH 0000/0001 | LOSS: 0.0938 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0092/0200 | LOSS: 0.0642 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.4180 |  ACC 0.0000\n",
      "\n",
      "Epoch: 93\n",
      "TRAIN: EPOCH 0093/0200 | BATCH 0000/0001 | LOSS: 0.0602 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0093/0200 | LOSS: 0.0512 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.0774 |  ACC 0.0000\n",
      "\n",
      "Epoch: 94\n",
      "TRAIN: EPOCH 0094/0200 | BATCH 0000/0001 | LOSS: 0.0584 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0094/0200 | LOSS: 0.0580 |  ACC 0.0000\n",
      "TEST:  LOSS: 8.0819 |  ACC 0.0000\n",
      "\n",
      "Epoch: 95\n",
      "TRAIN: EPOCH 0095/0200 | BATCH 0000/0001 | LOSS: 0.0699 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0095/0200 | LOSS: 0.0482 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.7249 |  ACC 0.0000\n",
      "\n",
      "Epoch: 96\n",
      "TRAIN: EPOCH 0096/0200 | BATCH 0000/0001 | LOSS: 0.0544 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0096/0200 | LOSS: 0.0385 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.7370 |  ACC 0.0000\n",
      "\n",
      "Epoch: 97\n",
      "TRAIN: EPOCH 0097/0200 | BATCH 0000/0001 | LOSS: 0.7437 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0097/0200 | LOSS: 0.0657 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.5420 |  ACC 0.0000\n",
      "\n",
      "Epoch: 98\n",
      "TRAIN: EPOCH 0098/0200 | BATCH 0000/0001 | LOSS: 0.4810 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0098/0200 | LOSS: 0.0525 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3617 |  ACC 0.0000\n",
      "\n",
      "Epoch: 99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0099/0200 | BATCH 0000/0001 | LOSS: 0.0592 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0099/0200 | LOSS: 0.0394 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3837 |  ACC 0.0000\n",
      "\n",
      "Epoch: 100\n",
      "TRAIN: EPOCH 0100/0200 | BATCH 0000/0001 | LOSS: 0.3126 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0100/0200 | LOSS: 0.0433 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2611 |  ACC 0.0000\n",
      "\n",
      "Epoch: 101\n",
      "TRAIN: EPOCH 0101/0200 | BATCH 0000/0001 | LOSS: 0.0567 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0101/0200 | LOSS: 0.0324 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1962 |  ACC 0.0000\n",
      "\n",
      "Epoch: 102\n",
      "TRAIN: EPOCH 0102/0200 | BATCH 0000/0001 | LOSS: 0.0897 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0102/0200 | LOSS: 0.0322 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1807 |  ACC 0.0000\n",
      "\n",
      "Epoch: 103\n",
      "TRAIN: EPOCH 0103/0200 | BATCH 0000/0001 | LOSS: 0.0593 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0103/0200 | LOSS: 0.0306 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1328 |  ACC 0.0000\n",
      "\n",
      "Epoch: 104\n",
      "TRAIN: EPOCH 0104/0200 | BATCH 0000/0001 | LOSS: 0.0714 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0104/0200 | LOSS: 0.0304 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1088 |  ACC 0.0000\n",
      "\n",
      "Epoch: 105\n",
      "TRAIN: EPOCH 0105/0200 | BATCH 0000/0001 | LOSS: 0.0563 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0105/0200 | LOSS: 0.0290 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0957 |  ACC 0.0000\n",
      "\n",
      "Epoch: 106\n",
      "TRAIN: EPOCH 0106/0200 | BATCH 0000/0001 | LOSS: 0.2955 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0106/0200 | LOSS: 0.0402 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0782 |  ACC 0.0000\n",
      "\n",
      "Epoch: 107\n",
      "TRAIN: EPOCH 0107/0200 | BATCH 0000/0001 | LOSS: 0.0736 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0107/0200 | LOSS: 0.0339 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0766 |  ACC 0.0000\n",
      "\n",
      "Epoch: 108\n",
      "TRAIN: EPOCH 0108/0200 | BATCH 0000/0001 | LOSS: 0.1965 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0108/0200 | LOSS: 0.0352 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0772 |  ACC 0.0000\n",
      "\n",
      "Epoch: 109\n",
      "TRAIN: EPOCH 0109/0200 | BATCH 0000/0001 | LOSS: 0.0614 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0109/0200 | LOSS: 0.0307 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0729 |  ACC 0.0000\n",
      "\n",
      "Epoch: 110\n",
      "TRAIN: EPOCH 0110/0200 | BATCH 0000/0001 | LOSS: 0.1125 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0110/0200 | LOSS: 0.0326 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0455 |  ACC 0.0000\n",
      "\n",
      "Epoch: 111\n",
      "TRAIN: EPOCH 0111/0200 | BATCH 0000/0001 | LOSS: 0.0558 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0111/0200 | LOSS: 0.0282 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0993 |  ACC 0.0000\n",
      "\n",
      "Epoch: 112\n",
      "TRAIN: EPOCH 0112/0200 | BATCH 0000/0001 | LOSS: 0.0652 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0112/0200 | LOSS: 0.0287 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0188 |  ACC 0.0000\n",
      "\n",
      "Epoch: 113\n",
      "TRAIN: EPOCH 0113/0200 | BATCH 0000/0001 | LOSS: 0.0558 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0113/0200 | LOSS: 0.0271 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1080 |  ACC 0.0000\n",
      "\n",
      "Epoch: 114\n",
      "TRAIN: EPOCH 0114/0200 | BATCH 0000/0001 | LOSS: 0.0616 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0114/0200 | LOSS: 0.0280 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0238 |  ACC 0.0000\n",
      "\n",
      "Epoch: 115\n",
      "TRAIN: EPOCH 0115/0200 | BATCH 0000/0001 | LOSS: 0.0561 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0115/0200 | LOSS: 0.0268 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1131 |  ACC 0.0000\n",
      "\n",
      "Epoch: 116\n",
      "TRAIN: EPOCH 0116/0200 | BATCH 0000/0001 | LOSS: 0.0542 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0116/0200 | LOSS: 0.0270 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0251 |  ACC 0.0000\n",
      "\n",
      "Epoch: 117\n",
      "TRAIN: EPOCH 0117/0200 | BATCH 0000/0001 | LOSS: 0.0544 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0117/0200 | LOSS: 0.0263 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1150 |  ACC 0.0000\n",
      "\n",
      "Epoch: 118\n",
      "TRAIN: EPOCH 0118/0200 | BATCH 0000/0001 | LOSS: 0.0554 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0118/0200 | LOSS: 0.0265 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0328 |  ACC 0.0000\n",
      "\n",
      "Epoch: 119\n",
      "TRAIN: EPOCH 0119/0200 | BATCH 0000/0001 | LOSS: 0.0553 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0119/0200 | LOSS: 0.0273 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0580 |  ACC 0.0000\n",
      "\n",
      "Epoch: 120\n",
      "TRAIN: EPOCH 0120/0200 | BATCH 0000/0001 | LOSS: 0.0563 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0120/0200 | LOSS: 0.0254 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0761 |  ACC 0.0000\n",
      "\n",
      "Epoch: 121\n",
      "TRAIN: EPOCH 0121/0200 | BATCH 0000/0001 | LOSS: 0.0582 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0121/0200 | LOSS: 0.0259 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0739 |  ACC 0.0000\n",
      "\n",
      "Epoch: 122\n",
      "TRAIN: EPOCH 0122/0200 | BATCH 0000/0001 | LOSS: 0.0558 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0122/0200 | LOSS: 0.0253 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1056 |  ACC 0.0000\n",
      "\n",
      "Epoch: 123\n",
      "TRAIN: EPOCH 0123/0200 | BATCH 0000/0001 | LOSS: 0.0567 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0123/0200 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0897 |  ACC 0.0000\n",
      "\n",
      "Epoch: 124\n",
      "TRAIN: EPOCH 0124/0200 | BATCH 0000/0001 | LOSS: 0.0553 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0124/0200 | LOSS: 0.0276 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0904 |  ACC 0.0000\n",
      "\n",
      "Epoch: 125\n",
      "TRAIN: EPOCH 0125/0200 | BATCH 0000/0001 | LOSS: 0.0540 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0125/0200 | LOSS: 0.0285 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.8841 |  ACC 0.0000\n",
      "\n",
      "Epoch: 126\n",
      "TRAIN: EPOCH 0126/0200 | BATCH 0000/0001 | LOSS: 0.0749 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0126/0200 | LOSS: 0.0301 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3237 |  ACC 0.0000\n",
      "\n",
      "Epoch: 127\n",
      "TRAIN: EPOCH 0127/0200 | BATCH 0000/0001 | LOSS: 0.1109 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0127/0200 | LOSS: 0.0298 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2218 |  ACC 0.0000\n",
      "\n",
      "Epoch: 128\n",
      "TRAIN: EPOCH 0128/0200 | BATCH 0000/0001 | LOSS: 0.1962 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0128/0200 | LOSS: 0.0330 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2032 |  ACC 0.0000\n",
      "\n",
      "Epoch: 129\n",
      "TRAIN: EPOCH 0129/0200 | BATCH 0000/0001 | LOSS: 0.2263 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0129/0200 | LOSS: 0.0332 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2439 |  ACC 0.0000\n",
      "\n",
      "Epoch: 130\n",
      "TRAIN: EPOCH 0130/0200 | BATCH 0000/0001 | LOSS: 0.2165 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0130/0200 | LOSS: 0.0416 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0505 |  ACC 0.0000\n",
      "\n",
      "Epoch: 131\n",
      "TRAIN: EPOCH 0131/0200 | BATCH 0000/0001 | LOSS: 0.0888 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0131/0200 | LOSS: 0.0320 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0152 |  ACC 0.0000\n",
      "\n",
      "Epoch: 132\n",
      "TRAIN: EPOCH 0132/0200 | BATCH 0000/0001 | LOSS: 0.0856 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0132/0200 | LOSS: 0.0283 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1547 |  ACC 0.0000\n",
      "\n",
      "Epoch: 133\n",
      "TRAIN: EPOCH 0133/0200 | BATCH 0000/0001 | LOSS: 0.0707 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0133/0200 | LOSS: 0.0263 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0833 |  ACC 0.0000\n",
      "\n",
      "Epoch: 134\n",
      "TRAIN: EPOCH 0134/0200 | BATCH 0000/0001 | LOSS: 0.0654 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0134/0200 | LOSS: 0.0271 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0310 |  ACC 0.0000\n",
      "\n",
      "Epoch: 135\n",
      "TRAIN: EPOCH 0135/0200 | BATCH 0000/0001 | LOSS: 0.0564 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0135/0200 | LOSS: 0.0253 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0865 |  ACC 0.0000\n",
      "\n",
      "Epoch: 136\n",
      "TRAIN: EPOCH 0136/0200 | BATCH 0000/0001 | LOSS: 0.0554 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0136/0200 | LOSS: 0.0260 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1352 |  ACC 0.0000\n",
      "\n",
      "Epoch: 137\n",
      "TRAIN: EPOCH 0137/0200 | BATCH 0000/0001 | LOSS: 0.0543 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0137/0200 | LOSS: 0.0288 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.9905 |  ACC 0.0000\n",
      "\n",
      "Epoch: 138\n",
      "TRAIN: EPOCH 0138/0200 | BATCH 0000/0001 | LOSS: 0.0540 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0138/0200 | LOSS: 0.0281 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.9771 |  ACC 0.0000\n",
      "\n",
      "Epoch: 139\n",
      "TRAIN: EPOCH 0139/0200 | BATCH 0000/0001 | LOSS: 0.0564 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0139/0200 | LOSS: 0.0273 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0626 |  ACC 0.0000\n",
      "\n",
      "Epoch: 140\n",
      "TRAIN: EPOCH 0140/0200 | BATCH 0000/0001 | LOSS: 0.0619 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0140/0200 | LOSS: 0.0280 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1830 |  ACC 0.0000\n",
      "\n",
      "Epoch: 141\n",
      "TRAIN: EPOCH 0141/0200 | BATCH 0000/0001 | LOSS: 0.0620 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0141/0200 | LOSS: 0.0250 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0385 |  ACC 0.0000\n",
      "\n",
      "Epoch: 142\n",
      "TRAIN: EPOCH 0142/0200 | BATCH 0000/0001 | LOSS: 0.0737 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0142/0200 | LOSS: 0.0263 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0032 |  ACC 0.0000\n",
      "\n",
      "Epoch: 143\n",
      "TRAIN: EPOCH 0143/0200 | BATCH 0000/0001 | LOSS: 0.0763 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0143/0200 | LOSS: 0.0260 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0851 |  ACC 0.0000\n",
      "\n",
      "Epoch: 144\n",
      "TRAIN: EPOCH 0144/0200 | BATCH 0000/0001 | LOSS: 0.0845 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0144/0200 | LOSS: 0.0324 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2439 |  ACC 0.0000\n",
      "\n",
      "Epoch: 145\n",
      "TRAIN: EPOCH 0145/0200 | BATCH 0000/0001 | LOSS: 0.0600 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0145/0200 | LOSS: 0.0314 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0048 |  ACC 0.0000\n",
      "\n",
      "Epoch: 146\n",
      "TRAIN: EPOCH 0146/0200 | BATCH 0000/0001 | LOSS: 0.0667 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0146/0200 | LOSS: 0.0317 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.9774 |  ACC 0.0000\n",
      "\n",
      "Epoch: 147\n",
      "TRAIN: EPOCH 0147/0200 | BATCH 0000/0001 | LOSS: 0.0852 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0147/0200 | LOSS: 0.0308 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.9756 |  ACC 0.0000\n",
      "\n",
      "Epoch: 148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0148/0200 | BATCH 0000/0001 | LOSS: 0.2131 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0148/0200 | LOSS: 0.0370 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0559 |  ACC 0.0000\n",
      "\n",
      "Epoch: 149\n",
      "TRAIN: EPOCH 0149/0200 | BATCH 0000/0001 | LOSS: 0.1253 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0149/0200 | LOSS: 0.0301 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3012 |  ACC 0.0000\n",
      "\n",
      "Epoch: 150\n",
      "TRAIN: EPOCH 0150/0200 | BATCH 0000/0001 | LOSS: 0.1714 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0150/0200 | LOSS: 0.0361 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3905 |  ACC 0.0000\n",
      "\n",
      "Epoch: 151\n",
      "TRAIN: EPOCH 0151/0200 | BATCH 0000/0001 | LOSS: 0.0873 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0151/0200 | LOSS: 0.0292 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2459 |  ACC 0.0000\n",
      "\n",
      "Epoch: 152\n",
      "TRAIN: EPOCH 0152/0200 | BATCH 0000/0001 | LOSS: 0.0840 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0152/0200 | LOSS: 0.0272 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3109 |  ACC 0.0000\n",
      "\n",
      "Epoch: 153\n",
      "TRAIN: EPOCH 0153/0200 | BATCH 0000/0001 | LOSS: 0.0785 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0153/0200 | LOSS: 0.0303 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3155 |  ACC 0.0000\n",
      "\n",
      "Epoch: 154\n",
      "TRAIN: EPOCH 0154/0200 | BATCH 0000/0001 | LOSS: 0.0675 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0154/0200 | LOSS: 0.0292 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0066 |  ACC 0.0000\n",
      "\n",
      "Epoch: 155\n",
      "TRAIN: EPOCH 0155/0200 | BATCH 0000/0001 | LOSS: 0.0629 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0155/0200 | LOSS: 0.0257 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1357 |  ACC 0.0000\n",
      "\n",
      "Epoch: 156\n",
      "TRAIN: EPOCH 0156/0200 | BATCH 0000/0001 | LOSS: 0.0568 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0156/0200 | LOSS: 0.0257 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.9769 |  ACC 0.0000\n",
      "\n",
      "Epoch: 157\n",
      "TRAIN: EPOCH 0157/0200 | BATCH 0000/0001 | LOSS: 0.0568 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0157/0200 | LOSS: 0.0234 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2494 |  ACC 0.0000\n",
      "\n",
      "Epoch: 158\n",
      "TRAIN: EPOCH 0158/0200 | BATCH 0000/0001 | LOSS: 0.0552 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0158/0200 | LOSS: 0.0286 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2027 |  ACC 0.0000\n",
      "\n",
      "Epoch: 159\n",
      "TRAIN: EPOCH 0159/0200 | BATCH 0000/0001 | LOSS: 0.1474 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0159/0200 | LOSS: 0.0379 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0881 |  ACC 0.0000\n",
      "\n",
      "Epoch: 160\n",
      "TRAIN: EPOCH 0160/0200 | BATCH 0000/0001 | LOSS: 0.0639 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0160/0200 | LOSS: 0.0415 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2665 |  ACC 0.0000\n",
      "\n",
      "Epoch: 161\n",
      "TRAIN: EPOCH 0161/0200 | BATCH 0000/0001 | LOSS: 0.2772 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0161/0200 | LOSS: 0.0530 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0599 |  ACC 0.0000\n",
      "\n",
      "Epoch: 162\n",
      "TRAIN: EPOCH 0162/0200 | BATCH 0000/0001 | LOSS: 0.6198 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0162/0200 | LOSS: 0.0641 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.5484 |  ACC 0.0000\n",
      "\n",
      "Epoch: 163\n",
      "TRAIN: EPOCH 0163/0200 | BATCH 0000/0001 | LOSS: 0.1566 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0163/0200 | LOSS: 0.0413 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.5076 |  ACC 0.0000\n",
      "\n",
      "Epoch: 164\n",
      "TRAIN: EPOCH 0164/0200 | BATCH 0000/0001 | LOSS: 0.3411 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0164/0200 | LOSS: 0.0472 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0811 |  ACC 0.0000\n",
      "\n",
      "Epoch: 165\n",
      "TRAIN: EPOCH 0165/0200 | BATCH 0000/0001 | LOSS: 0.0579 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0165/0200 | LOSS: 0.0328 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0958 |  ACC 0.0000\n",
      "\n",
      "Epoch: 166\n",
      "TRAIN: EPOCH 0166/0200 | BATCH 0000/0001 | LOSS: 0.1035 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0166/0200 | LOSS: 0.0429 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.8888 |  ACC 0.0000\n",
      "\n",
      "Epoch: 167\n",
      "TRAIN: EPOCH 0167/0200 | BATCH 0000/0001 | LOSS: 0.1008 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0167/0200 | LOSS: 0.0408 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.6079 |  ACC 0.0000\n",
      "\n",
      "Epoch: 168\n",
      "TRAIN: EPOCH 0168/0200 | BATCH 0000/0001 | LOSS: 0.0855 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0168/0200 | LOSS: 0.0400 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.4125 |  ACC 0.0000\n",
      "\n",
      "Epoch: 169\n",
      "TRAIN: EPOCH 0169/0200 | BATCH 0000/0001 | LOSS: 0.1811 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0169/0200 | LOSS: 0.0410 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.8089 |  ACC 0.0000\n",
      "\n",
      "Epoch: 170\n",
      "TRAIN: EPOCH 0170/0200 | BATCH 0000/0001 | LOSS: 0.1166 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0170/0200 | LOSS: 0.0319 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.4571 |  ACC 0.0000\n",
      "\n",
      "Epoch: 171\n",
      "TRAIN: EPOCH 0171/0200 | BATCH 0000/0001 | LOSS: 0.2518 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0171/0200 | LOSS: 0.0431 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1580 |  ACC 0.0000\n",
      "\n",
      "Epoch: 172\n",
      "TRAIN: EPOCH 0172/0200 | BATCH 0000/0001 | LOSS: 0.1453 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0172/0200 | LOSS: 0.0293 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.4106 |  ACC 0.0000\n",
      "\n",
      "Epoch: 173\n",
      "TRAIN: EPOCH 0173/0200 | BATCH 0000/0001 | LOSS: 0.1600 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0173/0200 | LOSS: 0.0326 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3433 |  ACC 0.0000\n",
      "\n",
      "Epoch: 174\n",
      "TRAIN: EPOCH 0174/0200 | BATCH 0000/0001 | LOSS: 0.0691 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0174/0200 | LOSS: 0.0267 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3649 |  ACC 0.0000\n",
      "\n",
      "Epoch: 175\n",
      "TRAIN: EPOCH 0175/0200 | BATCH 0000/0001 | LOSS: 0.1113 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0175/0200 | LOSS: 0.0286 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3912 |  ACC 0.0000\n",
      "\n",
      "Epoch: 176\n",
      "TRAIN: EPOCH 0176/0200 | BATCH 0000/0001 | LOSS: 0.0575 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0176/0200 | LOSS: 0.0273 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3270 |  ACC 0.0000\n",
      "\n",
      "Epoch: 177\n",
      "TRAIN: EPOCH 0177/0200 | BATCH 0000/0001 | LOSS: 0.0541 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0177/0200 | LOSS: 0.0272 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.4279 |  ACC 0.0000\n",
      "\n",
      "Epoch: 178\n",
      "TRAIN: EPOCH 0178/0200 | BATCH 0000/0001 | LOSS: 0.0545 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0178/0200 | LOSS: 0.0280 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.4462 |  ACC 0.0000\n",
      "\n",
      "Epoch: 179\n",
      "TRAIN: EPOCH 0179/0200 | BATCH 0000/0001 | LOSS: 0.0541 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0179/0200 | LOSS: 0.0286 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3066 |  ACC 0.0000\n",
      "\n",
      "Epoch: 180\n",
      "TRAIN: EPOCH 0180/0200 | BATCH 0000/0001 | LOSS: 0.0570 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0180/0200 | LOSS: 0.0269 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.3809 |  ACC 0.0000\n",
      "\n",
      "Epoch: 181\n",
      "TRAIN: EPOCH 0181/0200 | BATCH 0000/0001 | LOSS: 0.0665 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0181/0200 | LOSS: 0.0252 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2501 |  ACC 0.0000\n",
      "\n",
      "Epoch: 182\n",
      "TRAIN: EPOCH 0182/0200 | BATCH 0000/0001 | LOSS: 0.0611 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0182/0200 | LOSS: 0.0269 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2907 |  ACC 0.0000\n",
      "\n",
      "Epoch: 183\n",
      "TRAIN: EPOCH 0183/0200 | BATCH 0000/0001 | LOSS: 0.0665 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0183/0200 | LOSS: 0.0241 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1555 |  ACC 0.0000\n",
      "\n",
      "Epoch: 184\n",
      "TRAIN: EPOCH 0184/0200 | BATCH 0000/0001 | LOSS: 0.0578 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0184/0200 | LOSS: 0.0237 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2289 |  ACC 0.0000\n",
      "\n",
      "Epoch: 185\n",
      "TRAIN: EPOCH 0185/0200 | BATCH 0000/0001 | LOSS: 0.0653 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0185/0200 | LOSS: 0.0235 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0606 |  ACC 0.0000\n",
      "\n",
      "Epoch: 186\n",
      "TRAIN: EPOCH 0186/0200 | BATCH 0000/0001 | LOSS: 0.0566 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0186/0200 | LOSS: 0.0234 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1396 |  ACC 0.0000\n",
      "\n",
      "Epoch: 187\n",
      "TRAIN: EPOCH 0187/0200 | BATCH 0000/0001 | LOSS: 0.0581 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0187/0200 | LOSS: 0.0228 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2616 |  ACC 0.0000\n",
      "\n",
      "Epoch: 188\n",
      "TRAIN: EPOCH 0188/0200 | BATCH 0000/0001 | LOSS: 0.0538 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0188/0200 | LOSS: 0.0232 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1469 |  ACC 0.0000\n",
      "\n",
      "Epoch: 189\n",
      "TRAIN: EPOCH 0189/0200 | BATCH 0000/0001 | LOSS: 0.0537 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0189/0200 | LOSS: 0.0223 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1098 |  ACC 0.0000\n",
      "\n",
      "Epoch: 190\n",
      "TRAIN: EPOCH 0190/0200 | BATCH 0000/0001 | LOSS: 0.0559 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0190/0200 | LOSS: 0.0218 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2491 |  ACC 0.0000\n",
      "\n",
      "Epoch: 191\n",
      "TRAIN: EPOCH 0191/0200 | BATCH 0000/0001 | LOSS: 0.0540 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0191/0200 | LOSS: 0.0212 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2388 |  ACC 0.0000\n",
      "\n",
      "Epoch: 192\n",
      "TRAIN: EPOCH 0192/0200 | BATCH 0000/0001 | LOSS: 0.0540 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0192/0200 | LOSS: 0.0211 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0977 |  ACC 0.0000\n",
      "\n",
      "Epoch: 193\n",
      "TRAIN: EPOCH 0193/0200 | BATCH 0000/0001 | LOSS: 0.0540 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0193/0200 | LOSS: 0.0211 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0061 |  ACC 0.0000\n",
      "\n",
      "Epoch: 194\n",
      "TRAIN: EPOCH 0194/0200 | BATCH 0000/0001 | LOSS: 0.0625 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0194/0200 | LOSS: 0.0212 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.2606 |  ACC 0.0000\n",
      "\n",
      "Epoch: 195\n",
      "TRAIN: EPOCH 0195/0200 | BATCH 0000/0001 | LOSS: 0.0746 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0195/0200 | LOSS: 0.0253 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.6112 |  ACC 0.0000\n",
      "\n",
      "Epoch: 196\n",
      "TRAIN: EPOCH 0196/0200 | BATCH 0000/0001 | LOSS: 0.1257 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0196/0200 | LOSS: 0.0430 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.1839 |  ACC 0.0000\n",
      "\n",
      "Epoch: 197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: EPOCH 0197/0200 | BATCH 0000/0001 | LOSS: 0.3388 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0197/0200 | LOSS: 0.1289 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.0376 |  ACC 0.0000\n",
      "\n",
      "Epoch: 198\n",
      "TRAIN: EPOCH 0198/0200 | BATCH 0000/0001 | LOSS: 0.3416 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0198/0200 | LOSS: 0.1573 |  ACC 0.0000\n",
      "TEST:  LOSS: 6.7501 |  ACC 0.0000\n",
      "\n",
      "Epoch: 199\n",
      "TRAIN: EPOCH 0199/0200 | BATCH 0000/0001 | LOSS: 0.3287 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0199/0200 | LOSS: 0.1069 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.5425 |  ACC 0.0000\n",
      "\n",
      "Epoch: 200\n",
      "TRAIN: EPOCH 0200/0200 | BATCH 0000/0001 | LOSS: 0.0890 |  ACC 0.0000\n",
      "TRAIN: EPOCH 0200/0200 | LOSS: 0.1074 |  ACC 0.0000\n",
      "TEST:  LOSS: 7.8931 |  ACC 0.0000\n",
      "9627.979562997818\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(start_epoch, start_epoch + num_epoch):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(range(1, num_epoch+1), history['training_loss'], label='train')\n",
    "plt.plot(range(1, num_epoch+1), history['test_loss'], label='test')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "\n",
    "if not os.path.isdir(log_dir):\n",
    "    os.mkdir(log_dir)\n",
    "pkl.dump(history, open(log_dir+'/history.pkl', 'wb'))\n",
    "\n",
    "\n",
    "if not os.path.isdir(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "torch.save(state, './%s/%s.pth' % (ckpt_dir, experiment_name))\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b020169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(test_loader, batch_size, n_features, model):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        values = []\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            model.eval()\n",
    "            yhat = model(x_test)\n",
    "            batch_pred = []\n",
    "            for i in range(batch_size):\n",
    "                batch_y_hat = yhat[i].detach().numpy()\n",
    "                batch_pred.append(batch_y_hat[-1][-1])\n",
    "            batch_pred = array(batch_pred)\n",
    "            predictions.append(batch_pred)\n",
    "            values.append(y_test.to(device).detach().numpy())\n",
    "\n",
    "    return predictions, values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce43c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, values = evaluate(test_loader_one, batch_size=1, n_features=input_dim, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e17af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_full, values_full = evaluate(test_loader, batch_size=batch_size, n_features=input_dim, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99710dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(scaler, df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = scaler.inverse_transform(df[col])\n",
    "    return df\n",
    "\n",
    "def format_predictions(predictions, values, df_test, scaler):\n",
    "    vals = np.concatenate(values, axis=0).ravel()\n",
    "    preds = np.concatenate(predictions, axis=0).ravel()\n",
    "    df_result = pd.DataFrame(data={\"value\": vals, \"prediction\": preds}, index=df_test.head(len(vals)).index)\n",
    "    df_result = df_result.sort_index()\n",
    "    df_result = inverse_transform(scaler, df_result, [[\"value\", \"prediction\"]])\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9fc8820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-06-24</th>\n",
       "      <td>18.848999</td>\n",
       "      <td>13.245994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-25</th>\n",
       "      <td>18.826000</td>\n",
       "      <td>13.258254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-26</th>\n",
       "      <td>18.643999</td>\n",
       "      <td>13.255920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-29</th>\n",
       "      <td>18.338499</td>\n",
       "      <td>13.256379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-30</th>\n",
       "      <td>18.350500</td>\n",
       "      <td>13.255951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-12</th>\n",
       "      <td>20.083000</td>\n",
       "      <td>13.181125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-13</th>\n",
       "      <td>20.108999</td>\n",
       "      <td>13.181712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-16</th>\n",
       "      <td>20.011999</td>\n",
       "      <td>13.182588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-17</th>\n",
       "      <td>20.014999</td>\n",
       "      <td>13.182965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-18</th>\n",
       "      <td>20.150000</td>\n",
       "      <td>13.183367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                value  prediction\n",
       "Date                             \n",
       "2015-06-24  18.848999   13.245994\n",
       "2015-06-25  18.826000   13.258254\n",
       "2015-06-26  18.643999   13.255920\n",
       "2015-06-29  18.338499   13.256379\n",
       "2015-06-30  18.350500   13.255951\n",
       "...               ...         ...\n",
       "2019-09-12  20.083000   13.181125\n",
       "2019-09-13  20.108999   13.181712\n",
       "2019-09-16  20.011999   13.182588\n",
       "2019-09-17  20.014999   13.182965\n",
       "2019-09-18  20.150000   13.183367\n",
       "\n",
       "[1059 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = format_predictions(predictions, values, X_test, scaler)\n",
    "df_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8552858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1500cc3a940>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(df_result.index, df_result['value'], label='Values - Test Set')\n",
    "plt.plot(df_result.index, df_result['prediction'], label='Prediction - vs Test set')\n",
    "plt.plot(X_val.index, X_val.iloc[:,0], label='Values - Validation Set')\n",
    "plt.plot(X_train.index, X_train.iloc[:,0], label='Values - Training Set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Rate (Domestic Currency vs US Dollar)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a3257085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1500ceea730>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.plot(df_result.index, df_result['value'], label='Values - Test Set')\n",
    "plt.plot(df_result.index, df_result['prediction'], label='Prediction - vs Test set')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('FX Rate (Domestic Currency vs US Dollar)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ca9b987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1500cbc3d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result_full = format_predictions(predictions_full, values_full, X_test, scaler)\n",
    "df_result_full\n",
    "plt.figure(1)\n",
    "plt.plot(df_result_full.index, df_result_full['value'], label='Values - Test Set')\n",
    "plt.plot(df_result_full.index, df_result_full['prediction'], label='Prediction - vs Test set')\n",
    "plt.plot(X_val.index, X_val.iloc[:,0], label='Values - Validation Set')\n",
    "plt.plot(X_train.index, X_train.iloc[:,0], label='Values - Training Set')\n",
    "plt.xlabel('FX Rate')\n",
    "plt.ylabel('Time')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "89bb1bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-05-06</th>\n",
       "      <td>22.592001</td>\n",
       "      <td>10.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-07</th>\n",
       "      <td>22.371000</td>\n",
       "      <td>10.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-08</th>\n",
       "      <td>22.288000</td>\n",
       "      <td>10.966687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-09</th>\n",
       "      <td>22.480000</td>\n",
       "      <td>10.966687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-10</th>\n",
       "      <td>22.580000</td>\n",
       "      <td>10.966687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-13</th>\n",
       "      <td>22.319000</td>\n",
       "      <td>10.966687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-14</th>\n",
       "      <td>22.256001</td>\n",
       "      <td>10.966687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-15</th>\n",
       "      <td>22.313999</td>\n",
       "      <td>10.966686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-16</th>\n",
       "      <td>22.363001</td>\n",
       "      <td>10.966686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-17</th>\n",
       "      <td>22.013000</td>\n",
       "      <td>10.966686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-20</th>\n",
       "      <td>21.957001</td>\n",
       "      <td>10.966686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-21</th>\n",
       "      <td>22.003000</td>\n",
       "      <td>10.966685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-22</th>\n",
       "      <td>22.182999</td>\n",
       "      <td>10.966685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-23</th>\n",
       "      <td>22.226000</td>\n",
       "      <td>10.966685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-24</th>\n",
       "      <td>22.573999</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-28</th>\n",
       "      <td>22.746000</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-29</th>\n",
       "      <td>22.423000</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-30</th>\n",
       "      <td>22.359001</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-31</th>\n",
       "      <td>22.483000</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-03</th>\n",
       "      <td>22.493000</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-04</th>\n",
       "      <td>22.338001</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-05</th>\n",
       "      <td>22.317999</td>\n",
       "      <td>10.966690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-06</th>\n",
       "      <td>22.279999</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-07</th>\n",
       "      <td>22.018999</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-10</th>\n",
       "      <td>22.042000</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-11</th>\n",
       "      <td>22.180000</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-12</th>\n",
       "      <td>22.046000</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-13</th>\n",
       "      <td>22.148001</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-14</th>\n",
       "      <td>22.042000</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-17</th>\n",
       "      <td>21.974001</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-18</th>\n",
       "      <td>21.961000</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-19</th>\n",
       "      <td>21.945000</td>\n",
       "      <td>10.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-20</th>\n",
       "      <td>22.115000</td>\n",
       "      <td>10.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-21</th>\n",
       "      <td>21.869999</td>\n",
       "      <td>10.966689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-24</th>\n",
       "      <td>21.879999</td>\n",
       "      <td>10.966688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-25</th>\n",
       "      <td>21.751001</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-26</th>\n",
       "      <td>21.831999</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-27</th>\n",
       "      <td>21.663000</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-28</th>\n",
       "      <td>21.594999</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>21.732000</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-02</th>\n",
       "      <td>21.520000</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>21.285000</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-05</th>\n",
       "      <td>21.327000</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-08</th>\n",
       "      <td>21.122999</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-09</th>\n",
       "      <td>21.055000</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-10</th>\n",
       "      <td>21.049999</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-11</th>\n",
       "      <td>20.993000</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-12</th>\n",
       "      <td>20.948999</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-15</th>\n",
       "      <td>21.515999</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-16</th>\n",
       "      <td>21.585001</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-17</th>\n",
       "      <td>22.115999</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-18</th>\n",
       "      <td>22.279999</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-19</th>\n",
       "      <td>22.451000</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-22</th>\n",
       "      <td>22.507000</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-23</th>\n",
       "      <td>22.466000</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-24</th>\n",
       "      <td>22.091000</td>\n",
       "      <td>10.966693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-25</th>\n",
       "      <td>21.976000</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-26</th>\n",
       "      <td>21.719999</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-29</th>\n",
       "      <td>21.430099</td>\n",
       "      <td>10.966692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-30</th>\n",
       "      <td>21.521000</td>\n",
       "      <td>10.966691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                value  prediction\n",
       "Date                             \n",
       "2019-05-06  22.592001   10.966688\n",
       "2019-05-07  22.371000   10.966688\n",
       "2019-05-08  22.288000   10.966687\n",
       "2019-05-09  22.480000   10.966687\n",
       "2019-05-10  22.580000   10.966687\n",
       "2019-05-13  22.319000   10.966687\n",
       "2019-05-14  22.256001   10.966687\n",
       "2019-05-15  22.313999   10.966686\n",
       "2019-05-16  22.363001   10.966686\n",
       "2019-05-17  22.013000   10.966686\n",
       "2019-05-20  21.957001   10.966686\n",
       "2019-05-21  22.003000   10.966685\n",
       "2019-05-22  22.182999   10.966685\n",
       "2019-05-23  22.226000   10.966685\n",
       "2019-05-24  22.573999   10.966691\n",
       "2019-05-28  22.746000   10.966690\n",
       "2019-05-29  22.423000   10.966690\n",
       "2019-05-30  22.359001   10.966690\n",
       "2019-05-31  22.483000   10.966690\n",
       "2019-06-03  22.493000   10.966690\n",
       "2019-06-04  22.338001   10.966690\n",
       "2019-06-05  22.317999   10.966690\n",
       "2019-06-06  22.279999   10.966689\n",
       "2019-06-07  22.018999   10.966689\n",
       "2019-06-10  22.042000   10.966689\n",
       "2019-06-11  22.180000   10.966689\n",
       "2019-06-12  22.046000   10.966689\n",
       "2019-06-13  22.148001   10.966689\n",
       "2019-06-14  22.042000   10.966689\n",
       "2019-06-17  21.974001   10.966689\n",
       "2019-06-18  21.961000   10.966689\n",
       "2019-06-19  21.945000   10.966688\n",
       "2019-06-20  22.115000   10.966688\n",
       "2019-06-21  21.869999   10.966689\n",
       "2019-06-24  21.879999   10.966688\n",
       "2019-06-25  21.751001   10.966692\n",
       "2019-06-26  21.831999   10.966693\n",
       "2019-06-27  21.663000   10.966693\n",
       "2019-06-28  21.594999   10.966693\n",
       "2019-07-01  21.732000   10.966692\n",
       "2019-07-02  21.520000   10.966692\n",
       "2019-07-03  21.285000   10.966692\n",
       "2019-07-05  21.327000   10.966692\n",
       "2019-07-08  21.122999   10.966692\n",
       "2019-07-09  21.055000   10.966691\n",
       "2019-07-10  21.049999   10.966691\n",
       "2019-07-11  20.993000   10.966691\n",
       "2019-07-12  20.948999   10.966691\n",
       "2019-07-15  21.515999   10.966691\n",
       "2019-07-16  21.585001   10.966692\n",
       "2019-07-17  22.115999   10.966692\n",
       "2019-07-18  22.279999   10.966692\n",
       "2019-07-19  22.451000   10.966693\n",
       "2019-07-22  22.507000   10.966693\n",
       "2019-07-23  22.466000   10.966693\n",
       "2019-07-24  22.091000   10.966693\n",
       "2019-07-25  21.976000   10.966692\n",
       "2019-07-26  21.719999   10.966692\n",
       "2019-07-29  21.430099   10.966692\n",
       "2019-07-30  21.521000   10.966691"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_full.tail(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b018cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied - To prove this is suitable for multivariate\n",
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    def train(self, train_loader, val_loader, batch_size=64, n_epochs=50, n_features=1):\n",
    "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        model_path = 'RNN_Test'\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "    \n",
    "    \n",
    "    def evaluate(self, test_loader, batch_size=1, n_features=1):\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "                predictions.append(yhat.to(device).detach().numpy())\n",
    "                values.append(y_test.to(device).detach().numpy())\n",
    "\n",
    "        return predictions, values\n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
